[
  {
    "objectID": "r4babs2/week-3/overview.html",
    "href": "r4babs2/week-3/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week you will how to use and interpret the general linear model when the explanatory (or x) variable is categorical with two possible values. These tests are also known as t-tests. Just as with single linear regression, the response variable is continuous, the model puts a line of best through data and has two parameters called the intercept and the slope. These have the same in interpretation as they do in linear regression. The intercept is one of the group means, and the slope is the difference between that mean and the other group mean. You will also learn about the non-parametric tests we use when the assumptions of the general linear model are not met.\n\nLearning objectives\nThe successful student will be able to:\n\nunderstand the principles of two-sample tests\nappreciate that two-sample tests with lm() are based on the normal distribution and thus have assumptions\nappropriately select parametric and non-parametric two-sample tests\nappropriately select paired and and unpaired two-sample tests\napply and interpret lm()and wilcox.test()\nevaluate whether the assumptions of lm() are met\nscientifically report a two-sample test result including appropriate figures\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read Two-Sample tests\n\nWorkshop\n\nüíª Parametric two-sample test\nüíª Non-parametric two-sample test\nüíª Parametric paired-sample test\n\nConsolidate\n\nüíª Appropriately test whether a genetic modification was successful in increasing omega 3 fatty acids in Cannabis sativa.",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "About"
    ]
  },
  {
    "objectID": "r4babs2/week-3/study_before_workshop.html",
    "href": "r4babs2/week-3/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read Two-Sample tests",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs2/week-6/overview.html",
    "href": "r4babs2/week-6/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Congratulations on making it to the end of the stage 1 Data Analysis in R teaching!\n\n\n\nArtwork by Horst (2023):\n\n\nThis week you will learn how to test whether there is an association between two categorical variables using the chi-squared contingency test and how to test whether there is an association between two continuous variables using the correlation test.\n\nLearning objectives\nThe successful student will be able to:\n\nExplain the principles of correlation and chi-squared contingency tests\nSelect, appropriately correlation and chi-squared contingency tests\nApply and interpret a correlation and chi-squared contingency tests in R\nAppreciate the difference between statistical significance and biological significance\nSummarise and illustrate with appropriate R figures test results scientifically\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read Association\n\nWorkshop\n\nüíª Test whether there is an association between the heights of sibling pairs.\nüíª Learn about the effect of sample size on correlation\nüíª Apply the Spearman rank correlation test to the heights of sibling pairs.\nüíª Test whether there is an association between blood type and peptic ulcers.\nüíª Repeat iv. using untabulated data.\n\nConsolidate\n\nüíª Test whether there the proportion of slug colour morphs is the same in two populations.\nüíª Repeat i. using untabulated data.\n\n\n\n\n\n\n\nReferences\n\nHorst, Allison. 2023. ‚ÄúData Science Illustrations.‚Äù https://allisonhorst.com/allison-horst.",
    "crumbs": [
      "BABS 2",
      "Week 6: Association",
      "About"
    ]
  },
  {
    "objectID": "r4babs2/week-6/study_before_workshop.html",
    "href": "r4babs2/week-6/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read Association",
    "crumbs": [
      "BABS 2",
      "Week 6: Association",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs2/week-5/overview.html",
    "href": "r4babs2/week-5/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week we will extend of our understanding by learning how to include two categorical explanatory variables in a general linear model. This model is often known as the two-way ANOVA. It has three null hypotheses\n\nLearning objectives\nThe successful student will be able to:\n\ncombine dataframes of the same structure\nselect, appropriately, two-way ANOVA\napply and interpret lm() for a two-way ANOVA\nevaluate whether the assumptions of lm() are met\nunderstand the meaning of the interaction term\nscientifically report a two-way ANOVA result including appropriate figures\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read Two-way ANOVA\n\nWorkshop\n\nüíª Two-way ANOVA Choline deficiency on neuron size \n\nConsolidate\n\nüíª Appropriately test whether there are regional differences between two species of butterfly.",
    "crumbs": [
      "BABS 2",
      "Week 5: Two-way ANOVA",
      "About"
    ]
  },
  {
    "objectID": "r4babs2/week-5/study_before_workshop.html",
    "href": "r4babs2/week-5/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read Two-way ANOVA",
    "crumbs": [
      "BABS 2",
      "Week 5: Two-way ANOVA",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs2/r4babs2.html",
    "href": "r4babs2/r4babs2.html",
    "title": "Data Analysis in R for BABS 2",
    "section": "",
    "text": "Welcome to an exciting six-week journey into data analysis with R! In this part of the module, we‚Äôll explore key concepts that are essential for any budding bioscientist, including the logic of hypothesis testing, a foundation for making informed decisions based on data and Statistical models for analysing patterns and relationships across multiple variables.\nThis module builds on your skills from BABS1 step-by-step, helping you gain confidence in applying statistical tools to real-world bioscience problems. By the end, you‚Äôll have a solid understanding of how to analyse data to go with your existing skills in summarising and plottin g it.\n\n\nThe BABS2 Module Learning outcomes that relate to the Data Analysis in R content are:\n\nThink creatively to address a Grand Challenge by designing investigations with testable hypotheses and rigorous controls\nAppropriately select classical univariate statistical tests and some non-parametric equivalents to a given scenario and recognise when these are not suitable\nUse R to perform these analyses, reproducibly, on data in a variety of formats and present the results graphically\nCommunicate research in scientific reports and via oral presentation",
    "crumbs": [
      "BABS 2",
      "Data Analysis in R for BABS 2"
    ]
  },
  {
    "objectID": "r4babs2/r4babs2.html#module-learning-objectives",
    "href": "r4babs2/r4babs2.html#module-learning-objectives",
    "title": "Data Analysis in R for BABS 2",
    "section": "",
    "text": "The BABS2 Module Learning outcomes that relate to the Data Analysis in R content are:\n\nThink creatively to address a Grand Challenge by designing investigations with testable hypotheses and rigorous controls\nAppropriately select classical univariate statistical tests and some non-parametric equivalents to a given scenario and recognise when these are not suitable\nUse R to perform these analyses, reproducibly, on data in a variety of formats and present the results graphically\nCommunicate research in scientific reports and via oral presentation",
    "crumbs": [
      "BABS 2",
      "Data Analysis in R for BABS 2"
    ]
  },
  {
    "objectID": "r4babs2/r4babs2.html#the-logic-of-hypothesis-testing-and-cis",
    "href": "r4babs2/r4babs2.html#the-logic-of-hypothesis-testing-and-cis",
    "title": "Data Analysis in R for BABS 2",
    "section": "The logic of hypothesis testing and CIs",
    "text": "The logic of hypothesis testing and CIs",
    "crumbs": [
      "BABS 2",
      "Data Analysis in R for BABS 2"
    ]
  },
  {
    "objectID": "r4babs2/r4babs2.html#introduction-to-statistical-models-single-regression",
    "href": "r4babs2/r4babs2.html#introduction-to-statistical-models-single-regression",
    "title": "Data Analysis in R for BABS 2",
    "section": "Introduction to statistical models: Single regression",
    "text": "Introduction to statistical models: Single regression",
    "crumbs": [
      "BABS 2",
      "Data Analysis in R for BABS 2"
    ]
  },
  {
    "objectID": "r4babs2/r4babs2.html#two-sample-tests",
    "href": "r4babs2/r4babs2.html#two-sample-tests",
    "title": "Data Analysis in R for BABS 2",
    "section": "Two-sample tests",
    "text": "Two-sample tests",
    "crumbs": [
      "BABS 2",
      "Data Analysis in R for BABS 2"
    ]
  },
  {
    "objectID": "r4babs2/r4babs2.html#one-way-anova-and-kruskal-wallis",
    "href": "r4babs2/r4babs2.html#one-way-anova-and-kruskal-wallis",
    "title": "Data Analysis in R for BABS 2",
    "section": "One-way ANOVA and Kruskal-Wallis",
    "text": "One-way ANOVA and Kruskal-Wallis",
    "crumbs": [
      "BABS 2",
      "Data Analysis in R for BABS 2"
    ]
  },
  {
    "objectID": "r4babs2/r4babs2.html#two-way-anova",
    "href": "r4babs2/r4babs2.html#two-way-anova",
    "title": "Data Analysis in R for BABS 2",
    "section": "Two-way ANOVA",
    "text": "Two-way ANOVA",
    "crumbs": [
      "BABS 2",
      "Data Analysis in R for BABS 2"
    ]
  },
  {
    "objectID": "r4babs2/r4babs2.html#association-correlation-and-contingency",
    "href": "r4babs2/r4babs2.html#association-correlation-and-contingency",
    "title": "Data Analysis in R for BABS 2",
    "section": "Association: Correlation and Contingency",
    "text": "Association: Correlation and Contingency",
    "crumbs": [
      "BABS 2",
      "Data Analysis in R for BABS 2"
    ]
  },
  {
    "objectID": "r4babs2/week-4/study_after_workshop.html",
    "href": "r4babs2/week-4/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª Sports scientists were investigating the effects of fitness and heat acclimatisation on the sodium content of sweat. They measured the sodium content of the sweat (Œºmoll^‚àí1) of three groups of individuals: unfit and unacclimatised (UU); fit and unacclimatised(FU); and fit and acclimatised (FA). The are in sweat.txt. Is there a difference between the groups in the sodium content of their sweat?\n\n\nAnswer - don‚Äôt look until you have tried!# read in the data and look at structure\nsweat &lt;- read_table(\"data-raw/sweat.txt\")\nstr(sweat)\n\n\n\nAnswer - don‚Äôt look until you have tried!# quick plot of the data\nggplot(data = sweat, aes(x = gp, y = na)) +\n  geom_boxplot()\nAnswer - don‚Äôt look until you have tried!# Since the sample sizes are small and not the same in each \n# group and the variance in the FA gp looks a bit lower, I'm \n# leaning to a non-parametric test K-W. However, don't panic if \n# you decided to do an anova\n\n\n\nAnswer - don‚Äôt look until you have tried!# calculate some summary stats \nsweat_summary &lt;- sweat |&gt; \n  group_by(gp) |&gt; \n  summarise(mean = mean(na),\n            n = length(na),\n            median = median(na))\n\n\n\nAnswer - don‚Äôt look until you have tried!# Kruskal-Wallis\nkruskal.test(data = sweat, na ~ gp)\n# We can say there is a difference between the groups in the sodium \n# content of their sweat (chi-squared = 11.9802, df = 2, \n# p-value = 0.002503). Unfit and unacclimatised people have  \n# most salty sweat, Fit and acclimatised people the least salty.\n\n\n\nAnswer - don‚Äôt look until you have tried!# a post-hoc test to see where the sig differences lie:\nlibrary(FSA)\ndunnTest(data = sweat, na ~ gp)\n# Fit and acclimatised people (median = 49.5 Œºmoll^‚àí1) have \n# significantly less sodium in their sweat than the unfit and \n# unacclimatised people (70 Œºmoll^‚àí1) (Kruskal-Wallis multiple \n# comparison p-values adjusted with the Holm method: p = 0.0026). Fit \n# and unacclimatised (54 Œºmoll^‚àí1)  also have significantly less \n# sodium in their people have sodium concentrations than unfit and \n# unacclimatised people (p = 0.033). There was no difference between \n# the Fit and unacclimatised and the Fit and acclimatised. See figure 1.\n\n\n\nAnswer - don‚Äôt look until you have tried!ggplot(sweat, aes(x = gp, y = na) ) +\n  geom_boxplot() +\n  scale_x_discrete(labels = c(\"Fit Acclimatised\", \n                              \"Fit Unacclimatised\", \n                              \"Unfit Unacclimatised\"), \n                   name = \"Group\") +\n  scale_y_continuous(limits = c(0, 110), \n                     expand = c(0, 0),\n                     name = expression(\"Sodium\"~mu*\"mol\"*l^{-1})) +\n  annotate(\"segment\", x = 1, xend = 3, \n           y = 100, yend = 100,\n           colour = \"black\") +\n  annotate(\"text\", x = 2,  y = 103, \n           label = expression(italic(p)~\"= 0.0026\")) +\n  annotate(\"segment\", x = 2, xend = 3, \n           y = 90, yend = 90,\n           colour = \"black\") +\n  annotate(\"text\", x = 2.5,  y = 93, \n           label = expression(italic(p)~\"= 0.0340\")) +\n  theme_classic()\nAnswer - don‚Äôt look until you have tried!# Figure 1. Sodium content of sweat for three groups: Fit and \n# acclimatised (FA), Fit and unacclimatised (FU) and Unfit and \n# unacclimatised (UU). Heavy lines indicate the median, boxes the \n# interquartile range and whiskers the range. \n\n\n\nüíª The data are given in biomass.txt are taken from an experiment in which the insect pest biomass (g) was measured on plots sprayed with water (control) or one of five different insecticides. Do the insecticides vary in their effectiveness? What advice would you give to a person: - currently using insecticide E? - trying to choose between A and D? - trying to choose between C and B?\n\n\nAnswer - don‚Äôt look until you have tried!biom &lt;- read_table(\"data-raw/biomass.txt\")\n# The data are organised with an insecticide treatment group in\n# each column.\n\n\n\nAnswer - don‚Äôt look until you have tried!#Put the data into tidy format.\n\nbiom &lt;- biom |&gt; \n  pivot_longer(cols = everything(),\n               names_to = \"spray\",\n               values_to = \"biomass\")\n\n\n\nAnswer - don‚Äôt look until you have tried!# quick plot of the data\nggplot(data = biom, aes(x = spray, y = biomass)) +\n  geom_boxplot()\nAnswer - don‚Äôt look until you have tried!# Looks like there is a difference between sprays. E doesn't look \n# very effective.\n\n\n\nAnswer - don‚Äôt look until you have tried!# summary statistics\nbiom_summary &lt;- biom |&gt; \n  group_by(spray) |&gt; \n  summarise(mean = mean(biomass),\n            median = median(biomass),\n            sd = sd(biomass),\n            n = length(biomass),\n            se = sd / sqrt(n))\n# thoughts so far: the sample sizes are equal, 10 is a smallish but\n# reasonable sample size\n# the means and medians are similar to each other (expected for\n# normally distributed data), A has a smaller variance \n\n# We have one explanatory variable, \"spray\" comprising 6 levels\n# Biomass has decimal places and we would expect such data to be \n# normally distributed therefore one-way ANOVA is the desired test\n# - we will check the assumptions after building the model\n\n\n\nAnswer - don‚Äôt look until you have tried!# arry out an ANOVA and examine the results \nmod &lt;- lm(data = biom, biomass ~ spray)\nsummary(mod)\n# spray type does have an effect F-statistic: 26.46 on 5 and 54 DF,  \n# p-value: 2.081e-13\n\n\n\nAnswer - don‚Äôt look until you have tried!# Carry out the post-hoc test\nlibrary(emmeans)\n\nemmeans(mod, ~ spray) |&gt; pairs()\n\n# the signifcant comparisons are:\n# contrast         estimate   SE df t.ratio p.value\n# A - D              -76.50 21.9 54  -3.489  0.0119\n# A - E             -175.51 21.9 54  -8.005  &lt;.0001\n# A - WaterControl  -175.91 21.9 54  -8.024  &lt;.0001\n# B - E             -154.32 21.9 54  -7.039  &lt;.0001\n# B - WaterControl  -154.72 21.9 54  -7.057  &lt;.0001\n# C - E             -155.71 21.9 54  -7.102  &lt;.0001\n# C - WaterControl  -156.11 21.9 54  -7.120  &lt;.0001\n# D - E              -99.01 21.9 54  -4.516  0.0005\n# D - WaterControl   -99.41 21.9 54  -4.534  0.0004\n# All sprays are better than the water control except E. \n# This is probably the most important result.\n# What advice would you give to a person currently using insecticide E?\n# Don't bother!! It's no better than water. Switch to any of \n# the other sprays\n#  What advice would you give to a person currently\n#   + trying to choose between A and D? Choose A because A has sig lower\n#   insect biomass than D \n#   + trying to choose between C and B? It doesn't matter because there \n#   is no difference in insect biomass. Use other criteria to chose \n#   (e.g., price)\n# We might report this like:\n# There is a very highly significant effect of spray type on pest \n# biomass (F = 26.5; d.f., 5, 54; p &lt; 0.001). Post-hoc testing \n# showed E was no more effective than the control; A, C and B were \n# all better than the control but could be equally as good as each\n# other; D would be a better choice than the control or E but \n# worse than A. See figure 1\n\n\n\nAnswer - don‚Äôt look until you have tried!# I reordered the bars to make is easier for me to annotate with\n# I also used * to indicate significance\n\nggplot() +\n  geom_point(data = biom, aes(x = reorder(spray, biomass), y = biomass),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"gray50\") +\n  geom_errorbar(data = biom_summary, \n                aes(x = spray, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = biom_summary, \n                aes(x = spray, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Pest Biomass (units)\",\n                     limits = c(0, 540),\n                     expand = c(0, 0)) +\n  scale_x_discrete(\"Spray treatment\") +\n  # E and control are one group\n  annotate(\"segment\", x = 4.5, xend = 6.5, \n           y = 397, yend = 397,\n           colour = \"black\", linewidth = 1) +\n  annotate(\"text\", x = 5.5,  y = 385, \n           label = \"N.S\", size = 4) +\n  # WaterControl-D and E-D    ***\n  annotate(\"segment\", x = 4, xend = 5.5, \n           y = 410, yend = 410,\n           colour = \"black\") +\n  annotate(\"text\", x = 4.5,  y = 420, \n           label = \"***\", size = 5) +\n  # WaterControl-B ***\n  annotate(\"segment\", x = 3, xend = 5.5, \n         y = 440, yend = 440,\n         colour = \"black\") +\n  annotate(\"text\", x = 4,  y = 450,\n           label = \"***\", size = 5) +\n  # WaterControl-C ***\n  annotate(\"segment\", x = 2, xend = 5.5, \n           y = 475, yend = 475,\n           colour = \"black\") +\n  annotate(\"text\", x = 3.5,  y = 485, \n           label = \"***\", size = 5) +\n  # WaterControl-A ***\n  annotate(\"segment\", x = 1, xend = 5.5, \n         y = 510, yend = 510,\n         colour = \"black\") +\n  annotate(\"text\", x = 3.5,  y = 520, \n           label = \"***\", size = 5) +  \n# A-D ***\n  annotate(\"segment\", x = 1, xend = 4, \n         y = 330, yend = 330,\n         colour = \"black\") +\n  annotate(\"text\", x = 2.5,  y = 335, \n           label = \"*\", size = 5) +\n  theme_classic()\nAnswer - don‚Äôt look until you have tried!# Figure 1. The mean pest biomass following various insecticide \n# treatments. # Error bars are +/- 1 S.E. Significant comparisons \n# are indicated: * is p &lt; 0.05, ** p &lt; 0.01 and *** is p &lt; 0.001",
    "crumbs": [
      "BABS 2",
      "Week 4: One-way ANOVA and Kruskal-Wallis",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs2/week-4/workshop.html",
    "href": "r4babs2/week-4/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚ÄúDebugging and feelings‚Äù\n\n\nIn this session you will get practice in choosing between, performing, and presenting the results of, one-way ANOVA and Kruskal-Wallis in R.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding.\nTips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 4: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-4/workshop.html#session-overview",
    "href": "r4babs2/week-4/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this session you will get practice in choosing between, performing, and presenting the results of, one-way ANOVA and Kruskal-Wallis in R.",
    "crumbs": [
      "BABS 2",
      "Week 4: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-4/workshop.html#philosophy",
    "href": "r4babs2/week-4/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding.\nTips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 4: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-4/workshop.html#myoglobin-in-seal-muscle",
    "href": "r4babs2/week-4/workshop.html#myoglobin-in-seal-muscle",
    "title": "Workshop",
    "section": "Myoglobin in seal muscle",
    "text": "Myoglobin in seal muscle\nThe myoglobin concentration of skeletal muscle of three species of seal in grams per kilogram of muscle was determined and the data are given in seal.csv. We want to know if there is a difference between species. Each row represents an individual seal. The first column gives the myoglobin concentration and the second column indicates species.\n Save a copy of the data file seal.csv to data-raw\n Read in the data and check the structure. I used the name seal for the dataframe/tibble.\n What kind of variables do you have?\n\n\n\nExploring\n Do a quick plot of the data. You may need to refer to a previous workshop\nSummarising the data\nDo you remember Look after future you!\n If you followed that tip you‚Äôll be able to open that script and whizz through summarising,testing and plotting.\n Create a data frame called seal_summary that contains the means, standard deviations, sample sizes and standard errors for each species.\nYou should get the following numbers:\n\n\n\n\nspecies\nmean\nstd\nn\nse\n\n\n\nBladdernose Seal\n42.31600\n8.020634\n30\n1.464361\n\n\nHarbour Seal\n49.01033\n8.252004\n30\n1.506603\n\n\nWeddell Seal\n44.66033\n7.849816\n30\n1.433174\n\n\n\n\n\nApplying, interpreting and reporting\nWe can now carry out a one-way ANOVA using the same lm() function we used for two-sample tests.\n Carry out an ANOVA and examine the results with:\n\nmod &lt;- lm(data = seal, myoglobin ~ species)\nsummary(mod)\n\n\nCall:\nlm(formula = myoglobin ~ species, data = seal)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.306  -5.578  -0.036   5.240  18.250 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           42.316      1.468  28.819  &lt; 2e-16 ***\nspeciesHarbour Seal    6.694      2.077   3.224  0.00178 ** \nspeciesWeddell Seal    2.344      2.077   1.129  0.26202    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.043 on 87 degrees of freedom\nMultiple R-squared:  0.1096,    Adjusted R-squared:  0.08908 \nF-statistic: 5.352 on 2 and 87 DF,  p-value: 0.006427\n\n\nRemember: the tilde (~) means test the values in myoglobin when grouped by the values in species. Or explain myoglobin with species\n What do you conclude so far from the test? Write your conclusion in a form suitable for a report.\n\n\n\n Can you relate the values under Estimate to the means?\n\n\n\n\n\n\n\nThe ANOVA is significant but this only tells us that species matters, meaning at least two of the means differ. To find out which means differ, we need a post-hoc test. A post-hoc (‚Äúafter this‚Äù) test is done after a significant ANOVA test. There are several possible post-hoc tests and we will be using Tukey‚Äôs HSD (honestly significant difference) test (Tukey 1949) implemented in the emmeans (Lenth 2024) package.\n Load the package\n\nlibrary(emmeans)\n\n Carry out the post-hoc test\n\nemmeans(mod, ~ species) |&gt; pairs()\n\n contrast                        estimate   SE df t.ratio p.value\n Bladdernose Seal - Harbour Seal    -6.69 2.08 87  -3.224  0.0050\n Bladdernose Seal - Weddell Seal    -2.34 2.08 87  -1.129  0.4990\n Harbour Seal - Weddell Seal         4.35 2.08 87   2.095  0.0968\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nEach row is a comparison between the two means in the ‚Äòcontrast‚Äô column. The ‚Äòestimate‚Äô column is the difference between those means and the ‚Äòp.value‚Äô indicates whether that difference is significant.\nA plot can be used to visualise the result of the post-hoc which can be especially useful when there are very many comparisons.\n Plot the results of the post-hoc test:\n\nemmeans(mod, ~ species) |&gt; plot()\n\n\n\n\n\n\n\nWhere the purple bars overlap, there is no significant difference.\n What do you conclude from the test?\n\n\n\nCheck assumptions\nThe assumptions of the general linear model are that the residuals ‚Äì the difference between predicted value (i.e., the group mean) and observed values - are normally distributed and have homogeneous variance. To check these we can examine the mod$residuals variable. You may want to refer to Checking assumptions in the ‚ÄúSingle regression‚Äù workshop.\n Plot the model residuals against the fitted values.\n What to you conclude?\n\n\n\nTo examine normality of the model residuals we can plot them as a histogram and do a normality test on them.\n Plot a histogram of the residuals.\n Use the shapiro.test() to test the normality of the model residuals\n What to you conclude?\n\n\n\n\nIllustrating\n Create a figure like the one below. You may need to refer to Visualise from the ‚ÄúSummarising data with several variables‚Äù workshop (Rand 2023)\nWe will again use both our seal and seal_summary dataframes.\n Create the plot:\n\n\n\n\n\n\n\n\n Save your figure to your figures folder.",
    "crumbs": [
      "BABS 2",
      "Week 4: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-4/workshop.html#leafminers-on-birch",
    "href": "r4babs2/week-4/workshop.html#leafminers-on-birch",
    "title": "Workshop",
    "section": "Leafminers on Birch",
    "text": "Leafminers on Birch\nLarvae of the Ambermarked birch leafminer, Profenusa thomsoni, feed on the interior leaf tissues of Birch (Betula) species. They do not normally kill the tree but can weaken it making it susceptible to attack from other species. Researchers are interested in whether there is a difference in the rates at which white, grey and yellow birch are attacked. They introduce adult female P.thomsoni to a green house containing 30 young trees (ten of each type) and later count the egg laying events on each tree. The data are in leaf.txt.\nExploring\n Read in the data and check the structure. I used the name leaf for the dataframe/tibble.\n What kind of variables do we have?\n\n\n\n\n Do a quick plot of the data.\n Using your common sense, do these data look normally distributed?\n\n\n\n Why is a Kruskal-Wallis appropriate in this case?\n\n\n\n\n\n\n Calculate the medians, means and sample sizes.\nApplying, interpreting and reporting\n Carry out a Kruskal-Wallis:\n\nkruskal.test(data = leaf, eggs ~ birch)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  eggs by birch\nKruskal-Wallis chi-squared = 6.3393, df = 2, p-value = 0.04202\n\n\n What do you conclude from the test?\n\n\n\nA significant Kruskal-Wallis tells us at least two of the groups differ but where do the differences lie? The Dunn test is a post-hoc multiple comparison test for a significant Kruskal-Wallis. It is available in the package FSA\n Load the package using:\n\nlibrary(FSA)\n\n Run the post-hoc test with:\n\ndunnTest(data = leaf, eggs ~ birch)\n\n      Comparison         Z    P.unadj      P.adj\n1   Grey - White  1.296845 0.19468465 0.38936930\n2  Grey - Yellow -1.220560 0.22225279 0.22225279\n3 White - Yellow -2.517404 0.01182231 0.03546692\n\n\nThe P.adj column gives p-value for the comparison listed in the first column. Z is the test statistic.\n What do you conclude from the test?\n\n\n\n Write up the result is a form suitable for a report.\n\n\n\n\n\n\n\nIllustrating\n A box plot is an appropriate choice for illustrating a Kruskal-Wallis. Can you produce a figure like this?\n\n\n\n\n\n\n\n\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 2",
      "Week 4: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-2/study_after_workshop.html",
    "href": "r4babs2/week-2/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª Effect of anxiety status and sporting performance. The data in sprint.txt are from an investigation of the effect of anxiety status and sporting performance. A group of 40 100m sprinters undertook a psychometric test to measure their anxiety shortly before competing. The data are their anxiety scores and the 100m times achieved. What you do conclude from these data?\n\n\nAnswer - don‚Äôt look until you have tried!# this example is designed to emphasise the importance of plotting your data first\nsprint &lt;- read_table(\"data-raw/sprint.txt\")\n# Anxiety is discrete but ranges from 16 to 402 meaning the gap between possible measures is small and \n# the variable could be treated as continuous if needed. Time is a continuous measure that has decimal places and which we would expect to follow a normal distribution \n\n# explore with a plot\nggplot(sprint, aes(x = anxiety, y = time) ) +\n  geom_point()\nAnswer - don‚Äôt look until you have tried!# A scatterplot of the data clearly reveals that these data are not linear. There is a good relationship between the two variables but since it is not linear, single linear regression is not appropriate.\n\n\n\nüíª Juvenile hormone in stag beetles. The concentration of juvenile hormone in stag beetles is known to influence mandible growth. Groups of stag beetles were injected with different concentrations of juvenile hormone (arbitrary units) and their average mandible size (mm) determined. The experimenters planned to analyse their data with regression. The data are in stag.txt\n\n\n\nAnswer - don‚Äôt look until you have tried!# read the data in and check the structure\nstag &lt;- read_table(\"data-raw/stag.txt\")\nstr(stag)\n\n# jh is discrete but ordered and has been chosen by the experimenter - it is the explanatory variable.  \n# the response is mandible size which has decimal places and is something we would expect to be \n# normally distributed. So far, common sense suggests the assumptions of regression are met.\n\n\n\nAnswer - don‚Äôt look until you have tried!# exploratory plot\nggplot(stag, aes(x = jh, y = mand)) +\n  geom_point()\nAnswer - don‚Äôt look until you have tried!# looks linear-ish on the scatter\n# regression still seems appropriate\n# we will check the other assumptions after we have run the lm\n\n\n\nAnswer - don‚Äôt look until you have tried!# build the statistical model\nmod &lt;- lm(data = stag, mand ~ jh)\n\n# examine it\nsummary(mod)\n# mand = 0.032*jh + 0.419\n# the slope of the line is significantly different from zero / the jh explains a significant amount of the variation in mand (ANOVA: F = 16.63; d.f. = 1,14; p = 0.00113).\n# the intercept is 0.419 and differs significantly from zero \n\n\n\nAnswer - don‚Äôt look until you have tried!# checking the assumption\nplot(mod, which = 1) \nAnswer - don‚Äôt look until you have tried!# we're looking for the variance in the residuals to be equal along the x axis.\n# with a small data set there is some apparent heterogeneity but it doesn't look too.\n# \nhist(mod$residuals)\nAnswer - don‚Äôt look until you have tried!# We have some skew which again might be partly a result of a small sample size.\nshapiro.test(mod$residuals) # the also test not sig diff from normal\n\n# On balance the use of regression is probably justifiable but it is borderline\n# but ideally the experiment would be better if multiple individuals were measure at\n# each of the chosen juvenile hormone levels.\n\n\n\nAnswer - don‚Äôt look until you have tried!# a better plot\nggplot(stag, aes(x = jh, y = mand) ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  scale_x_continuous(name = \"Juvenile hormone (arbitrary units)\",\n                     expand = c(0, 0),\n                     limits = c(0, 32)) +\n  scale_y_continuous(name = \"Mandible size (mm)\",\n                     expand = c(0, 0),\n                     limits = c(0, 2)) +\n  theme_classic()",
    "crumbs": [
      "BABS 2",
      "Week 2: Introduction to statistical models: Single regression",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs2/week-2/workshop.html",
    "href": "r4babs2/week-2/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚Äúlinear regression dragons‚Äù\n\n\nIn this session you will carry out, interpret and report a single linear regression.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 2: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-2/workshop.html#session-overview",
    "href": "r4babs2/week-2/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this session you will carry out, interpret and report a single linear regression.",
    "crumbs": [
      "BABS 2",
      "Week 2: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-2/workshop.html#philosophy",
    "href": "r4babs2/week-2/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 2: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-2/workshop.html#linear-regression",
    "href": "r4babs2/week-2/workshop.html#linear-regression",
    "title": "Workshop",
    "section": "Linear Regression",
    "text": "Linear Regression\nThe data in plant.xlsx is a set of observations of plant growth over two months. The researchers planted the seeds and harvested, dried and weighed a plant each day from day 10 so all the data points are independent of each other.\n Save a copy of plant.xlsx to your data-raw folder and import it.\n What type of variables do you have? Which is the response and which is the explanatory? What is the null hypothesis?\n\n\n\n\n\n\nExploring\n Do a quick plot of the data:\n\nggplot(plant, aes(x = day, y = mass)) +\n  geom_point()\n\n\n\n\n\n\n\n What are the assumptions of linear regression? Do these seem to be met?\n\n\n\n\n\n\n\n\n\n\nApplying, interpreting and reporting\n We now carry out a regression assigning the result of the lm() procedure to a variable and examining it with summary().\n\nmod &lt;- lm(data = plant, mass ~ day)\nsummary(mod)\n\n\nCall:\nlm(formula = mass ~ day, data = plant)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.810 -11.253  -0.408   9.075  48.869 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -8.6834     6.4729  -1.342    0.186    \nday           1.6026     0.1705   9.401  1.5e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.92 on 49 degrees of freedom\nMultiple R-squared:  0.6433,    Adjusted R-squared:  0.636 \nF-statistic: 88.37 on 1 and 49 DF,  p-value: 1.503e-12\n\n\nThe Estimates in the Coefficients table give the intercept (first line) and the slope (second line) of the best fitting straight line. The p-values on the same line are tests of whether that coefficient is different from zero.\nThe F value and p-value in the last line are a test of whether the model as a whole explains a significant amount of variation in the dependent variable. For a single linear regression this is exactly equivalent to the test of the slope against zero.\n What is the equation of the line? What do you conclude from the analysis?\n\n\n\n\n\n Does the line go through (0,0)?\n\n\n\n What percentage of variation is explained by the line?\n\n\nIt might be useful to assign the slope and the intercept to variables in case we need them later. The can be accessed in the mod$coefficients variable:\n\nmod$coefficients\n\n(Intercept)         day \n  -8.683379    1.602606 \n\n\n Assign mod$coefficients[1] to b0 and mod$coefficients[1] to b1:\n\nb0 &lt;- mod$coefficients[1] |&gt; round(2)\nb1 &lt;- mod$coefficients[2] |&gt; round(2)\n\nI also rounded the values to two decimal places.\nChecking assumptions\nWe need to examine the residuals. Very conveniently, the object which is created by lm() contains a variable called $residuals. Also conveniently, the R‚Äôs plot() function can used on the output objects of lm(). The assumptions of the GLM demand that each y is drawn from a normal distribution for each x and these normal distributions have the same variance. Therefore, we plot the residuals against the fitted values to see if the variance is the same for all the values of x. The fitted - or predicted - values are the values on the line of best fit. Each residual is the difference between the fitted values and the observed value.\n Plot the model residuals against the fitted values like this:\n\nplot(mod, which = 1)\n\n\n\n\n\n\n\n What to you conclude?\n\n\n\nTo examine normality of the model residuals we can plot them as a histogram and do a normality test on them.\n Plot a histogram of the residuals:\n\nggplot(mapping = aes(x = mod$residuals)) + \n  geom_histogram(bins = 10)\n\n\n\n\n\n\n\n Use the shapiro.test() to test the normality of the model residuals\n\nshapiro.test(mod$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mod$residuals\nW = 0.96377, p-value = 0.1208\n\n\nUsually, when we are doing statistical tests we would like the the test to be significant because it means we have evidence of a biological effect. However, when doing normality tests we hope it will not be significant. A non-significant result means that there is no significant difference between the distribution of the residuals and a normal distribution and that indicates the assumptions are met.\n What to you conclude?\n\n\n\n\nIllustrating\nWe want a figure with the points and the statistical model, i.e., the best fitting straight line.\n Create a scatter plot using geom_point()\n\nggplot(plant, aes(x = day, y = mass)) +\n  geom_point() + \n  theme_classic()\n\n\n\n\n\n\n\n The geom_smooth() function will add a variety of fitted lines to a plot. We want a straight line so we need to specify method = \"lm\":\n\nggplot(plant, aes(x = day, y = mass)) +\n  geom_point() +   \n  geom_smooth(method = \"lm\", \n              se = FALSE, \n              colour = \"black\") +\n  theme_classic()\n\n\n\n\n\n\n\n What do the se and colour arguments do? Try changing them.\n Let‚Äôs add the equation of the line to the figure using annotate():\n\nggplot(plant, aes(x = day, y = mass)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              se = FALSE, \n              colour = \"black\") +\n  annotate(\"text\", x = 20, y = 110, \n           label = \"mass = 1.61 * day - 8.68\") +\n  theme_classic()\n\n\n\n\n\n\n\nWe have to tell annotate() what type of geom we want - text in this case, - where to put it, and the text we want to appear.\n Improve the axes. You may need to refer back Changing the axes from the Week 7 workshop in BABS1 (Rand 2023)\n Save your figure to your figures folder. Make sure you script figure saving with ggsave().",
    "crumbs": [
      "BABS 2",
      "Week 2: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-2/workshop.html#look-after-future-you",
    "href": "r4babs2/week-2/workshop.html#look-after-future-you",
    "title": "Workshop",
    "section": "Look after future you!",
    "text": "Look after future you!\nMake life easier for future you by going back through your code and tidying up.\nYou might need to:\n\ncollect together library statements at the beginning of the code\nedit your comments for clarity and include a paragraph explaining what the analysis is about\nrename variables for consistency or clarity\nremove house keeping or exploratory code or mark it for later removal\nrestyle code, add code section headers etc\n\nIf you need to make additional notes that do not belong in the script, you can add them a text file called README.txt that future you will know what to do with!\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 2",
      "Week 2: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-2/workshop.html#footnotes",
    "href": "r4babs2/week-2/workshop.html#footnotes",
    "title": "Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\nYou made this folder in Week 1.‚Ü©Ô∏é",
    "crumbs": [
      "BABS 2",
      "Week 2: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-1/study_after_workshop.html",
    "href": "r4babs2/week-1/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª Adiponectin is exclusively secreted from adipose tissue and modulates a number of metabolic processes. Nicotinic acid can affect adiponectin secretion. 3T3-L1 adipocytes were treated with nicotinic acid or with a control treatment and adiponectin concentration (pg/mL) measured. The data are in adipocytes.txt. Each row represents an independent sample of adipocytes and the first column gives the concentration adiponectin and the second column indicates whether they were treated with nicotinic acid or not. Estimate the mean Adiponectin concentration in each group - this means calculate the sample mean and construct a confidence interval around it for each group. This exercise forces you to bring together ideas from this workshop and from previous workshops\n\n\nHow to calculate a confidence intervals (this workshop)\n\nHow to summarise variables in more than one group (previous BABS 1 workshop)\n\n\nAnswer - don‚Äôt look until you have tried!# data import\nadip &lt;- read_table(\"data-raw/adipocytes.txt\")\n\n# examine the structure\nstr(adip)\n\n# summarise\nadip_summary &lt;- adip %&gt;% \n  group_by(treatment) %&gt;% \n  summarise(mean = mean(adiponectin),\n            sd = sd(adiponectin),\n            n = length(adiponectin),\n            se = sd/sqrt(n),\n            dif = qt(0.975, df = n - 1) * se,\n            lower_ci = mean - dif,\n            uppp_ci = mean + dif)\n\n\n# we conclude we're 95% certain the mean for the control group is \n# between 4.73 and 6.36 and the mean for the nicotinic group is \n# between 6.52 and 8.50. More usually we might put is like this:\n# the mean for the control group is 5.55 +/- 0.82 and that for the nicotinic group is 7.51 +/- 0.99",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs2/week-1/workshop.html",
    "href": "r4babs2/week-1/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚Äúlove this class‚Äù\n\n\nIn this session you will remind yourself how to import files, and calculate confidence intervals on large and small samples. You will also learn how to create a zip file - this is what you will submit for the assessment.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-1/workshop.html#session-overview",
    "href": "r4babs2/week-1/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this session you will remind yourself how to import files, and calculate confidence intervals on large and small samples. You will also learn how to create a zip file - this is what you will submit for the assessment.",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-1/workshop.html#philosophy",
    "href": "r4babs2/week-1/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-1/workshop.html#remind-yourself-how-to-import-files",
    "href": "r4babs2/week-1/workshop.html#remind-yourself-how-to-import-files",
    "title": "Workshop",
    "section": "Remind yourself how to import files!",
    "text": "Remind yourself how to import files!\nImporting data from files was covered in BABS 1 (Rand 2023) if you need to remind yourself.",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-1/workshop.html#check-your-settings",
    "href": "r4babs2/week-1/workshop.html#check-your-settings",
    "title": "Workshop",
    "section": "Check your settings",
    "text": "Check your settings\nChanging some defaults to make life easier\nSome useful settings",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-1/workshop.html#confidence-intervals-large-samples",
    "href": "r4babs2/week-1/workshop.html#confidence-intervals-large-samples",
    "title": "Workshop",
    "section": "Confidence intervals (large samples)",
    "text": "Confidence intervals (large samples)\nThe data in beewing.txt are left wing widths of 100 honey bees (mm). The confidence interval for large samples is given by:\n\\(\\bar{x} \\pm 1.96 \\times s.e.\\)\nWhere 1.96 is the quantile for 95% confidence.\n Save beewing.txt to your data-raw folder.\n Read in the data and check the structure of the resulting dataframe.\n Calculate and assign to variables: the mean, standard deviation, sample size and standard error:\n\n# mean\nm &lt;- mean(beewing$wing_mm)\n\n# standard deviation\nsd &lt;- sd(beewing$wing_mm)\n\n# sample size (needed for the se)\nn &lt;- length(beewing$wing_mm)\n\n# standard error\nse &lt;- sd / sqrt(n)\n\n To calculate the 95% confidence interval we need to look up the quantile (multiplier) using qnorm():\n\nq &lt;- qnorm(0.975)\n\nThis should be about 1.96.\n Now we can use it in our confidence interval calculation:\n\nlcl &lt;- m - q * se\nucl &lt;- m + q * se\n\nI used the names lcl and ucl to stand for ‚Äúlower confidence limit‚Äù and ‚Äúupper confidence limit‚Äù respectively.\n Print the values:\n\nlcl\n\n[1] 4.473176\n\nucl\n\n[1] 4.626824\n\n\nThis means we are 95% confident the population mean lies between 4.47 mm and 4.63 mm.\n How would you write this up in a report?\n\n\n\n Between what values would you be 99% confident of the population mean being?\n\n\n\n\n\n\nHint\n\n\n\nYou will need to think about what probability to give qnorm(). For 95% confidence intervals we had to give 0.975. This is because 95% is 2.5% (0.025) in each tail of the distribution.",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-1/workshop.html#confidence-intervals-small-samples",
    "href": "r4babs2/week-1/workshop.html#confidence-intervals-small-samples",
    "title": "Workshop",
    "section": "Confidence intervals (small samples)",
    "text": "Confidence intervals (small samples)\nThe confidence interval for small samples is given by:\n\\(\\bar{x} \\pm t_{[d.f]} \\times s.e.\\)\nThe only difference between the C.I. calculation for small samples and the C.I. calculation for large sample is the multiplier. For large samples we use the ‚Äúthe standard normal distribution‚Äù accessed with qnorm(); for small samples we use the ‚Äút distribution‚Äù assessed with qt().\nThe value returned by q(t) is larger than that by qnorm() which reflects the greater uncertainty we have on estimations of population means based on small samples.\nThe fatty acid Docosahexaenoic acid (DHA) is a major component of membrane phospholipids in nerve cells and deficiency leads to many behavioural and functional deficits. The cross sectional area of neurons in the CA 1 region of the hippocampus of normal rats is 155 \\(\\mu m^2\\). A DHA deficient diet was fed to 8 animals and the cross sectional area (csa) of neurons is given in neuron.txt\n Save neuron.txt to your data-raw folder\n Read in the data and check the structure of the resulting dataframe\n Assign the mean to m.\n Calculate and assign the standard error to se.\nTo work out the confidence interval for our sample mean we need to use the t distribution because it is a small sample. This means we need to determine the degrees of freedom (the number in the sample minus one).\n We can assign this to a variable, df, using:\n\ndf &lt;- length(neur$csa) - 1\n\n The t value is found by:\n\nt &lt;- qt(0.975, df = df)\n\nNote that we are using qt() rather than qnorm() but that the probability, 0.975, used is the same. Finally, we need to put our mean, standard error and t value in the equation. \\(\\bar{x} \\pm t_{[d.f]} \\times s.e.\\).\n The upper confidence limit is:\n\n(m + t * se) |&gt; round(2)\n\n[1] 151.95\n\n\nThe first part of the command, (m + t * se) calculates the upper limit. This is ‚Äòpiped‚Äô in to the round() function to round the result to two decimal places.\n Calculate the lower confidence limit:\n Given the upper and lower confidence values for the estimate of the population mean, what do you think about the effect of the DHA deficient diet?",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-1/workshop.html#look-after-future-you",
    "href": "r4babs2/week-1/workshop.html#look-after-future-you",
    "title": "Workshop",
    "section": "Look after future you!",
    "text": "Look after future you!\nHave a look at the Assessment Overview on the VLE. Part of the assessment for BIO00026C Becoming a Bioscientist: Grand Challenges is to submit the RStudio Project which supports the figures and analysis in your report. You will zip up the RStudio Project folder and submit it to the VLE. That folder should contain all the data, code and figures you have used in your report and all of the results should be reproducible. Reproducible means that if someone downloads that zipped folder and unzips it they should be able to understand what the analysis was, what you did and why and be able to run all the code to reproduce the figures and results in your report without issue.\nYou can practice this every week!\n Make sure your script is saved. Close down the ‚Äúweek-1‚Äù RStudio project using either the file menu or the menu on the top right where the Project name appears.\n Locate the week-1 folder in Windows explorer. Right click on the folder and select ‚ÄúSend to‚Äù and then ‚ÄúCompressed (zipped) folder‚Äù. This will create a file called week-1.zip. Email this file to someone near you have have them email you with theirs. Your neighbour should be able to download week-1.zip, unzip it and then open the project in RStudio and run the code to reproduce all your work. ** Note: Save the downloaded week-1.zip some where that is NOT your ‚Äúdata-analysis-in-r-2‚Äù to avoid naming conflicts.** Also do not save it in any RStudio project folder.\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/overview.html",
    "href": "pgt52m/week-3/overview.html",
    "title": "Overview",
    "section": "",
    "text": "The type of values our data can take is important in how we analyse and visualise it. This week you will learn the difference between continuous and discrete values and how we summarise and visualise them. You will also learn about the ‚Äúnormal distribution‚Äù which is the most important continuous distribution.\n\n\n\nDiscrete variable\n\n\n\nLearning objectives\nThe successful student will be able to:\n\ndistinguish between continuous, discrete, nominal and ordinal variable\nread in data in to RStudio from a plain text file and Excel files\nsummarise and plot variables appropriately for the data type\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read: Ideas about data\n\nWorkshop\n\nüíª Importing data\nüíª Summarising discrete data\nüíª Summarising count data\nüíª Summarising continuous data\n\nConsolidate\n\nüíª Summarise some data\nüíª Plot some data\nüíª Format a plot (1)\nüíª Format a plot (2)\nüìñ Read Understanding the pipe |&gt;",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-3/study_before_workshop.html",
    "href": "pgt52m/week-3/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read Ideas about data",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Prepare!"
    ]
  },
  {
    "objectID": "pgt52m/week-6/overview.html",
    "href": "pgt52m/week-6/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week you will be introduced to the idea of a statistical ‚Äúmodel‚Äù in general and to general linear model in particular. Our first general linear model will be single linear regression which puts a line of best fit through data so the response can be predicted from the explanatory variable. We will consider the two ‚Äúparameters‚Äù estimated by the model (the slope and the intercept) and whether these differ from zero\n\nLearning objectives\nThe successful student will be able to:\n\nexplain what is meant by a statistical model and fitting a model\nknow what the general linear model is and how it relates to regression\nexplain the principle of regression and know when it can be applied\napply and interpret a simple linear regression in R\nevaluate whether the assumptions of regression are met\nscientifically report a regression result including appropriate figures\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read What is a statistical model\nüìñ Read Single linear regression\n\nWorkshop\ni.üíª Carry out a single linear regression\nConsolidate\n\nüíª Appropriately analyse the relationsip between juvenile hormone and mandible size in stage beetles\nüíª Appropriately analyse the relationsip between anxiety and performance",
    "crumbs": [
      "PGT 52M",
      "Week 6: Introduction to statistical models: Single regression",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-6/study_before_workshop.html",
    "href": "pgt52m/week-6/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read What is a statistical model\nüìñ Read Single linear regression",
    "crumbs": [
      "PGT 52M",
      "Week 6: Introduction to statistical models: Single regression",
      "Prepare!"
    ]
  },
  {
    "objectID": "pgt52m/week-7/overview.html",
    "href": "pgt52m/week-7/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week you will how to use and interpret the general linear model when the x variable is categorical and has two groups. Just as with single linear regression, the model puts a line of best through data and the model parameters, the intercept and the slope, have the same in interpretation The intercept is one of the group means and the slope is the difference between that, mean and the other group mean. You will also learn about the non-parametric equivalents - the tests we use when the assumptions of the general linear model are not met.\n\nLearning objectives\nThe successful student will be able to:\n\nunderstand the principles of two-sample tests\nappreciate that two-sample tests with lm() are based on the normal distribution and thus have assumptions\nappropriately select parametric and non-parametric two-sample tests\nappropriately select paired and and unpaired two-sample tests\napply and interpret lm()and wilcox.test()\nevaluate whether the assumptions of lm() are met\nscientifically report a two-sample test result including appropriate figures\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read Two-Sample tests\n\nWorkshop\n\nüíª Parametric two-sample test\nüíª Non-parametric two-sample test\nüíª Parametric paired-sample test\n\nConsolidate\n\nüíª Appropriately test whether a genetic modification was successful in increasing omega 3 fatty acids in Cannabis sativa.\nüíª ‚Ä¶.",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-7/study_before_workshop.html",
    "href": "pgt52m/week-7/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "Prepare\n\nüìñ Read Two-Sample tests",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "Prepare!"
    ]
  },
  {
    "objectID": "pgt52m/week-5/overview.html",
    "href": "pgt52m/week-5/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week we will cover the logic of consider the logic of hypothesis testing and type 1 and type 2 errors. We will also find out what the sampling distribution of the mean and the standard error are, and how to calculate confidence intervals.\n\n\n\nArtwork by Horst (2023): ‚Äútype 1 error‚Äù\n\n\n\n\n\nArtwork by Horst (2023): ‚Äútype 2 error‚Äù\n\n\n\nLearning objectives\nThe successful student will be able to:\n\ndemonstrate the process of hypothesis testing with an example\nexplain type 1 and type 2 errors\ndefine the sampling distribution of the mean and the standard error\nexplain what a confidence interval is\ncalculate confidence intervals for large and small samples\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read The logic of hyothesis testing\nüìñ Read Confidence Intervals\n\nWorkshop\n\nüíª Remind yourself how to import files\nüíª Calculate confidence intervals on large\nüíª Calculate confidence intervals on small samples.\n\nConsolidate\n\nüíª Calculate confidence intervals for each group in a data set\n\n\n\n\n\n\n\nReferences\n\nHorst, Allison. 2023. ‚ÄúData Science Illustrations.‚Äù https://allisonhorst.com/allison-horst.",
    "crumbs": [
      "PGT 52M",
      "Week 5: The logic of hypothesis testing and CI",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-5/study_before_workshop.html",
    "href": "pgt52m/week-5/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read The logic of hyothesis testing\nüìñ Read Confidence Intervals",
    "crumbs": [
      "PGT 52M",
      "Week 5: The logic of hypothesis testing and CI",
      "Prepare!"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html",
    "href": "pgt52m/pgt52m.html",
    "title": "52M Data Analysis in R",
    "section": "",
    "text": "This module introduces you to data analysis in R. The first 4 weeks covers core concepts about scientific computing, types of variable, the role of variables in analysis and how to use RStudio to organise analysis and import, summarise and plot data. In weeks 5 to 8, you will learn about the logic of hypothesis testing, confidence intervals, what is meant by a statistical model, two-sample tests and one-way analysis of variance (ANOVA). You will learn how to write reproducible reports in Quarto in weeks 9 and 10. Finally, there will be a drop-in for your questions in week 11.\nThis module complement the work you will do in BIO00070M Research, Professional and Team Skills where you will you will learn how to organise reproducible data analyses using a project-oriented workflow and analyses RNA sequence data. It will be important to use the skills and tools you learn in 52M and apply them in 70M.\n\n\nThe Module Learning outcomes are:\n\nExplain the purpose of data analysis and the rationale for scripting analysis in the biosciences\nRecognise when statistics such as t-tests, one-way ANOVA, correlation and regression can be applied, and use R to perform these analyses on data in a variety of formats\nSummarise data in single or multiple groups, recognise tidy data formats, and carry out some typical data tidying tasks\nUse markdown (through Quarto) to produce reproducible analyses, figures and reports",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#module-learning-objectives",
    "href": "pgt52m/pgt52m.html#module-learning-objectives",
    "title": "52M Data Analysis in R",
    "section": "",
    "text": "The Module Learning outcomes are:\n\nExplain the purpose of data analysis and the rationale for scripting analysis in the biosciences\nRecognise when statistics such as t-tests, one-way ANOVA, correlation and regression can be applied, and use R to perform these analyses on data in a variety of formats\nSummarise data in single or multiple groups, recognise tidy data formats, and carry out some typical data tidying tasks\nUse markdown (through Quarto) to produce reproducible analyses, figures and reports",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-1-understanding-file-systems",
    "href": "pgt52m/pgt52m.html#week-1-understanding-file-systems",
    "title": "52M Data Analysis in R",
    "section": "Week 1: Understanding file systems",
    "text": "Week 1: Understanding file systems\nYou will learn about operating systems, files and file systems, working directories, absolute and relative paths, what R and RStudio are",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-2-introduction-to-r-and-project-organisation",
    "href": "pgt52m/pgt52m.html#week-2-introduction-to-r-and-project-organisation",
    "title": "52M Data Analysis in R",
    "section": "Week 2: Introduction to R and project organisation",
    "text": "Week 2: Introduction to R and project organisation\nYou will start writing R code in RStudio and will create your first graph! You will learn about data types such as ‚Äúnumerics‚Äù and ‚Äúcharacters‚Äù and some of the different types of objects in R such as ‚Äúvectors‚Äù and ‚Äúdataframes‚Äù. These are the building blocks for the rest of your R journey. You will also learn a workflow and about the layout of RStudio and using RStudio Projects.",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-3-types-of-variable-summarising-and-plotting-data",
    "href": "pgt52m/pgt52m.html#week-3-types-of-variable-summarising-and-plotting-data",
    "title": "52M Data Analysis in R",
    "section": "Week 3: Types of variable, summarising and plotting data",
    "text": "Week 3: Types of variable, summarising and plotting data\nThe type of values our data can take is important in how we analyse and visualise it. This week you will learn the difference between continuous and discrete values and how we summarise and visualise them. The focus will be on plotting and summarising single variables. You will also learn how to read in data in to RStudio from plain text files and Excel files.",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-4-summarising-data-with-several-variables",
    "href": "pgt52m/pgt52m.html#week-4-summarising-data-with-several-variables",
    "title": "52M Data Analysis in R",
    "section": "Week 4: Summarising data with several variables",
    "text": "Week 4: Summarising data with several variables\nThis week you will start plotting data sets with more than one variable. This means you need to be able determine which variable is the response and which is the explanatory. You will find out what is meant by ‚Äútidy‚Äù data and how to perform a simple data tidying task. Finally you will discover how to save your figures and place them in documents.",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-5-the-logic-of-hypothesis-testing-and-ci",
    "href": "pgt52m/pgt52m.html#week-5-the-logic-of-hypothesis-testing-and-ci",
    "title": "52M Data Analysis in R",
    "section": "Week 5: The logic of hypothesis testing and CI",
    "text": "Week 5: The logic of hypothesis testing and CI\nThis week we will cover the logic of consider the logic of hypothesis testing and type 1 and type 2 errors. We will also find out what the sampling distribution of the mean and the standard error are, and how to calculate confidence intervals.",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-6-introduction-to-statistical-models-single-regression",
    "href": "pgt52m/pgt52m.html#week-6-introduction-to-statistical-models-single-regression",
    "title": "52M Data Analysis in R",
    "section": "Week 6: Introduction to statistical models: Single regression",
    "text": "Week 6: Introduction to statistical models: Single regression\nThis week you will be introduced to the idea of a statistical ‚Äúmodel‚Äù in general and to general linear model in particular. Our first general linear model will be single linear regression which puts a line of best fit through data so the response can be predicted from the explanatory variable. We will consider the two ‚Äúparameters‚Äù estimated by the model (the slope and the intercept) and whether these differ from zero",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-7-two-sample-tests",
    "href": "pgt52m/pgt52m.html#week-7-two-sample-tests",
    "title": "52M Data Analysis in R",
    "section": "Week 7: Two-sample tests",
    "text": "Week 7: Two-sample tests\nThis week you will how to use and interpret the general linear model when the x variable is categorical and has two groups. Just as with single linear regression, the model puts a line of best through data and the model parameters, the intercept and the slope, have the same in interpretation The intercept is one of the group means and the slope is the difference between that, mean and the other group mean. You will also learn about the non-parametric equivalents - the tests we use when the assumptions of the general linear model are not met.",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-8-one-way-anova-and-kruskal-wallis",
    "href": "pgt52m/pgt52m.html#week-8-one-way-anova-and-kruskal-wallis",
    "title": "52M Data Analysis in R",
    "section": "Week 8: One-way ANOVA and Kruskal-Wallis",
    "text": "Week 8: One-way ANOVA and Kruskal-Wallis\nLast week you learnt how to use and interpret the general linear model when the x variable was categorical with two groups. You will now extend that to situations when there are more than two groups. This is often known as the one-way ANOVA (analysis of variance). You will also learn about the Kruskal- Wallis test which can be used when the assumptions of the general linear model are not met.",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-9-assessment-intro",
    "href": "pgt52m/pgt52m.html#week-9-assessment-intro",
    "title": "52M Data Analysis in R",
    "section": "Week 9: Assessment intro",
    "text": "Week 9: Assessment intro\nThis week, we will introduce you to the assessment for this module. We will look at a specimen assessment using techniques you have already learned and apply them to analysing a dataset. Your assessment will use a different dataset but you will apply the same principles. We will be covering what your assessment submission should contain using this example.",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-10-reproducible-reporting",
    "href": "pgt52m/pgt52m.html#week-10-reproducible-reporting",
    "title": "52M Data Analysis in R",
    "section": "Week 10: Reproducible Reporting",
    "text": "Week 10: Reproducible Reporting\nFollowing on from last week‚Äôs introduction to the assessment. You will be introduced to quarto, which is a way of generating reproducible reports and you will need for your assessment. This will cover how to embed sections and executable chunks of R code within your quarto files.",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/pgt52m.html#week-11-drop-in",
    "href": "pgt52m/pgt52m.html#week-11-drop-in",
    "title": "52M Data Analysis in R",
    "section": "Week 11: Drop-in",
    "text": "Week 11: Drop-in\nThis session contains no set material however, we will cover topics that people have had difficulty with during the course and cover any material you may still be struggling with from the workshops. This will be our last timetabled session to ask questions prior to the asessment release and a good opportunity to ask any outstanding questions. No questions are silly questions!",
    "crumbs": [
      "PGT 52M",
      "52M Data Analysis in R"
    ]
  },
  {
    "objectID": "pgt52m/week-4/study_after_workshop.html",
    "href": "pgt52m/week-4/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the packages and import the data.\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n\nüíª Summarise and plot the pigeons dataframe appropriately.\n\n\nAnswer - don‚Äôt look until you have tried!# import\npigeons &lt;- read_table(\"data-raw/pigeon.txt\")\n\n# reformat to tidy\npigeons &lt;- pivot_longer(data = pigeons, \n                        cols = everything(), \n                        names_to = \"population\", \n                        values_to = \"distance\")\n\n# sumnmarise\npigeons_summary &lt;- pigeons %&gt;%\n  group_by(population) %&gt;%\n  summarise(mean = mean(distance),\n            std = sd(distance),\n            n = length(distance),\n            se = std/sqrt(n))\n# plot\nggplot() +\n  geom_point(data = pigeons, aes(x = population, y = distance),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"gray50\") +\n  geom_errorbar(data = pigeons_summary, \n                aes(x = population, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = pigeons_summary, \n                aes(x = population, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Interorbital distance (mm)\", \n                     limits = c(0, 14), \n                     expand = c(0, 0)) +\n  scale_x_discrete(name = \"Population\") +\n  theme_classic()\n\n\n\n\nüíª The data in blood.csv are measurements of several blood parameters from fifty people with Crohn‚Äôs disease, a lifelong condition where parts of the digestive system become inflamed. Twenty-five of people are in the early stages of diagnosis and 25 have started treatment. The variables in the dataset are:\n\nsodium - Sodium concentration in umol/L, the average of 5 technical replicates\npotassium - Potassium concentration in umol/L, the average of 5 technical replicates\nB12 Vitamin - B12 in pmol/L, the average of 5 technical replicates\nwbc - White blood cell count in 10^9 /L, the average of 5 technical replicates\nrbc count - Red blood cell count in 10^12 /L, the average of 5 technical replicates\nplatlet count - platlet count in 10^9 /L, the average of 5 technical replicates\ninflammation marker - the presence or absence of a marker of inflammation, either 0 or 1\nstatus - whether the individual is before or after treatment.\n\nYour task is to summarise and plot these data in any suitable way. Create a complete RStudio Project for an analysis of these data. You will need to:\n\nMake a new project\nMake folders for data and for figures\nImport the data\nSummarise and plot variables of your choice. It doesn‚Äôt matter what you chose - the goal is the practice the project workflow and selecting appropriate plotting and summarising methods for particular data sets.",
    "crumbs": [
      "PGT 52M",
      "Week 4: Summarising data with several variables",
      "Consolidate!"
    ]
  },
  {
    "objectID": "pgt52m/week-4/workshop.html",
    "href": "pgt52m/week-4/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Data data Artwork from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst\n\n\nIn this workshop you will learn to summarise and plot datasets with more than one variable and how to write figures to files. You will also get more practice with working directories, importing data, formatting figures and the pipe.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 4: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-4/workshop.html#session-overview",
    "href": "pgt52m/week-4/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will learn to summarise and plot datasets with more than one variable and how to write figures to files. You will also get more practice with working directories, importing data, formatting figures and the pipe.",
    "crumbs": [
      "PGT 52M",
      "Week 4: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-4/workshop.html#philosophy",
    "href": "pgt52m/week-4/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 4: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-4/workshop.html#myoglobin-in-seal-muscle",
    "href": "pgt52m/week-4/workshop.html#myoglobin-in-seal-muscle",
    "title": "Workshop",
    "section": "Myoglobin in seal muscle",
    "text": "Myoglobin in seal muscle\nThe myoglobin concentration of skeletal muscle of three species of seal in grams per kilogram of muscle was determined and the data are given in seal.csv. Each row represents an individual seal. The first column gives the myoglobin concentration and the second column indicates species.\nImport\n Save seal.csv to your data-raw folder\n Read the data into a dataframe called seal. . You might want to look up data import from last week.\n What types of variables do you have in the seal dataframe? What role would you expect them to play in analysis?\n\n\n\n\nThe key point here is that the fundamental structure of:\n\none continuous response and one nominal explanatory variable with two groups (adipocytes), and\none continuous response and one nominal explanatory variable with three groups (seals)\n\nis the same! The only thing that differs is the number of groups (the number of values in the nominal variable). This means the code for summarising and plotting is identical except for the variable names!\n\n\n\n\n\n\nTip\n\n\n\nWhen two datasets have the same number of columns and the response variable and the explanatory variables have the same data types then the code you need is the same.\n\n\nSummarise\nSummarising the data for each species is the next sensible step. The most useful summary statistics for a continuous variable like myoglobin are the means, standard deviations, sample sizes and standard errors. You might remember from last week that we use the group_by() and summarise() functions along with the functions that do the calculations.\n Create a data frame called seal_summary that contains the means, standard deviations, sample sizes and standard errors for the control and nicotinic acid treated samples.\n\nseal_summary &lt;- seal %&gt;%\n  group_by(species) %&gt;%\n  summarise(mean = mean(myoglobin),\n            std = sd(myoglobin),\n            n = length(myoglobin),\n            se = std/sqrt(n))\n\nYou should get the following numbers:\n\n\n\n\nspecies\nmean\nstd\nn\nse\n\n\n\nBladdernose Seal\n42.31600\n8.020634\n30\n1.464361\n\n\nHarbour Seal\n49.01033\n8.252004\n30\n1.506603\n\n\nWeddell Seal\n44.66033\n7.849816\n30\n1.433174\n\n\n\n\n\nVisualise\nMost commonly, we put the explanatory variable on the x axis and the response variable on the y axis. A continuous response, particularly one that follows the normal distribution, is best summarised with the mean and the standard error. In my opinion, you should also show all the raw data points if possible.\nWe are going to create a figure like this:\n\n\n\n\n\n\n\n\nIn this figure, we have the data points themselves which are in seal dataframe and the means and standard errors which are in the seal_summary dataframe. That is, we have two dataframes we want to plot.\nHere you will learn that dataframes and aesthetics can be specified within a geom_xxxx (rather than in the ggplot()). This is very useful if the geom only applies to some of the data you want to plot.\n\n\n\n\n\n\nTip: ggplot()\n\n\n\nYou put the data argument and aes() inside ggplot() if you want all the geoms to use that dataframe and variables. If you want a different dataframe for a geom, put the data argument and aes() inside the geom_xxxx()\n\n\nI will build the plot up in small steps but you should edit your existing ggplot() command as we go.\n Plot the data points first.\n\nggplot() +\n  geom_point(data = seal, \n             aes(x = species, y = myoglobin))\n\n\n\n\n\n\n\nNotice how we have given the data argument and the aesthetics inside the geom. The variables species and myoglobin are in the seal dataframe\n So the data points don‚Äôt overlap, we can add some random jitter in the x direction (edit your existing code):\n\nggplot() +\n  geom_point(data = seal, \n             aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0))\n\n\n\n\n\n\n\nNote that position = position_jitter(width = 0.1, height = 0) is inside the geom_point() parentheses, after the aes() and a comma.\nWe‚Äôve set the vertical jitter to 0 because, in contrast to the categorical x-axis, movement on the y-axis has meaning (the myoglobin levels).\n Let‚Äôs make the points a light grey (edit your existing code):\n\nggplot() +\n  geom_point(data = seal, \n             aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\")\n\n\n\n\n\n\n\nNow to add the errorbars. These go from one standard error below the mean to one standard error above the mean.\n Add a geom_errorbar() for errorbars (edit your existing code):\n\nggplot() +\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) \n\n\n\n\n\n\n\nWe have specified the seal_summary dataframe and the variables species, mean and se are in that.\nThere are several ways you could add the mean. You could use geom_point() but I like to use geom_errorbar() again with the ymin and ymax both set to the mean.\n Add a geom_errorbar() for the mean (edit your existing code):\n\nggplot() +\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean, ymax = mean),\n                width = 0.2)\n\n\n\n\n\n\n\n Alter the axis labels and limits using scale_y_continuous() and scale_x_discrete() (edit your existing code):\n\nggplot() +\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Myoglobin (g/kg)\", \n                     limits = c(0, 80), \n                     expand = c(0, 0)) +\n  scale_x_discrete(name = \"Species\")\n\n\n\n\n\n\n\nYou only need to use scale_y_continuous() and scale_x_discrete() to use labels that are different from those in the dataset. Often this is to use proper terminology and captialisation.\n Format the figure in a way that is more suitable for including in a report using theme_classic() (edit your existing code):\n\nggplot() +\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Myoglobin (g/kg)\", \n                     limits = c(0, 80), \n                     expand = c(0, 0)) +\n   scale_x_discrete(name = \"Species\") +\n  theme_classic()\n\n\n\n\n\n\n\nWriting figures to file\n Make a new folder called figures.\n Edit you ggplot code so that you assign the figure to a variable.\n\nsealfig &lt;- ggplot() +\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Myoglobin (g/kg)\", \n                     limits = c(0, 80), \n                     expand = c(0, 0)) +\n  scale_x_discrete(name = \"Species\") +\n  theme_classic()\n\nThe figure won‚Äôt be shown in the Plots tab - the output has gone into sealfig rather than to the Plots tab. To make it appear in the Plots tab type sealfig\n The ggsave() command will write a ggplot figure to a file:\n\nggsave(\"figures/seal-muscle.png\",\n       plot = sealfig,\n       device = \"png\",\n       width = 4,\n       height = 3,\n       units = \"in\",\n       dpi = 300)\n\nfiguresseal-muscle.png is the name of the file, including the relative path.\n Look up ggsave() in the manual to understand the arguments. You can do this by putting your cursor on the command and pressing F1",
    "crumbs": [
      "PGT 52M",
      "Week 4: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-4/workshop.html#pigeons",
    "href": "pgt52m/week-4/workshop.html#pigeons",
    "title": "Workshop",
    "section": "Pigeons",
    "text": "Pigeons\nThe data in pigeon.txt are 40 measurements of interorbital width (in mm) for two populations of domestic pigeons measured to the nearest 0.1mm\n\n\nInterorbital width is the distance between the eyes\n\nImport\n Save pigeon.txt to your data-raw folder\n Read the data into a dataframe called pigeons.\n What variables are there in the pigeons dataframe?\n\n\n\n\nHummmm, these data are not organised like the other data sets we have used. The population is given as the column names and the interorbital distances for one population are given in a different column than those for the other population. The first row has data from two pigeons which have nothing in common, they just happen to be the first individual recorded in each population.\n\n\n\n\n\nA\nB\n\n\n\n12.4\n12.6\n\n\n11.2\n11.3\n\n\n11.6\n12.1\n\n\n12.3\n12.2\n\n\n11.8\n11.8\n\n\n10.7\n11.5\n\n\n11.3\n11.2\n\n\n11.6\n11.9\n\n\n12.3\n11.2\n\n\n10.5\n12.1\n\n\n12.1\n11.9\n\n\n10.4\n10.7\n\n\n10.8\n11.0\n\n\n11.9\n12.2\n\n\n10.9\n12.6\n\n\n10.8\n11.6\n\n\n10.4\n10.7\n\n\n12.0\n12.4\n\n\n11.7\n11.8\n\n\n11.3\n11.1\n\n\n11.5\n12.9\n\n\n11.8\n11.9\n\n\n10.3\n11.1\n\n\n10.3\n12.2\n\n\n11.5\n11.8\n\n\n10.7\n11.5\n\n\n11.3\n11.2\n\n\n11.6\n11.9\n\n\n13.3\n11.2\n\n\n10.7\n11.1\n\n\n12.1\n11.6\n\n\n10.2\n12.7\n\n\n10.8\n11.0\n\n\n11.4\n12.2\n\n\n10.9\n11.3\n\n\n10.3\n11.6\n\n\n10.4\n12.2\n\n\n10.0\n12.4\n\n\n11.2\n11.3\n\n\n11.3\n11.1\n\n\n\n\n\n\n\nThis data is not in ‚Äòtidy‚Äô format (Wickham 2014).\nTidy format has variables in column and observations in rows. All of the distance measurements should be in one column and a second column should give the population.\n\n\n\n\n\npopulation\ndistance\n\n\n\nA\n12.4\n\n\nB\n12.6\n\n\nA\n11.2\n\n\nB\n11.3\n\n\nA\n11.6\n\n\nB\n12.1\n\n\nA\n12.3\n\n\nB\n12.2\n\n\nA\n11.8\n\n\nB\n11.8\n\n\nA\n10.7\n\n\nB\n11.5\n\n\nA\n11.3\n\n\nB\n11.2\n\n\nA\n11.6\n\n\nB\n11.9\n\n\nA\n12.3\n\n\nB\n11.2\n\n\nA\n10.5\n\n\nB\n12.1\n\n\nA\n12.1\n\n\nB\n11.9\n\n\nA\n10.4\n\n\nB\n10.7\n\n\nA\n10.8\n\n\nB\n11.0\n\n\nA\n11.9\n\n\nB\n12.2\n\n\nA\n10.9\n\n\nB\n12.6\n\n\nA\n10.8\n\n\nB\n11.6\n\n\nA\n10.4\n\n\nB\n10.7\n\n\nA\n12.0\n\n\nB\n12.4\n\n\nA\n11.7\n\n\nB\n11.8\n\n\nA\n11.3\n\n\nB\n11.1\n\n\nA\n11.5\n\n\nB\n12.9\n\n\nA\n11.8\n\n\nB\n11.9\n\n\nA\n10.3\n\n\nB\n11.1\n\n\nA\n10.3\n\n\nB\n12.2\n\n\nA\n11.5\n\n\nB\n11.8\n\n\nA\n10.7\n\n\nB\n11.5\n\n\nA\n11.3\n\n\nB\n11.2\n\n\nA\n11.6\n\n\nB\n11.9\n\n\nA\n13.3\n\n\nB\n11.2\n\n\nA\n10.7\n\n\nB\n11.1\n\n\nA\n12.1\n\n\nB\n11.6\n\n\nA\n10.2\n\n\nB\n12.7\n\n\nA\n10.8\n\n\nB\n11.0\n\n\nA\n11.4\n\n\nB\n12.2\n\n\nA\n10.9\n\n\nB\n11.3\n\n\nA\n10.3\n\n\nB\n11.6\n\n\nA\n10.4\n\n\nB\n12.2\n\n\nA\n10.0\n\n\nB\n12.4\n\n\nA\n11.2\n\n\nB\n11.3\n\n\nA\n11.3\n\n\nB\n11.1\n\n\n\n\n\n\n\nData which is in tidy format is easier to summarise, analyses and plot because the organisation matches the conceptual structure of the data:\n\nit is more obvious what the variables are because they columns are named with them - in the untidy format, that the measures are distances is not clear and what A and B are isn‚Äôt clear\nit is more obvious that there is no relationship between any of the pigeons except for population\nfunctions are designed to work with variables in columns\nTidying data\nWe can put this data in such a format with the pivot_longer() function from the tidyverse:\npivot_longer() collects the values from specified columns (cols) into a single column (values_to) and creates a column to indicate the group (names_to).\n Put the data in tidy format:\n\npigeons &lt;- pivot_longer(data = pigeons, \n                        cols = everything(), \n                        names_to = \"population\", \n                        values_to = \"distance\")\n\nWe have overwritten the original dataframe. If you wanted to keep the original you would need to give a new name on the left side of the assignment &lt;- Note: the data in the file are unchanged.",
    "crumbs": [
      "PGT 52M",
      "Week 4: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-4/workshop.html#ulna-and-height",
    "href": "pgt52m/week-4/workshop.html#ulna-and-height",
    "title": "Workshop",
    "section": "Ulna and height",
    "text": "Ulna and height\nThe datasets we have used up to this point, have had a continuous variable and a categorical variable where it makes sense to summarise the response for each of the different groups in the categorical variable and plot the response on the y-axis. We will now summarise a dataset with two continuous variables. The data in height.txt are the ulna length (cm) and height (m) of 30 people. In this case, it is more appropriate to summarise both of thee variables and to plot them as a scatter plot.\nWe will use summarise() again but we do not need the group_by() function this time. We will also need to use each of the summary functions, such as mean(), twice, once for each variable.\nImport\n Save height.txt to your data-raw folder\n Read the data into a dataframe called ulna_heights.\nSummarise\n Create a data frame called ulna_heights_summary that contains the sample size and means, standard deviations and standard errors for both variables.\n\nulna_heights_summary &lt;- ulna_heights %&gt;%\n  summarise(n = length(ulna),\n            mean_ulna = mean(ulna),\n            std_ulna = sd(ulna),\n            se_ulna = std_ulna/sqrt(n),\n            mean_height = mean(height),\n            std_height = sd(height),\n            se_height = std_height/sqrt(n))\n\nYou should get the following numbers:\n\n\n\n\nn\nmean_ulna\nstd_ulna\nse_ulna\nmean_height\nstd_height\nse_height\n\n\n30\n24.72\n4.137332\n0.75537\n1.494\n0.2404823\n0.0439059\n\n\n\n\nVisualise\nTo plot make a scatter plot we need to use geom_point() again but without any scatter. In this case, it does not really matter which variable is on the x-axis and which is on the y-axis.\n Make a simple scatter plot\n\nggplot(data = ulna_heights, aes(x = ulna, y = height)) +\n  geom_point()\n\n\n\n\n\n\n\nIf you have time, you may want to format the figure more appropriately.\n\n\nYou‚Äôre finished!",
    "crumbs": [
      "PGT 52M",
      "Week 4: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/study_after_workshop.html",
    "href": "pgt52m/week-2/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª In a maternity hospital, the total numbers of births induced on each day of the week over a six week period were recorded (see table below). Create a plot of these data with the days of week in order.\n\n\n\n\nNumber of inductions for each day of the week over six weeks.\n\nDay\nNo. inductions\n\n\n\nMonday\n43\n\n\nTuesday\n36\n\n\nWednesday\n35\n\n\nThursday\n38\n\n\nFriday\n48\n\n\nSaturday\n26\n\n\nSunday\n24\n\n\n\n\n\n\nAnswer - don‚Äôt look until you have tried!# create a dataframe for the data\nday &lt;- c(\"Monday\", \n         \"Tuesday\", \n         \"Wednesday\",\n         \"Thursday\",\n         \"Friday\",\n         \"Saturday\",\n         \"Sunday\")\nfreq &lt;- c(43, 36, 35, 38, 48, 26, 24) \ninductions &lt;- data.frame(day, freq)\n\n# make the order of the days correct rather than alphabetical\ninductions &lt;- inductions |&gt; \n  mutate(day = fct_relevel(day, c(\"Monday\",\n                                  \"Tuesday\",\n                                  \"Wednesday\",\n                                  \"Thursday\",\n                                  \"Friday\",\n                                  \"Saturday\",\n                                  \"Sunday\")))\n\n# plot the data as a barplot with the bars in\nggplot(data = inductions, \n       aes(x = day, y = freq)) +\n  geom_col(colour = \"black\",\n           fill = \"lightseagreen\") +\n  scale_x_discrete(expand = c(0, 0),\n                   name = \"Day of the week\") + \n  scale_y_continuous(expand = c(0, 0),\n                     name = \"Number of inductions\",\n                     limits = c(0, 55)) +\n  theme_classic()\n\n\n\nüìñ Read Workflow in RStudio",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Consolidate!"
    ]
  },
  {
    "objectID": "pgt52m/week-2/study_before_workshop.html",
    "href": "pgt52m/week-2/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "Either\n\nüìñ Read First Steps in RStudio in\n\nOR\n\nüìπ Watch",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Prepare!"
    ]
  },
  {
    "objectID": "pgt52m/week-8/overview.html",
    "href": "pgt52m/week-8/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Last week you learnt how to use and interpret the general linear model when the x variable was categorical with two groups. You will now extend that to situations when there are more than two groups. This is often known as the one-way ANOVA (analysis of variance). You will also learn about the Kruskal- Wallis test which can be used when the assumptions of the general linear model are not met.\n\nLearning objectives\nThe successful student will be able to:\n\nexplain the rationale behind ANOVA understand the meaning of the F values\nselect, appropriately, one-way ANOVA and Kruskal-Wallis\nknow what functions are used in R to run these tests and how to interpret them\nevaluate whether the assumptions of lm() are met\nscientifically report the results of these tests including appropriate figures\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read One-way ANOVA and Kruskal-Wallis\n\nWorkshop\n\nüíª One-way ANOVA\nüíª Kruskal-Wallis\n\nConsolidate\n\nüíª Appropriately test if fitness and acclimation effect the sodium content of sweat\nüíª Appropriately test if insecticides vary in their effectiveness",
    "crumbs": [
      "PGT 52M",
      "Week 8: One-way ANOVA and Kruskal-Wallis",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-8/study_before_workshop.html",
    "href": "pgt52m/week-8/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "Prepare\n\nüìñ Read One-way ANOVA and Kruskal-Wallis",
    "crumbs": [
      "PGT 52M",
      "Week 8: One-way ANOVA and Kruskal-Wallis",
      "Prepare!"
    ]
  },
  {
    "objectID": "pgt52m/week-9/overview.html",
    "href": "pgt52m/week-9/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week we will be looking at the assessment for this module and introducing you to a specimen sample of the assessment so that you can familiarise yourself with the format and what we are expecting you to produce. We will be looking at a Rproject containing a quarto markdown file and a report results section. We will also look at the marking criteria. This material can also be found on the VLE under the module assessment marking criteria section. Next week we will cover how to reproduce a quarto markdown file yourself in more detail.\n\nLearning objectives\nThe successful student will be able to:\n\nUnderstand the structure of the Rproject we will be expecting you to produce in the assessment (e.g.¬†segregated into data-raw, figures etc).\nUnderstand the marking criteria so you understand how the assessment is going to be evaluated e.g.¬†one aspect we will be looking at is whether the code within the quarto markdown generates the plots included within the report.\nKnow where to look on the VLE for additional assessment information\nKnow the appropriate dates for the release and submisison of the assessment.\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read the marking criteria available on the VLE\n\nWorkshop\n\nüíª Explore the specimen Rproject\n\nConsolidate\n\nüìñ Refamiliarise yourself with how Rprojects work",
    "crumbs": [
      "PGT 52M",
      "Week 9: Introduction to the Assessment",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-9/study_before_workshop.html",
    "href": "pgt52m/week-9/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "Prepare\n\nüìñ Read Marking criteria for module assessment",
    "crumbs": [
      "PGT 52M",
      "Week 9: Introduction to the Assessment",
      "Prepare!"
    ]
  },
  {
    "objectID": "pgt52m/week-1/overview.html",
    "href": "pgt52m/week-1/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week you will carry out some independent study to ensure you have some understanding of computer file systems. We will introduce you to the concepts of paths and working directories.\n\n\n\nArtwork by Horst (2023): ‚Äúcode gets the blame‚Äù\n\n\n\nLearning objectives\nThe parentheses after each learning objective indicate where the content covers that objective.\nThe successful student will be able to:\n\nexplain what an operating system is\nexplain the organisation of files and directories in a file systems\nexplain what a file is and give some common files types\nexplain what is meant by a plain text file\nexplain the relationship between the file extensions, the file format and associations with programs\nuse a file manager\nexplain root, home and working directories\nexplain absolute and relative file paths\nknow what R and RStudio are\nknow how to organise their work\n\n\n\nInstructions\n\nPrepare\n\nWatch an Introduction to Data Analysis in R for BABS 1 - 4\nRead What they forgot to teach you about computers\nRead What are R and Rstudio?\n\nWorkshop\n\nOptional: Install R and RStudio\n\nConsolidate\n\n\n\n\n\n\nReferences\n\nHorst, Allison. 2023. ‚ÄúData Science Illustrations.‚Äù https://allisonhorst.com/allison-horst.",
    "crumbs": [
      "PGT 52M",
      "Week 1: Understanding file systems",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-1/study_before_workshop.html",
    "href": "pgt52m/week-1/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "Watch an Introduction to Data Analysis in R for BABS 1 - 4\nRead What they forgot to teach you about computers in Computational Analysis for Bioscientists\nRead What are R and Rstudio?. You only need to read this section, you do not need to the read the rest of the chapter (yet!)",
    "crumbs": [
      "PGT 52M",
      "Week 1: Understanding file systems",
      "Prepare!"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis in R",
    "section": "",
    "text": "Data Analysis in R helps you analyse data but also to understand the literature, design experiments and report the results.\n\n\nReproducible data management, handling, wrangling, modelling and visualisation underpin both the scientific process and many of the most in-demand hard skills.\n\n\n\nPart of the reason that these skills are in-demand is that they take time and practice in the same way that playing an instrument, speaking another language or playing a sport do. They are skills you develop rather than facts you memorise. You will make a lot of mistakes.\n\n\n\nThere is a lot of problem solving which is enaging work because there‚Äôs always something to ‚Äòchase‚Äô. You may be able to concentrate on coding for much longer than on writing or reading because it is such an active learning process. You‚Äôll create impressive looking figures, which you can reproduce on a different dataset in moments, exciting biological insights revealed in a test and whole world of ‚Äòtechy‚Äô tricks you had no idea you‚Äôd be able to do!\nThe time and effort you put in to learning ‚ÄúData Analysis in R‚Äù WILL reward you no matter how you evaluate yourself relative to others. You will be able to:\n\nbetter and/or more quickly design and analyse scientific investigations for modules and projects in which in turn will allow you to perform better in assessments.\nevaluate and interpret the data analysis in papers\naccess a wide range of careers\n\n\n\n\nAll the Data Analysis in R teaching is on the VLE so why is this site useful? Well, perhaps more than any other material, you will want to refer back when applying your skills throughout your degree and this site collects everything together in a searchable way. The search icon is on the top right."
  },
  {
    "objectID": "index.html#learning-data-analysis-is-important",
    "href": "index.html#learning-data-analysis-is-important",
    "title": "Data Analysis in R",
    "section": "",
    "text": "Reproducible data management, handling, wrangling, modelling and visualisation underpin both the scientific process and many of the most in-demand hard skills."
  },
  {
    "objectID": "index.html#and-takes-time",
    "href": "index.html#and-takes-time",
    "title": "Data Analysis in R",
    "section": "",
    "text": "Part of the reason that these skills are in-demand is that they take time and practice in the same way that playing an instrument, speaking another language or playing a sport do. They are skills you develop rather than facts you memorise. You will make a lot of mistakes."
  },
  {
    "objectID": "index.html#but-can-be-great-fun",
    "href": "index.html#but-can-be-great-fun",
    "title": "Data Analysis in R",
    "section": "",
    "text": "There is a lot of problem solving which is enaging work because there‚Äôs always something to ‚Äòchase‚Äô. You may be able to concentrate on coding for much longer than on writing or reading because it is such an active learning process. You‚Äôll create impressive looking figures, which you can reproduce on a different dataset in moments, exciting biological insights revealed in a test and whole world of ‚Äòtechy‚Äô tricks you had no idea you‚Äôd be able to do!\nThe time and effort you put in to learning ‚ÄúData Analysis in R‚Äù WILL reward you no matter how you evaluate yourself relative to others. You will be able to:\n\nbetter and/or more quickly design and analyse scientific investigations for modules and projects in which in turn will allow you to perform better in assessments.\nevaluate and interpret the data analysis in papers\naccess a wide range of careers"
  },
  {
    "objectID": "index.html#what-is-this-site-for",
    "href": "index.html#what-is-this-site-for",
    "title": "Data Analysis in R",
    "section": "",
    "text": "All the Data Analysis in R teaching is on the VLE so why is this site useful? Well, perhaps more than any other material, you will want to refer back when applying your skills throughout your degree and this site collects everything together in a searchable way. The search icon is on the top right."
  },
  {
    "objectID": "r4babs4/week-6/study_after_workshop.html",
    "href": "r4babs4/week-6/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª\n\n\nüìñ Read xxx",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs4/week-6/workshop.html",
    "href": "r4babs4/week-6/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop learn how to create density plots to visualise the distribution and gating of the signals and calculate the the percentage of cells in each quadrant of a quadrant gated plot of TNFa_APC_Lin signal against the E_coli_FITC_Lin signal. You will also grow your knowledge of ggplot annotation and data import from googlesheet.",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-6/workshop.html#add-your-data",
    "href": "r4babs4/week-6/workshop.html#add-your-data",
    "title": "Workshop",
    "section": "Add your data",
    "text": "Add your data\nEnter these in the BIO00066I Biomedical Sciences class data\nThe columns you must add are:\n\napc_mfi: Mean fluorescence intensity of the logicle transformed TNFa_APC_Lin in the TNF-Œ± positive cells\nperc_tfna_pos: % non debris cells that are TNF-Œ± positive cells\n\nThe other columns are calculations you make along the way and may help you get to the apc_mfi and perc_tfna_pos values.\nThe column names are the same as those used in the Data Analysis 2: Biomedical sciences - Sample data analysis workshop.",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-6/workshop.html#set-up",
    "href": "r4babs4/week-6/workshop.html#set-up",
    "title": "Workshop",
    "section": "Set up",
    "text": "Set up\nüé¨ Open the RStudio project you created in the Data Analysis 2: Biomedical sciences - Sample data analysis workshop.\nüé¨ Create a new script called data-presentation.R\nüé¨ Load packages:\n\nlibrary(tidyverse)\n\nüé¨ Save a copy of live_labelled.csv to your data-processed folder. These cells have been AI cleaned, gated to remove debris and dead cells, and labelled as positive or negative for the E_coli_FITC_Lin and TNFa_APC_Lin signals1.\nüé¨ Import the data:\n\nclean_trans_nondebris &lt;- read_csv(\"data-processed/live_labelled.csv\")\n\nüé¨ I‚Äôm also going to select only columns I need to keep my life simple:\n\nclean_trans_nondebris &lt;- clean_trans_nondebris |&gt; \n  select(FS_Lin,\n         SS_Lin,\n         E_coli_FITC_Lin,\n         TNFa_APC_Lin,\n         antibody,\n         treatment,\n         tnfa,\n         fitc)\n\nThese are the forward and side scatter, the two logicle-transformed signals the groups (treatment and antibody) and whether the cell is positive or negative for each of the signals.\nüé¨ Click on the data frame in the environment window to view it and make sure you have an understanding of the data.\n\n\n\n\n\nFS_Lin\nSS_Lin\nE_coli_FITC_Lin\nTNFa_APC_Lin\nantibody\ntreatment\ntnfa\nfitc\n\n\n\n27304\n21432\n2.573944\n1.797574\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n\n\n16437\n18261\n3.303969\n1.553092\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n\n\n23356\n20257\n3.024955\n1.432302\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n\n\n20567\n19949\n1.665994\n1.602869\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC -'ve\n\n\n31556\n24441\n3.363674\n1.674940\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n\n\n25858\n18398\n1.592289\n1.469350\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC -'ve\n\n\n25512\n11655\n1.592289\n1.535148\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC -'ve\n\n\n26949\n18936\n3.629136\n1.762831\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n\n\n22715\n24400\n3.345617\n1.810729\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n\n\n29398\n21824\n3.687067\n1.688024\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n\n\n\n\n\n\n\nüé¨ Use fct_relevel() to put treatment groups in order so that our graphs are better to interpret.\n\nclean_trans_nondebris &lt;- clean_trans_nondebris |&gt; \n  mutate(treatment = fct_relevel(treatment, c(\"MEDIA\",\n                                              \"LPS\",\n                                              \"ECOLIGreen\")))\n\nWe need to calculate some summary information such as the percent of TNF-Œ± positive cells in each sample and the mean fluorescence intensity of the TNFa_APC_Lin signal in the TNF-Œ± positive cells. If you especially hate R but are familiar with pivot tables in Excel, then you could use that‚Ä¶.. but it would not be as reproducible as using R and tidyverse functions.\nüé¨ Calculate the number of cells in each sample:\n\n# number of cells in each sample after gating\nclean_trans_nondebris_n &lt;-  clean_trans_nondebris |&gt; \n  group_by(antibody, treatment) |&gt; \n  summarise(n_nondebris = n()) \n\nüé¨ Click on the dataframe in the environment window to view it and make sure you have an understanding of the summary.\n\n\n\n\n\nantibody\ntreatment\nn_nondebris\n\n\n\nISOTYPE\nMEDIA\n13106\n\n\nISOTYPE\nLPS\n45138\n\n\nISOTYPE\nECOLIGreen\n26866\n\n\nTNFAPC\nMEDIA\n24419\n\n\nTNFAPC\nLPS\n25479\n\n\nTNFAPC\nECOLIGreen\n26002\n\n\n\n\n\n\n\nüé¨ Calculate the number of TNF-Œ± positive cells in each sample and the mean fluorescence intensity of the TNFa_APC_Lin signal in the TNF-Œ± positive cells:\n\n## summarise the number of TNF-Œ± +'ve cells in each sample  \nclean_trans_nondebris_tfna_pos &lt;- clean_trans_nondebris |&gt; \n  filter(tnfa == \"TNF-Œ± +'ve\") |&gt;\n  group_by(antibody, treatment) |&gt;\n  summarise(n_pos_tnfa = n(),\n            mean_apc = round(mean(TNFa_APC_Lin), 2))\n\nüé¨ Click on the dataframe in the environment window to view it and make sure you have an understanding of the summary.\n\n\n\n\n\nantibody\ntreatment\nn_pos_tnfa\nmean_apc\n\n\n\nISOTYPE\nMEDIA\n11\n2.14\n\n\nISOTYPE\nLPS\n24\n2.15\n\n\nISOTYPE\nECOLIGreen\n23\n2.14\n\n\nTNFAPC\nMEDIA\n13503\n2.26\n\n\nTNFAPC\nLPS\n25414\n3.14\n\n\nTNFAPC\nECOLIGreen\n25965\n3.27\n\n\n\n\n\n\n\nNote: If your dataframe has 0 rows first check you have written ‚ÄúTNF-Œ± +‚Äôve‚Äù correctly in the filter function (other no rows will match). If you have written it correctly, and you are working on your own machine, you may have different character encoding. The simplest solution: is to repeat the step in workshop 2\n\nis to repeat the step in workshop 2 ‚ÄúAdd a label, tnfa, to the data to indicate if the cell is positive or negative for TNF-Œ±‚Äù by using TNF-a rather than TNF-Œ± in the labelling\nmake sure you resave the data (‚Äúdata-processed/live_labelled.csv‚Äù) after that step\nmake sure you edit the code in this workshop to reflect the change in the label\n\nIn order to calculate the percentage of cells that are TNF-Œ± positive, we need to join the two summaries together and add a column using mutate().\nüé¨ Join the summary of the total number of cells in each sample with the summary of the number of TNF-Œ± positive cells in each sample and calculate the percentage of cells that are TNF-Œ± positive:\n\n## join the summary with the summary of the number of cells in each sample\n## and calculate the percentage of cells that are TNF-Œ± +'ve\nclean_trans_nondebris_tfna_pos &lt;- \n  clean_trans_nondebris_tfna_pos |&gt; \n  left_join(clean_trans_nondebris_n, by = c(\"antibody\", \"treatment\")) |&gt; \n  mutate(perc_tfna_pos = round(n_pos_tnfa/n_nondebris * 100, 1) )\n\nüé¨ Click on the dataframe in the environment window to view it and make sure you have an understanding of the summary.\n\n\n\n\n\nantibody\ntreatment\nn_pos_tnfa\nmean_apc\nn_nondebris\nperc_tfna_pos\n\n\n\nISOTYPE\nMEDIA\n11\n2.14\n13106\n0.1\n\n\nISOTYPE\nLPS\n24\n2.15\n45138\n0.1\n\n\nISOTYPE\nECOLIGreen\n23\n2.14\n26866\n0.1\n\n\nTNFAPC\nMEDIA\n13503\n2.26\n24419\n55.3\n\n\nTNFAPC\nLPS\n25414\n3.14\n25479\n99.7\n\n\nTNFAPC\nECOLIGreen\n25965\n3.27\n26002\n99.9\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip for your own summaries\n\n\n\nYou can use the same process calculate the percentage of cells that are FITC positive in each sample and the mean fluorescence intensity of the FITC signal in the FITC positive cells.",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-6/workshop.html#distribution-of-apc-tnf-Œ±-signal-with-gate",
    "href": "r4babs4/week-6/workshop.html#distribution-of-apc-tnf-Œ±-signal-with-gate",
    "title": "Workshop",
    "section": "Distribution of APC TNF-Œ± signal with gate",
    "text": "Distribution of APC TNF-Œ± signal with gate\nTo annotate the distribution of APC TNF-Œ± signal with the gate used to define whether the cells are positive or negative for TNF-Œ± it is useful to assign that value to a variable that we can use in our plots. We will do the FITC gate value at the same time2.\nüé¨ Assign the gate values to variables:\n\napc_cut &lt;- 2\nfitc_cut &lt;- 2\n\nPlot one sample\nThe pipe (|&gt;) allows us to filter the data before plotting it which allows select the sample we want to plot.\nüé¨ Plot the distribution of the APC TNF-Œ± signal for the MEDIA treatment and the ISOTYPE antibody:\n\nclean_trans_nondebris |&gt; \n    filter(treatment == \"MEDIA\",\n           antibody == \"ISOTYPE\") |&gt;\n  ggplot(aes(x = TNFa_APC_Lin)) +\n  geom_density(fill = \"gray80\") +\n  geom_vline(xintercept = apc_cut, \n             color = \"red\") +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 2.5),\n                     name = \"Density\") +\n  scale_x_continuous(name = \"Logicle transformed APC TNF-Œ± signal\") +\n  theme_bw()\n\n\n\n\n\n\n\n\ngeom_vline() adds a vertical line to the plot at the value of apc_cut which is the gate value we determined for the APC TNF-Œ± signal.\ngeom_density() is a smoothed version of a histogram and shows the distribution of the data. The fill argument sets the colour of the plot to a light grey.\nthe expand argument in a scale_x_.... or scale_y_.... sets the axis line at zero rather than being below it.\n\nPlot annotation\nYou have (at least) three options for adding the summary statistics to the plot.\n\n\nMost simple: adding in word/googledocs (or whatever you write your report in).\nSave the plot using ggsave(), insert as an image into your report and a text box.\n\nIn R by hard coding the values in the geom_text() function.\n\n\nclean_trans_nondebris |&gt; \n  filter(treatment == \"MEDIA\",\n         antibody == \"ISOTYPE\") |&gt;\n  ggplot(aes(x = TNFa_APC_Lin)) +\n  geom_density(fill = \"gray80\") +\n  geom_vline(xintercept = apc_cut, \n             color = \"red\") +\n  geom_text(label = \"0.1 % cells\\nTNF-Œ± +'ve\\nMFI = 2.14\",\n            x = 1.6,\n            y = 2.2,\n            colour = \"red\") +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 2.5),\n                     name = \"Density\") +\n  scale_x_continuous(name = \"Logicle transformed APC TNF-Œ± signal\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nIn R and fully reproducibly by using the clean_trans_nondebris_tfna_pos dataframe with the summary statistics in geom_text(). That dataframe also needs filtering to the sample you are plotting.\n\n\nclean_trans_nondebris |&gt; \n  filter(treatment == \"MEDIA\",\n         antibody == \"ISOTYPE\") |&gt;\n  ggplot(aes(x = TNFa_APC_Lin)) +\n  geom_density(fill = \"gray80\") +\n  geom_vline(xintercept = apc_cut, \n             color = \"red\") +\n   geom_text(data = clean_trans_nondebris_tfna_pos |&gt; \n              filter(treatment == \"MEDIA\",\n                     antibody == \"ISOTYPE\"), \n             aes(label = paste0(perc_tfna_pos, \n                                \"% cells\\nTNF-Œ± +'ve\\nMFI = \",\n                                mean_apc)), \n             x = 1.7, \n             y = 2.1,\n             colour = \"red\") +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 2.5),\n                     name = \"Density\") +\n  scale_x_continuous(name = \"Logicle transformed APC TNF-Œ± signal\") +\n  theme_bw()\n\n\n\n\n\n\n\nThis has several advantages:\n\nif the data changes, the plot annotation will update automatically just as the distribution will.\nextending to multiple facets requires little extra work.\nWrite to file\nüé¨ Assign the plot to apc_distibution_media_isotype\n\napc_distibution_media_isotype &lt;- clean_trans_nondebris |&gt; \n  filter(treatment == \"MEDIA\",\n         antibody == \"ISOTYPE\") |&gt;\n  ggplot(aes(x = TNFa_APC_Lin)) +\n  geom_density(fill = \"gray80\") +\n  geom_vline(xintercept = apc_cut, \n             color = \"red\") +\n   geom_text(data = clean_trans_nondebris_tfna_pos |&gt; \n              filter(treatment == \"MEDIA\",\n                     antibody == \"ISOTYPE\"), \n             aes(label = paste0(perc_tfna_pos, \n                                \"% cells\\nTNF-Œ± +'ve\\nMFI = \",\n                                mean_apc)), \n             x = 1.7, \n             y = 2.1,\n             colour = \"red\") +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 2.5),\n                     name = \"Density\") +\n  scale_x_continuous(name = \"Logicle transformed APC TNF-Œ± signal\") +\n  theme_bw()\n\nüé¨ Save the plot to a file:\n\nggsave(\"figures/apc_distibution_media_isotype.png\",\n       device = \"png\",\n       plot = apc_distibution_media_isotype,\n       width = 4,\n       height = 2.5,\n       units = \"in\",\n       dpi = 300)\n\nMultiple facets\nTo plot all the samples in one go we can use facet_grid(). treatment ~ antibody puts the treatments in rows and the antibodies in columns. Of course, we now don‚Äôt need to filter the data to a single sample.\nüé¨ Plot the distribution of the APC TNF-Œ± signal for all samples:\n\nclean_trans_nondebris |&gt; \n  ggplot(aes(x = TNFa_APC_Lin)) +\n  geom_density(fill = \"gray80\") +\n  geom_vline(xintercept = apc_cut, \n             color = \"red\") +\n   geom_text(data = clean_trans_nondebris_tfna_pos, \n             aes(label = paste0(perc_tfna_pos, \n                                \"% cells\\nTNF-Œ± +'ve\\nMFI = \",\n                                mean_apc)), \n             x = 4, \n             y = 1.8,\n             colour = \"red\") +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 2.5),\n                     name = \"Density\") +\n  scale_x_continuous(name = \"Logicle transformed APC TNF-Œ± signal\") +\n  facet_grid(treatment ~ antibody) +\n  theme_bw()\n\n\n\n\n\n\n\nNote that adding plot annotations manually (method 1) and using R fully reproducibly (method 3) are possible on faceted plots but method 2 is not because you need the annotations to change with values in treatment and antibody.\n\n\n\n\n\n\nTip for your own plots\n\n\n\nYou can combine filtering data and faceted plots to do facet plots of a subset of the samples.\n\n\nOverlay instead of facets\nUsing facets is one way to show multiple samples in one plot. Another way is to overlay the plots by mapping the fill aesthetic to the antibody variable. Making the fill semi-transparent with alpha = 0.3 allows you to see the overlap of the distributions.\nüé¨ Overlay the distribution of the APC TNF-Œ± signals for the media treated samples:\n\nclean_trans_nondebris |&gt; \n   filter(treatment == \"MEDIA\") |&gt;\n   ggplot(aes(x = TNFa_APC_Lin, fill = antibody)) +\n   geom_density(alpha = 0.3) +\n   geom_vline(xintercept = apc_cut, \n              color = \"red\") +\n   scale_y_continuous(expand = c(0, 0),\n                      limits = c(0, 2.5)) +\n   scale_x_continuous(name = \"Logicle transformed APC TNF-Œ± signal\") +\n   theme_bw() \n\n\n\n\n\n\n\nTo change the colours we need to used a scale_fill_... function. These functions can also be used to change the name (name = ...) of the legend and the names (labels = c(...)) of each group. scale_fill_manual() allows to specify the colours (values = c(...)) manually.\nInstead of picking colours, I like to use the viridis scales. The viridis scales provide colour maps that are perceptually uniform in both colour and black-and-white. They are also designed to be perceived by viewers with common forms of colour blindness. See Introduction to viridis for more information.\nHere I use scale_fill_viridis_d(). The d stands for discrete. The function scale_fill_viridis_c() would be used for continuous data. I‚Äôve used the default ‚Äúviridis‚Äù (or ‚ÄúD‚Äù) option (do ?scale_fill_viridis_d for all the options) and got rid of the ‚Äúantibody‚Äù name. I also moved the legend.\n\nclean_trans_nondebris |&gt; \n   filter(treatment == \"MEDIA\") |&gt;\n   ggplot(aes(x = TNFa_APC_Lin, fill = antibody)) +\n   geom_density(alpha = 0.3) +\n   geom_vline(xintercept = apc_cut, \n              color = \"red\") +\n   scale_fill_viridis_d(name = NULL) +\n   scale_y_continuous(expand = c(0, 0),\n                      limits = c(0, 2.5)) +\n   scale_x_continuous(name = \"Logicle transformed APC TNF-Œ± signal\") +\n   theme_bw() +\n   theme(legend.position = c(0.85, 0.85))",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-6/workshop.html#percentage-of-cells-in-each-quadrant",
    "href": "r4babs4/week-6/workshop.html#percentage-of-cells-in-each-quadrant",
    "title": "Workshop",
    "section": "Percentage of cells in each quadrant",
    "text": "Percentage of cells in each quadrant\nWe want to calculate the the percentage of cells in each quadrant of a quadrant gated plot of TNFa_APC_Lin signal against the E_coli_FITC_Lin signal.\nüé¨ Calculate the number of cells in each quadrant for each sample:\n\n## calculate the number of cells in each quadrant\nall_combin_n &lt;- clean_trans_nondebris |&gt; \n  group_by(antibody, treatment, tnfa, fitc) |&gt;\n  summarise(n = n()) \n\nüé¨ Click on the data frame in the environment window to view it and make sure you have an understanding of the data.\n\n\n\n\n\nantibody\ntreatment\ntnfa\nfitc\nn\n\n\n\nISOTYPE\nMEDIA\nTNF-Œ± +'ve\nFITC -'ve\n11\n\n\nISOTYPE\nMEDIA\nTNF-Œ± -'ve\nFITC +'ve\n4\n\n\nISOTYPE\nMEDIA\nTNF-Œ± -'ve\nFITC -'ve\n13091\n\n\nISOTYPE\nLPS\nTNF-Œ± +'ve\nFITC +'ve\n1\n\n\nISOTYPE\nLPS\nTNF-Œ± +'ve\nFITC -'ve\n23\n\n\nISOTYPE\nLPS\nTNF-Œ± -'ve\nFITC +'ve\n5\n\n\nISOTYPE\nLPS\nTNF-Œ± -'ve\nFITC -'ve\n45109\n\n\nISOTYPE\nECOLIGreen\nTNF-Œ± +'ve\nFITC +'ve\n18\n\n\nISOTYPE\nECOLIGreen\nTNF-Œ± +'ve\nFITC -'ve\n5\n\n\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n15457\n\n\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC -'ve\n11386\n\n\nTNFAPC\nMEDIA\nTNF-Œ± +'ve\nFITC +'ve\n20\n\n\nTNFAPC\nMEDIA\nTNF-Œ± +'ve\nFITC -'ve\n13483\n\n\nTNFAPC\nMEDIA\nTNF-Œ± -'ve\nFITC +'ve\n2\n\n\nTNFAPC\nMEDIA\nTNF-Œ± -'ve\nFITC -'ve\n10914\n\n\nTNFAPC\nLPS\nTNF-Œ± +'ve\nFITC +'ve\n13\n\n\nTNFAPC\nLPS\nTNF-Œ± +'ve\nFITC -'ve\n25401\n\n\nTNFAPC\nLPS\nTNF-Œ± -'ve\nFITC +'ve\n1\n\n\nTNFAPC\nLPS\nTNF-Œ± -'ve\nFITC -'ve\n64\n\n\nTNFAPC\nECOLIGreen\nTNF-Œ± +'ve\nFITC +'ve\n14969\n\n\nTNFAPC\nECOLIGreen\nTNF-Œ± +'ve\nFITC -'ve\n10996\n\n\nTNFAPC\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n29\n\n\nTNFAPC\nECOLIGreen\nTNF-Œ± -'ve\nFITC -'ve\n8\n\n\n\n\n\n\n\nAs there are four quadrants and six samples, you would expect 24 rows in the data frame. However, there are only 23 rows. This is because there are no cells in the quadrant where both cells are positive for both TNF-Œ± and FITC for the ISOTYOPE antibody and MEDIA treated samples. Since we are probably happy not to annotate a figure with 0 %, this is fine.\nTo calculate the percentage of cells in each quadrant, we need to join this dataframe with the number of non-debris cells for each sample, i.e., clean_trans_nondebris_n\nüé¨ Calculate the percentage of cells in each quadrant for each sample:\n\nall_combin_perc &lt;- all_combin_n |&gt; \n  left_join(clean_trans_nondebris_n, \n            by = c(\"antibody\", \"treatment\")) |&gt; \n  mutate(perc = round(n / n_nondebris * 100, 1)) |&gt; \n  filter(perc &gt; 0)\n\nI have additionally filtered out rows where the % cells rounds to 0. This is again because we are probably happy not to annotate a figure with 0 %.\nüé¨ Click on the data frame in the environment window to view it and make sure you have an understanding of the data.\n\n\n\n\n\nantibody\ntreatment\ntnfa\nfitc\nn\nn_nondebris\nperc\n\n\n\nISOTYPE\nMEDIA\nTNF-Œ± +'ve\nFITC -'ve\n11\n13106\n0.1\n\n\nISOTYPE\nMEDIA\nTNF-Œ± -'ve\nFITC -'ve\n13091\n13106\n99.9\n\n\nISOTYPE\nLPS\nTNF-Œ± +'ve\nFITC -'ve\n23\n45138\n0.1\n\n\nISOTYPE\nLPS\nTNF-Œ± -'ve\nFITC -'ve\n45109\n45138\n99.9\n\n\nISOTYPE\nECOLIGreen\nTNF-Œ± +'ve\nFITC +'ve\n18\n26866\n0.1\n\n\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n15457\n26866\n57.5\n\n\nISOTYPE\nECOLIGreen\nTNF-Œ± -'ve\nFITC -'ve\n11386\n26866\n42.4\n\n\nTNFAPC\nMEDIA\nTNF-Œ± +'ve\nFITC +'ve\n20\n24419\n0.1\n\n\nTNFAPC\nMEDIA\nTNF-Œ± +'ve\nFITC -'ve\n13483\n24419\n55.2\n\n\nTNFAPC\nMEDIA\nTNF-Œ± -'ve\nFITC -'ve\n10914\n24419\n44.7\n\n\nTNFAPC\nLPS\nTNF-Œ± +'ve\nFITC +'ve\n13\n25479\n0.1\n\n\nTNFAPC\nLPS\nTNF-Œ± +'ve\nFITC -'ve\n25401\n25479\n99.7\n\n\nTNFAPC\nLPS\nTNF-Œ± -'ve\nFITC -'ve\n64\n25479\n0.3\n\n\nTNFAPC\nECOLIGreen\nTNF-Œ± +'ve\nFITC +'ve\n14969\n26002\n57.6\n\n\nTNFAPC\nECOLIGreen\nTNF-Œ± +'ve\nFITC -'ve\n10996\n26002\n42.3\n\n\nTNFAPC\nECOLIGreen\nTNF-Œ± -'ve\nFITC +'ve\n29\n26002\n0.1\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip for your own plots\n\n\n\nYou can combine the concept of annotation and faceted plots to annotate a quadrant gated plot of TNFa_APC_Lin signal against the E_coli_FITC_Lin signal you made in the Data Analysis 2: Biomedical sciences - Sample data analysis workshop.",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-6/workshop.html#importing-from-google-sheets",
    "href": "r4babs4/week-6/workshop.html#importing-from-google-sheets",
    "title": "Workshop",
    "section": "Importing from google sheets",
    "text": "Importing from google sheets\nThe BIO00066I Biomedical Sciences class data are in a google sheet. You can download the file as an excel file or .csv. file but it is also possible to import the data directly from the google sheet into R. Use whatever you prefer. An advantage of using the google sheet is you won‚Äôt have to remember to download the data when someone updates it.\nYou can use the googlesheets4 package (Bryan 2023) to do this.\n\nlibrary(googlesheets4)\n\n\nfile &lt;- \"https://docs.google.com/spreadsheets/d/104EXdgsiIq-FuRF9Ly9zewEVdpkVWbyOwxSAmiqJepg/edit#gid=0\"\n\n\nclass_data &lt;- read_sheet(file)\n\nYou will be asked:\nIs it OK to cache OAuth access credentials in the folder\nC:/Users/emmar/AppData/Local/gargle/gargle/Cache between R sessions?\n1: Yes\n2: No\nSelection: \nType the number for yes.\nYou will be prompted to authenticate with Google in a browser window.\nI suggest clicking the box for:\n\nSee, edit, create, and delete all your Google Sheets spreadsheets. Learn more\n\nbut you do not have to. Click allow/continue.\nYou will see a message in the browser window:\n\nAuthentication complete. Please close this page and return to R.\n\nYou should see that the class data has been imported into R.\nNote that you will probably want to do some quality control such has filtering out rows with missing data in some columns. We did this in the Data Analysis 1: Core workshop.",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-6/workshop.html#analysis-of-the-class-data",
    "href": "r4babs4/week-6/workshop.html#analysis-of-the-class-data",
    "title": "Workshop",
    "section": "Analysis of the class data",
    "text": "Analysis of the class data\nYou should be able to apply techniques you have learned in stage 1 to the class data. You can find those materials on the VLE in the 17C/8C module sites. However, you may find it useful to use the latest version of those material which are available outside the VLE at without 2FA.\nStage 1\n\nData Analysis in R for Becoming a Bioscientist 1 (Rand 2023a). Core concepts about scientific computing, types of variable, the role of variables in analysis and how to use RStudio to organise analysis and import, summarise and plot data.\nData Analysis in R for Becoming a Bioscientist 2 (Rand 2023a). The logic of hypothesis testing, confidence intervals, what is meant by a statistical model, two-sample tests and one- and two-way analysis of variance (ANOVA).\nSupporting book Computational Analysis for Bioscientists (Rand 2023b)",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-6/workshop.html#footnotes",
    "href": "r4babs4/week-6/workshop.html#footnotes",
    "title": "Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\nData Analysis 2: Biomedical sciences - Sample data analysis workshop has been amended to include the instruction to save these data at the end.‚Ü©Ô∏é\nYou might want to look back at Quality control 3: Gating to determine a ‚Äòreal‚Äô signal in the week 2 workshop to remind yourself of how we determined the gate values for the sample data.‚Ü©Ô∏é",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-4/study_after_workshop.html",
    "href": "r4babs4/week-4/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Exercises\n\nüíª Ensure you have added your data to the class data\nüìñ Go through Week 1 Core materials and check you have applied the principles to your own data analysis.",
    "crumbs": [
      "BABS 4",
      "Week 4: DA 3 Biomed. Sci",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs4/week-4/workshop.html",
    "href": "r4babs4/week-4/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will use the tools you used in the previous workshop (and before!) to analyse the data you have collected. You will provide some key pieces of information for the class data set.",
    "crumbs": [
      "BABS 4",
      "Week 4: DA 3 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-4/workshop.html#getting-started-on-your-own-analysis",
    "href": "r4babs4/week-4/workshop.html#getting-started-on-your-own-analysis",
    "title": "Workshop",
    "section": "Getting started on your own analysis",
    "text": "Getting started on your own analysis\nüé¨ Open the RStudio Project you created in the Consolidation exercise from week 2.\nüé¨ If you have not already done so, save your data files to the project. Are the file names going to be easy for you to work with? Remember that we used the file names to label to rows with their treatment (Media, LPS or ECOLIGreen) and antibody (ISOTYPE or TNFAPC) so if you do not match the names you will need to redesign the code appropriately. It is easier to rename your files!\nüé¨ Open your R script and begin to analyse your data.",
    "crumbs": [
      "BABS 4",
      "Week 4: DA 3 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-4/workshop.html#data-for-the-class-dataset.",
    "href": "r4babs4/week-4/workshop.html#data-for-the-class-dataset.",
    "title": "Workshop",
    "section": "Data for the class dataset.",
    "text": "Data for the class dataset.\nYou need to provide the following information for the class dataset:\n\ngroup_name A name for your group. Take care not to use a name used by others. Take care to use the exactly the same name for each of your rows\ncell_treatmentOne of MEDIA, LPS or ECOLIGreen\nantibody One of ISOTYPE or TNFAPC\nn The number of cells in sample after flowAI cleaning\nn_live The number of cells in sample after flowAI cleaning and removing dead cells/debris (‚Äúgating‚Äù) (i.e., the % live cells)\nperc_live The % of cells in sample after flowAI cleaning and removing dead cells/debris (‚Äúgating‚Äù) (i.e., the % live cells)\napc_cut threshold for logicle transformed TNFa_APC_Lin. This should be the same for all your samples and indicates the level at which cells are postive for TNF-Œ± positive\nmean_apc Mean fluorescence intensity of the logicle transformed TNFa_APC_Lin in the TNF-Œ± positive cells\nn_pos_tnfa Number of TNF-Œ± positive cells\nperc_pos_tnfa Percent of live cells that are TNF-Œ± positive\n\nEnter these in the BIO00066I Biomedical Sciences class data\nSome columns are required for the class analysis. Other columns help you get to the required values and help others determine the reliability of your data.",
    "crumbs": [
      "BABS 4",
      "Week 4: DA 3 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-4/workshop.html#how-to-change-the-name-of-an-rstudio-project.",
    "href": "r4babs4/week-4/workshop.html#how-to-change-the-name-of-an-rstudio-project.",
    "title": "Workshop",
    "section": "How to change the name of an RStudio project.",
    "text": "How to change the name of an RStudio project.\nYou will need to rename your RStudio Project to your exam number before you submit. You can change the name of an RStudio project by:\n\nclosing the project\nrenaming both the project folder and the .Rproj file.",
    "crumbs": [
      "BABS 4",
      "Week 4: DA 3 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/overview.html",
    "href": "r4babs4/week-2/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This is the first of the three workshops which are specific to the Biomedical sciences strand. The aim of these workshops is to teach you how to analyse the flow cytometry data you will collect in the practicals. In this workshop, we will guide you through the analysis of a sample data set just like the one you will generate. Jillian collected these data in designing this set of practicals. You will learn both how to analyse the data and what your own data should look like.\n\nLearning objectives\nThe successful student will be able to:\n\nexplain what is in a flow cytometry data set\nimport fcs files, explain a ‚ÄúflowFrame‚Äù and a ‚ÄúflowSet‚Äù and access the column names and data in them\napply automated quality control to a flowSet with the flowAI package\nexplain why we use the ‚Äúlogicle‚Äù transformation and apply it to appropriate channels\ncast the data into a dataframe to use standard tools for filtering, summarising and plotting data\nexplain the purpose of gating and apply appropriate gates to flow cytometry data\ncreate appropriate summary statistics and figures to demonstrate the results of the analysis\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read what the sample data are, what analysis is needed and what tools we will use.\n\nWorkshop\ni.üíª Analyse the sample data set.\nConsolidate\n\nüíª Set up your RStudio Project for the analysis of your own data.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "About"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#overview-1",
    "href": "r4babs4/week-2/study_before_workshop.html#overview-1",
    "title": "Independent Study to prepare for workshop",
    "section": "Overview",
    "text": "Overview\n\nThese slides:\n\nPrepare you for the workshop analysing the sample data‚Ä¶. and your own data, which is in the same format\nSummarise the experimental design and aims\nExplain what the data are\nGo through the analytical steps conceptually\nExplain what tools we will use in the workshop to do the analysis",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#experimental-design-and-aims-1",
    "href": "r4babs4/week-2/study_before_workshop.html#experimental-design-and-aims-1",
    "title": "Independent Study to prepare for workshop",
    "section": "Experimental design and aims",
    "text": "Experimental design and aims\n\n\nMacrophages produce TNF-Œ± in response to bacterial infection\nQuestion: Does the production of TNF-Œ± by macrophages require live bacteria, or is the cell wall component sufficient?\nTherefore we need 3 treatments: Media (control), Lipopolysaccharide (LPS, Cell wall component of E. coli) and live E. coli\nWe measure TNF-Œ± with a TNF-Œ± antibody conjugated to Allophycocyanin (APC) - this will bind and fluoresce red\nTherefore we also need a control for antibody binding and use Isotype antibody - this will bind but not fluoresce",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#experimental-design-and-aims-2",
    "href": "r4babs4/week-2/study_before_workshop.html#experimental-design-and-aims-2",
    "title": "Independent Study to prepare for workshop",
    "section": "Experimental design and aims",
    "text": "Experimental design and aims\n\n\nMacrophages are treated with one of three treatments: Media, LPS or NeonGreen fluorescent E.coli\nTwo antibodies are used for each treatment: Isotype antibody, TNF-Œ± antibody conjugated to Allophycocyanin (APC)\nThus there are 3 x 2 = 6 combinations (i.e., 6 datasets)\nTwo variables of interest: red fluorescence, green fluorescence\nWe also measure forward scatter (cell size) and side scatter (cell granularity) which can be used to quality control the cells",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#experimental-design-and-aims-3",
    "href": "r4babs4/week-2/study_before_workshop.html#experimental-design-and-aims-3",
    "title": "Independent Study to prepare for workshop",
    "section": "Experimental design and aims",
    "text": "Experimental design and aims\n\nWe only expect to see red fluorescence (APC) if the treatment induces TNF-Œ± production in macrophages and the TNF-Œ± antibody is used.\nWe only expect to see green fluorescence (FITC) if the treatment is E. coli\nThis is summarised in the figure on the next page",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#experimental-design-and-aims-4",
    "href": "r4babs4/week-2/study_before_workshop.html#experimental-design-and-aims-4",
    "title": "Independent Study to prepare for workshop",
    "section": "Experimental design and aims",
    "text": "Experimental design and aims",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#the-data-1",
    "href": "r4babs4/week-2/study_before_workshop.html#the-data-1",
    "title": "Independent Study to prepare for workshop",
    "section": "The data",
    "text": "The data\n\n\nThe data are in a flow cytometry standard format (FCS) file\nEach FCS file contains data from one sample\nYou will have 6 FCS files, one for each combination of treatment and antibody\nthere are 16 variables in columns and up to 50000 cells in rows",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#the-data-2",
    "href": "r4babs4/week-2/study_before_workshop.html#the-data-2",
    "title": "Independent Study to prepare for workshop",
    "section": "The data",
    "text": "The data\n\n\n\nthe 16 columns: TIME, Time MSW, Pulse Width, FS Lin, FS Area, FS Log, SS Lin, SS Area, SS Log, FL 1 Lin, FL 1 Area, FL 1 Log, FL 8 Lin, FL 8 Area, FL 8 Log, Event Count\nFS is Forward scatter, SS is Side scatter, FL is fluorescence channel\nFL 1 is the green fluorescence channel and we will rename it E_coli_FITC\nFL 8 is the red fluorescence channel and we will rename it TNFa_APC\nWe will use the Lin columns only\nWe will use just four columns: E_coli_FITC_Lin, TNFa_APC_Lin, FS Lin, and SS Lin",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#overview-2",
    "href": "r4babs4/week-2/study_before_workshop.html#overview-2",
    "title": "Independent Study to prepare for workshop",
    "section": "Overview",
    "text": "Overview\n\n\nThe analysis of flow cytometry data is relatively simple conceptually\nWe apply several quality control steps to the data to remove anomalous signals, dead cells and debris\nWe use scatter plots, calculate means, and find percentages of cells in different regions of the scatter plots",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#analytical-steps-1",
    "href": "r4babs4/week-2/study_before_workshop.html#analytical-steps-1",
    "title": "Independent Study to prepare for workshop",
    "section": "Analytical steps",
    "text": "Analytical steps\n\n\n\nImport the data into R and improve the column names\nApply automated quality control\nApply a ‚Äúlogicle‚Äù transformation (Parks, Roederer, and Moore 2006) to the fluorescence channels (similar to logging)\nExplore the data with scatter plots and histograms/density plots\nUse FS Lin and SS Lin to determine what cells (rows) to remove as dead/debris\nDetermine cut-offs for cells being positive for TNF-Œ± and E. coli\nCalculate the percentage of cells that are positive for TNF-Œ± for each treatment combination",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#tools-1",
    "href": "r4babs4/week-2/study_before_workshop.html#tools-1",
    "title": "Independent Study to prepare for workshop",
    "section": "Tools",
    "text": "Tools\n\n\nImport and rename columns using the flowCore package (Ellis et al. 2024)\nAutomated quality control with the flowAI package (Monaco et al. 2016)\nApply a ‚Äúlogicle‚Äù transformation using the flowCore package\nPut the data into a dataframe to make it easy to use tidyverse (Wickham et al. 2019) tools like group_by(), summarise(), ggplot(), filter()",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#the-data-in-r",
    "href": "r4babs4/week-2/study_before_workshop.html#the-data-in-r",
    "title": "Independent Study to prepare for workshop",
    "section": "The data in R",
    "text": "The data in R\n\n\nthe flowCore package imports each FCS file as a flowFrame object\nThe flowFrame object contains the data from the FCS file and metadata about the experiment\nA collection of related flowFrames are stored in a flowSet object\nflowAI and flowCore functions work with flowSet objects\nAfter that we can convert the flowSet to a dataframe to use tidyverse tools with which you are more familiar",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#summary-1",
    "href": "r4babs4/week-2/study_before_workshop.html#summary-1",
    "title": "Independent Study to prepare for workshop",
    "section": "Summary",
    "text": "Summary\n\nSample data are like the data you will produce in your own experiment\n3 treatments x 2 antibodies = 6 combinations; 4 variables upto 50000 cells each\nThe analysis is conceptually simple: quality control, transformation, scatter plots, and calculating percentages\nThe week 2 workshop analyses the sample data, in the week 4 workshop you will analyse your own data\nWe will use the flowCore, flowAI and tidyverse packages to do the analysis",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_before_workshop.html#references",
    "href": "r4babs4/week-2/study_before_workshop.html#references",
    "title": "Independent Study to prepare for workshop",
    "section": "References",
    "text": "References\n\n\n\n\nEllis, B, Perry Haaland, Florian Hahne, Nolwenn Le Meur, Nishant Gopalakrishnan, Josef Spidlen, Mike Jiang, and Greg Finak. 2024. ‚ÄúflowCore: flowCore: Basic Structures for Flow Cytometry Data.‚Äù\n\n\nMonaco, Gianni, Hao Chen, Michael Poidinger, Jinmiao Chen, Joao Pedro de Magalhaes, and Anis Larbi. 2016. ‚ÄúflowAI: Automatic and Interactive Anomaly Discerning Tools for Flow Cytometry Data‚Äù 32. 10.1093/bioinformatics/btw191.\n\n\nParks, David R., Mario Roederer, and Wayne A. Moore. 2006. ‚ÄúA New ‚ÄúLogicle‚Äù Display Method Avoids Deceptive Effects of Logarithmic Scaling for Low Signals and Compensated Data.‚Äù Cytometry Part A 69A (6): 541‚Äì51. https://doi.org/10.1002/cyto.a.20258.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D‚ÄôAgostino McGowan, Romain Fran√ßois, Garrett Grolemund, et al. 2019. ‚ÄúWelcome to the Tidyverse‚Äù 4: 1686. https://doi.org/10.21105/joss.01686.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-1/overview.html",
    "href": "r4babs4/week-1/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week the independent study to be done before the workshop is revision of some stage 1 core concepts. It covers file types, file systems, working directories, paths and RStudio Projects. You may feel completely confident with them but many students will benefit from a refresher.\nIn the workshop we will cover Project organisation, working with data that has many variables and observations, getting an overview with summaries and distribution plots, and how to filter rows and columns.\n\nLearning objectives\nThe successful student will be able to:\n\nexplain the organisation of files and directories in a file systems including root, home and working directories (revision)\nexplain and appropriately use, absolute and relative file paths (revision)\nknow how to use a project-oriented workflow to organise their work systematically and reproducibly\nexplain the organisation of some typical ‚Äúbig data‚Äù files\ncreate summaries and plots to get an overview of a data set\nfilter rows from data sets for quality control, to remove missing data, or to select a subset of the data with work with\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read Understanding file systems (Stage 1 revision).\nüìñ Read RStudio projects (Stage 1 revision).\n\nWorkshop\n\nüë©‚Äçüè´ Find out why reproducible research matters and some tips for achieving it.\n\nüë©‚Äçüè´ Find out what big data are\nüíª Understand some data files that are typical of big data\nüíª Learn how to filter a dataset and create summaries and plots to get an overview\n\nConsolidate\n\nüíª",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "About"
    ]
  },
  {
    "objectID": "r4babs4/week-1/study_before_workshop.html",
    "href": "r4babs4/week-1/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read Understanding file systems. Approximately 15 - 20 minutes. This is revision of some stage 1 core concepts. It covers file types, filesystems. working directories and paths. You may feel completely confident with them but many students will benefit from a refresher.\nüìñ Read RStudio Projects. Section 7.1 only. Approximately 5 - 10 minutes. This is revision but part of the assessment requires that you use an RStudio project so if you aren‚Äôt sure you are using them, you might want to check.\n\nEntirely optionally, you might want to review some other stage 1 content. You can access these through the past VLE sites but you might find it helpful to use my latest versions because I have improved them, there is no 2FA and the sites are searchable.\nStage 1\n\nData Analysis in R for Becoming a Bioscientist 1.Core concepts about scientific computing, types of variable, the role of variables in analysis and how to use RStudio to organise analysis and import, summarise and plot data.\nData Analysis in R for Becoming a Bioscientist 2. The logic of hypothesis testing, confidence intervals, what is meant by a statistical model, two-sample tests and one- and two-way analysis of variance (ANOVA).",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Prepare!"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\nAbout me"
  },
  {
    "objectID": "r4babs1/week-6/study_after_workshop.html",
    "href": "r4babs1/week-6/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "There is no additional study this week but you may want to look ahead to next week.",
    "crumbs": [
      "BABS 1",
      "Week 6: Understanding file systems",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs1/week-6/workshop.html",
    "href": "r4babs1/week-6/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "There is no formal workshop this week but I recommend setting yourself up to work from home\n\nüíª Set up the Virtual Desktop. I recommend working on the University computers for this work. Installing R and RStudio is almost always straightforward but many people are still developing their computing skills. If you sometimes have difficulty updating and or installing software on your own machine, wouldn‚Äôt know what what versions of R and RStudio you are using or don‚Äôt realise there is a difference between R and RStudio you will likely avoid trouble by using the university machines. The uni machines always have up-to-date R and R packages and all the packages that appear in teaching materials. You can still work from home by using the Virtual Desktop Service. The VDS allows you to log on to a university computer from your own computer. It means you can access all software and filestores. When using the VDS for R and RStudio, it usually makes sense to use other software - such as a browser or file explorer - also through the VDS. Go to the Virtual Desktop Service for set up instructions.\nHowever, If you are confident in your ability to set up your own machine, you need:\n\nto know there is a difference between R and RStudio\nInstall R and Rstudio\nto us R 4.4 and RStudio 2024.09.0 Build 375 (‚ÄúCranberry Hibiscus‚Äù)\nto be certain you are actually using R 4.4 - it is written in the top edge of the console window. By default RStudio uses the latest version on R on your machine.\n\nIt is possible to access all your files on your university account without using the VDS. For example, if you want to work on uni machines at uni and your machine at home. You can best do this by mapping a drive. If you store everything on google drive you can also read/write to that like any other drive using google drive app.\n\nEven if you plan to use your own machine I really recommend you take the time to set the VDS up now while you‚Äôre not time pressured so you always have that option ready.",
    "crumbs": [
      "BABS 1",
      "Week 6: Understanding file systems",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/study_after_workshop.html",
    "href": "r4babs1/week-7/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª In a maternity hospital, the total numbers of births induced on each day of the week over a six week period were recorded (see table below). Create a plot of these data with the days of week in order.\n\n\n\n\nNumber of inductions for each day of the week over six weeks.\n\nDay\nNo. inductions\n\n\n\nMonday\n43\n\n\nTuesday\n36\n\n\nWednesday\n35\n\n\nThursday\n38\n\n\nFriday\n48\n\n\nSaturday\n26\n\n\nSunday\n24\n\n\n\n\n\n\nAnswer - don‚Äôt look until you have tried!# create a dataframe for the data\nday &lt;- c(\"Monday\", \n         \"Tuesday\", \n         \"Wednesday\",\n         \"Thursday\",\n         \"Friday\",\n         \"Saturday\",\n         \"Sunday\")\nfreq &lt;- c(43, 36, 35, 38, 48, 26, 24) \ninductions &lt;- data.frame(day, freq)\n\n# make the order of the days correct rather than alphabetical\ninductions &lt;- inductions |&gt; \n  mutate(day = fct_relevel(day, c(\"Monday\",\n                                  \"Tuesday\",\n                                  \"Wednesday\",\n                                  \"Thursday\",\n                                  \"Friday\",\n                                  \"Saturday\",\n                                  \"Sunday\")))\n\n# plot the data as a barplot with the bars in\nggplot(data = inductions, \n       aes(x = day, y = freq)) +\n  geom_col(colour = \"black\",\n           fill = \"lightseagreen\") +\n  scale_x_discrete(expand = c(0, 0),\n                   name = \"Day of the week\") + \n  scale_y_continuous(expand = c(0, 0),\n                     name = \"Number of inductions\",\n                     limits = c(0, 55)) +\n  theme_classic()\n\n\n\nüìñ Read Workflow in RStudio",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs1/week-7/study_before_workshop.html",
    "href": "r4babs1/week-7/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "Either\n\nüìñ Read First Steps in RStudio in\n\nOR\n\nüìπ Watch",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs1/r4babs1.html",
    "href": "r4babs1/r4babs1.html",
    "title": "Data Analysis in R for BABS 1",
    "section": "",
    "text": "This is the first of the four BABS modules. Over four weeks you will learn some core concepts about scientific computing, types of variable, the role of variables in analysis and how to use RStudio to organise analysis and import, summarise and plot data. You may want to read the overview of Data Analysis in R in your degree.\n\n\nThe BABS1 Module Learning outcomes that relate to the Data Analysis in R content are:\n\nMethodically record scientific investigations with lab books, organise data and use R to import, summarise and plot simple data sets.\nExplain the key features of effective written media for dissemination of scientific information and be able to communicate experimental results through a scientific poster.",
    "crumbs": [
      "BABS 1",
      "Data Analysis in R for BABS 1"
    ]
  },
  {
    "objectID": "r4babs1/r4babs1.html#module-learning-objectives",
    "href": "r4babs1/r4babs1.html#module-learning-objectives",
    "title": "Data Analysis in R for BABS 1",
    "section": "",
    "text": "The BABS1 Module Learning outcomes that relate to the Data Analysis in R content are:\n\nMethodically record scientific investigations with lab books, organise data and use R to import, summarise and plot simple data sets.\nExplain the key features of effective written media for dissemination of scientific information and be able to communicate experimental results through a scientific poster.",
    "crumbs": [
      "BABS 1",
      "Data Analysis in R for BABS 1"
    ]
  },
  {
    "objectID": "r4babs1/r4babs1.html#understanding-file-systems",
    "href": "r4babs1/r4babs1.html#understanding-file-systems",
    "title": "Data Analysis in R for BABS 1",
    "section": "Understanding file systems",
    "text": "Understanding file systems\nYou will learn about operating systems, files and file systems, working directories, absolute and relative paths, what R and RStudio are",
    "crumbs": [
      "BABS 1",
      "Data Analysis in R for BABS 1"
    ]
  },
  {
    "objectID": "r4babs1/r4babs1.html#introduction-to-r-and-project-organisation",
    "href": "r4babs1/r4babs1.html#introduction-to-r-and-project-organisation",
    "title": "Data Analysis in R for BABS 1",
    "section": "Introduction to R and project organisation",
    "text": "Introduction to R and project organisation\nYou will start writing R code in RStudio and will create your first graph! You will learn about data types such as ‚Äúnumerics‚Äù and ‚Äúcharacters‚Äù and some of the different types of objects in R such as ‚Äúvectors‚Äù and ‚Äúdataframes‚Äù. These are the building blocks for the rest of your R journey. You will also learn a workflow and about the layout of RStudio and using RStudio Projects.",
    "crumbs": [
      "BABS 1",
      "Data Analysis in R for BABS 1"
    ]
  },
  {
    "objectID": "r4babs1/r4babs1.html#types-of-variable-summarising-and-plotting-data",
    "href": "r4babs1/r4babs1.html#types-of-variable-summarising-and-plotting-data",
    "title": "Data Analysis in R for BABS 1",
    "section": "Types of variable, summarising and plotting data",
    "text": "Types of variable, summarising and plotting data\nThe type of values our data can take is important in how we analyse and visualise it. This week you will learn the difference between continuous and discrete values and how we summarise and visualise them. The focus will be on plotting and summarising single variables. You will also learn how to read in data in to RStudio from plain text files and Excel files.",
    "crumbs": [
      "BABS 1",
      "Data Analysis in R for BABS 1"
    ]
  },
  {
    "objectID": "r4babs1/r4babs1.html#summarising-data-with-several-variables",
    "href": "r4babs1/r4babs1.html#summarising-data-with-several-variables",
    "title": "Data Analysis in R for BABS 1",
    "section": "Summarising data with several variables",
    "text": "Summarising data with several variables\nThis week you will start plotting data sets with more than one variable. This means you need to be able determine which variable is the response and which is the explanatory. You will find out what is meant by ‚Äútidy‚Äù data and how to perform a simple data tidying task. Finally you will discover how to save your figures and place them in documents.",
    "crumbs": [
      "BABS 1",
      "Data Analysis in R for BABS 1"
    ]
  },
  {
    "objectID": "r4babs1/week-8/study_after_workshop.html",
    "href": "r4babs1/week-8/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the packages and import the data.\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n\nfly_bristles_means &lt;- read_excel(\"data-raw/bristles-mean.xlsx\")\ncats &lt;- read_csv(\"data-raw/cat-coats.csv\")\n\nExercises\n\nüíª Summarise the fly_bristles_means dataframe by calculating the mean, median, sample size, standard deviation and standard error of the mean_count variable.\n\n\nAnswer - don‚Äôt look until you have tried!fly_bristles_means_summary &lt;- fly_bristles_means |&gt; \n  summarise(mean = mean(mean_count),\n            median = median(mean_count),\n            n = length(mean_count),\n            standard_dev = sd(mean_count),\n            standard_error = standard_dev / sqrt(n))\n\n\n\nüíª Create an appropriate plot to show the distribution of mean_count in fly_bristles_means\n\n\n\nAnswer - don‚Äôt look until you have tried!ggplot(fly_bristles_means, aes(x = mean_count)) +\n  geom_histogram(bins = 10)\n\n\n\nüíª Can you format the plot 2. by removing the grey background, giving the bars a black outline and the fill colour of your choice and improving the axis format and labelling? You may want to refer to last week‚Äôs workshop.\n\n\nAnswer - don‚Äôt look until you have tried!ggplot(fly_bristles_means, aes(x = mean_count)) +\n  geom_histogram(bins = 10, \n                 colour = \"black\",\n                 fill = \"skyblue\") +\n  scale_x_continuous(name = \"Number of bristles\",\n                     expand = c(0, 0)) +\n  scale_y_continuous(name = \"Frequency\",\n                     expand = c(0, 0),\n                     limits = c(0, 35)) +\n  theme_classic()\n\n\n\nüíª Amend this code to change the order of the bars by the average mass of each coat colour? Changing the order of bars was covered last week. You may also want to practice formatting the graph nicely.\n\n\nggplot(cats, aes(x = coat, y = mass)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nAnswer - don‚Äôt look until you have tried!ggplot(cats, \n       aes(x = reorder(coat, mass), y = mass)) +\n  geom_boxplot(fill = \"darkcyan\") +\n  scale_x_discrete(name = \"Coat colour\") +\n  scale_y_continuous(name = \"Mass (kg)\", \n                     expand = c(0, 0),\n                     limits = c(0, 8)) +\n  theme_classic()\n\n\n\nüìñ Read Understanding the pipe |&gt;",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs1/week-8/workshop.html",
    "href": "r4babs1/week-8/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): Continuous and Discrete\n\n\nIn this workshop you will learn how to import data from files in your working directory and from a folder in your working directory. This will develop your understanding of working directories and paths. You will also create summaries and plots for data you import. This will give you more practice customising plots and using the pipe.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-8/workshop.html#session-overview",
    "href": "r4babs1/week-8/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will learn how to import data from files in your working directory and from a folder in your working directory. This will develop your understanding of working directories and paths. You will also create summaries and plots for data you import. This will give you more practice customising plots and using the pipe.",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-8/workshop.html#philosophy",
    "href": "r4babs1/week-8/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-8/workshop.html#importing-data-from-files",
    "href": "r4babs1/week-8/workshop.html#importing-data-from-files",
    "title": "Workshop",
    "section": "Importing data from files",
    "text": "Importing data from files\nLast week we created data by typing the values in to R. This is not practical when you have a lot of data. For example if you have recorded a lot of data into a spreadsheet, or you are using a data file that has been supplied to you by a person or a machine. Far more commonly, we import data from a file into R. This requires you know two pieces of information.\n\n\nWhat format the data are in\nThe format of the data determines what function you will use to import it and the file extension often indicates format.\n\n\n.txt a plain text file1, where the columns are often separated by a space but might also be separated by a tab, a backslash or forward slash, or some other character\n\n.csv a plain text file where the columns are separated by commas\n\n.xlsx an Excel file\n\n\n\nWhere the file is relative to your working directory\nR can only read in a file if you say where it is, i.e., you give its relative path.\n\n\nWe will first save the four files for this workshop to our Project folder (week-8) and read them in. Then we will then create a new folder inside our Project folder called data-raw, move the data files into it and read them in from there. This will allow you to see how the file paths need to be modified when a file is not in your working directory.\n Save these four files in to your week-8 folder\n\nThe coat colour and mass of 62 cats: cat-coats.csv\n\nThe relative size of over 5000 cells measure by forward scatter (FSC) in flow cytometry: cell-size.txt\n\nThe number of sternopleural bristles on 96 female Drosophila: bristles.txt\n\nThe number of sternopleural bristles on 96 female Drosophila (with technical replicates): bristles-mean.xlsx\n\n\nThe first three files can be read in with core tidyverse Wickham et al. (2019) functions and the last can be read in with the readxl Wickham and Bryan (2023) package.\n Load the two packages\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nWe will first read in cat-coats.csv. A .csv. extension suggests this is plain text file with comma separated columns. However, before we attempt to read it it, when should take a look at it. We can do this from RStudio\n Go to the Files pane (bottom right), click on the cat-coats.csv file and choose View File2\n\n\nRStudio Files Pane\n\nAny plain text file will open in the top left pane (Excel files will launch Excel).\n Is the file csv?\n\n\n What kind of variables does the file contain?\n\n\n Read in the csv file with:\n\ncats &lt;- read_csv(\"cat-coats.csv\")\n\nThe data from the file a read into a dataframe called cats and you will be able to see it in the Environment.\n Click on each of the remaining files and choose View File.\n In each case, say what the format is and what types of variables it contains.\n\n\n\n\n\n\n\n\nWe use the read_table()3 command to read in plain text files of single columns or where the columns are separated by spaces.\n The file cell-size.txt can be read into a dataframe called cells using read_table():\n\ncells &lt;- read_table(\"cell-size.txt\")\n\n Now you try reading bristles.txt in to a dataframe called fly_bristles\nThe readxl package we loaded earlier has two useful functions for working with Excel files: excel_sheets(\"filename.xlsx\") will list the sheets in an Excel workbook; read_excel(\"filename.xlsx\") will read in to top sheet or a specified sheet with a small modification read_excel(\"filename.xlsx\", sheet = \"Sheet1\").\n List the the names of the sheets and read in the sheet with the data like this:\n\nexcel_sheets(\"bristles-mean.xlsx\")\nfly_bristles_means &lt;- read_excel(\"bristles-mean.xlsx\", sheet = \"means\")\n\nWell done! You can now read read in from files in your working directory.\nTo help you understand relative file paths, we will now move the data files.\n First remove the dataframes you just created to make it easier to see whether you can successfully read in the files from a different place:\n\nrm(cats, fly_bristles, cells, fly_bristles_means)\n\n Now make a new folder called data-raw. You can do this on the Files Pane by clicking New Folder and typing into the box that appears.\n Check the boxes next to the file names and choose More | Move‚Ä¶ and select the data-raw folder.\n The files will move. To import data from files in the data-raw folder, you need to give the relative path to the file from the working directory. The working directory is the Project folder, week-8 so the relative path is data-raw/cat-coats.csv\n Import the cat-coats.csv data like this:\n\ncats &lt;- read_csv(\"data-raw/cat-coats.csv\")\n\n Now you do the other files!\nFrom this point forward in the course, we will always create a data-raw folder each time we make a new Project.\nThese are the most common forms of data file you will encounter at first. However, data can certainly come to you in other formats particularly when they have come from particular software. Usually, there is an R package specially for that format.\nIn the rest of the workshop we will take each dataset in turn and create summaries and plots appropriate for the data types. Data is summarised using the group_by() and summarise() functions",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-8/workshop.html#summarising-discrete-data-cat-coat",
    "href": "r4babs1/week-8/workshop.html#summarising-discrete-data-cat-coat",
    "title": "Workshop",
    "section": "Summarising discrete data: Cat coat",
    "text": "Summarising discrete data: Cat coat\nThe most appropriate way to summarise nominal data like the colour of cat coats is to tabulate the number of cats with each colour.\n Summarise the cats dataframe by counting the number of cats in each category\n\ncats |&gt; \n  group_by(coat) |&gt; \n  count()\n\n# A tibble: 6 √ó 2\n# Groups:   coat [6]\n  coat              n\n  &lt;chr&gt;         &lt;int&gt;\n1 black            23\n2 calico            1\n3 ginger           10\n4 tabby             8\n5 tortoiseshell     5\n6 white            15\n\n\n|&gt; is the pipe and can be produced with Ctrl+Shift+M\nThis sort of data might be represented with a barchart. You have two options for producing that barchart:\n\nplot the summary table using geom_col()\nplot the raw data using geom_bar()\n\nWe did the first of these last week. The geom_col() function uses the numbers in a second column to determine how high the bars are. However, the geom_bar() function will do the tabulating for you.\n Plot the coat data using geom_bar:\n\nggplot(cats, aes(x = coat)) +\n  geom_bar()\n\n\n\n\n\n\n\nThe gaps that R put automatically between the bars reflects that the coat colours are discrete categories.",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-8/workshop.html#summarising-counts-bristles",
    "href": "r4babs1/week-8/workshop.html#summarising-counts-bristles",
    "title": "Workshop",
    "section": "Summarising Counts: Bristles",
    "text": "Summarising Counts: Bristles\nCounts are discrete and can be thought of a categories with an order (ordinal).\n Summarise the fly_bristles dataframe by counting the number of flies in each category of bristle number\nSince counts are numbers, we might also want to calculate some summary statistics such as the median and interquartile range.\n Summarise the fly_bristles dataframe by calculate the median and interquartile range\n\nfly_bristles |&gt; \n  summarise(median(number),\n            IQR(number))\n\n# A tibble: 1 √ó 2\n  `median(number)` `IQR(number)`\n             &lt;dbl&gt;         &lt;dbl&gt;\n1                6             4\n\n\nAs the interquartile is 4 and the median is 6 then 25% flies have 4 bristles or fewer and 25% have 8 or more.\nThe distribution of counts4 is not symmetrical for lower counts so the mean is not usually a good way to summarise count data.\n If you want to save the table you created and give the columns better names you can make two adjustments:\n\nfly_bristles_summary &lt;- fly_bristles |&gt; \n  summarise(med = median(number),\n            interquartile = IQR(number))\n\n\nwe have saved the output to an object fly_bristles_summary using assignment &lt;-. This means you will not see output from the command.\nwe have given the columns better names med and interquartile using the = operator.\n\n Plot the bristles data using geom_bar:\nIf counts have a a high mean and big range, like number of hairs on a person‚Äôs head, then you can often treat them as continuous. This means you can use statistics like the mean and standard deviation to summarise them, histograms to plot them and use some standard statistical tests on them.",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-8/workshop.html#summarising-continuous-data",
    "href": "r4babs1/week-8/workshop.html#summarising-continuous-data",
    "title": "Workshop",
    "section": "Summarising continuous data",
    "text": "Summarising continuous data\nCat mass\nThe variable mass in the cats dataframe is continuous. Very many continuous variables have a normal distribution. e normal distribution is also known as the bell-shaped curve. If we had the mass of all the cats in the world, we would find many cats were near the mean and fewer would be away from the mean, either much lighter or much heavier. In fact 68% would be within one standard deviation of the mean and about 96% would be within two standard deviations.\n\n\n\n\n\n\n\n\n We can find the mean mass with:\n\ncats |&gt; \n  summarise(mean = mean(mass))\n\n# A tibble: 1 √ó 1\n   mean\n  &lt;dbl&gt;\n1  4.51\n\n\nWe can add any sort of summary by placing it inside the the summarise parentheses. Each one is separated by a comma. We did this to find the median and the interquatrile range for fly bristles.\n For example, another way to calculate the number of values is to use the length() function:\n\ncats |&gt; \n  summarise(mean = mean(mass),\n            n = length(mass))\n\n# A tibble: 1 √ó 2\n   mean     n\n  &lt;dbl&gt; &lt;int&gt;\n1  4.51    62\n\n\n Adapt the code to calculate the mean, the sample size and the standard deviation (sd())\nA single continuous variable can be plotted using a histogram to show the shape of the distribution.\n Plot a histogram of cats mass:\n\nggplot(cats, aes(x = mass)) +\n  geom_histogram(bins = 15, colour = \"black\") \n\n\n\n\n\n\n\nNotice that there are no gaps between the bars which reflects that mass is continuous. bins determines how many groups the variable is divided up into (i.e., the number of bars) and colour sets the colour for the outline of the bars. A sample of 62 is a relatively small number of values for plotting a distribution and the number of bins used determines how smooth or normally distributed the values look.\n Experiment with the number of bins. Does the number of bins affect how you view the distribution.\nNext week we will practice summarise and plotting data files with several variables but just to give you a taste, we will find summary statistics about mass for each of the coat types.\n The group_by() function is used before the summarise() to do calculations for each of the coats:\n\ncats |&gt; \n  group_by(coat) |&gt; \n  summarise(mean = mean(mass),\n                  standard_dev = sd(mass))\n\n# A tibble: 6 √ó 3\n  coat           mean standard_dev\n  &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1 black          4.63        1.33 \n2 calico         2.19       NA    \n3 ginger         4.46        1.12 \n4 tabby          4.86        0.444\n5 tortoiseshell  4.50        0.929\n6 white          4.34        1.34 \n\n\nYou can read this as:\n\ntake cats and then group by coat and then summarise by finding the mean of mass and the standard deviation of mass\n\n Why do we get an NA for the standard deviation of the calico cats?\n\n\n\nCells\n Summarise the cells dataframe by calculating the mean, median, sample size and standard deviation of FSC.\n Add a column for the standard error which is given by \\(\\frac{s.d.}{\\sqrt{n}}\\)\nMeans of counts\nMany things are quite difficult to measure or count and in these cases we often do technical replicates. A technical replicate allows us the measure the exact same thing to check how variable the measurement process is. For example, Drosophila are small and counting their sternopleural bristles is tricky. In addition, where a bristle is short (young) or broken scientists might vary in whether they count it. Or people or machines might vary in measuring the concentration of the same solution.\nWhen we do technical replicates we calculate their mean and use that as the measure. This is what is in our fly_bristles_means dataframe - the bristles of each of the 96 flies was counted by 5 people and the data are those means. These has an impact on how we plot and summarise the dataset because the distribution of mean counts is continuous! We can use means, standard deviations and histograms. This will be an exercise in Consolidate.",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-8/workshop.html#look-after-future-you",
    "href": "r4babs1/week-8/workshop.html#look-after-future-you",
    "title": "Workshop",
    "section": "Look after future you!",
    "text": "Look after future you!\nFuture you is going to summarise and plot data from the ‚ÄúRiver practicals‚Äù. You can make this much easier by documenting what you have done now. At the moment all of your code from this workshop is in a single file, probably called import-summarise-plot.R. I recommend making a new script for each of nominal, continuous and count data and copying the code which imports, summarises and plots it. This will make it easier for future you to find the code you need. Here is an example: nominal_data.R. You may wish to comment your version much more.\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-8/workshop.html#footnotes",
    "href": "r4babs1/week-8/workshop.html#footnotes",
    "title": "Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\nPlain text files can be opened in notepad or other similar editor and still be readable.‚Ü©Ô∏é\nDo not be tempted to import data this way. Unless you are careful, your data import will not be scripted or will not be scripted correctly.‚Ü©Ô∏é\nnote read_csv() and read_table() are the same functions with some different settings.‚Ü©Ô∏é\nCount data are usually ‚ÄúPoisson‚Äù distributed.‚Ü©Ô∏é",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-9/study_after_workshop.html",
    "href": "r4babs1/week-9/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the packages and import the data.\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n\nüíª Summarise and plot the pigeons dataframe appropriately.\n\n\nAnswer - don‚Äôt look until you have tried!# import\npigeons &lt;- read_table(\"data-raw/pigeon.txt\")\n\n# reformat to tidy\npigeons &lt;- pivot_longer(data = pigeons, \n                        cols = everything(), \n                        names_to = \"population\", \n                        values_to = \"distance\")\n\n# sumnmarise\npigeons_summary &lt;- pigeons %&gt;%\n  group_by(population) %&gt;%\n  summarise(mean = mean(distance),\n            std = sd(distance),\n            n = length(distance),\n            se = std/sqrt(n))\n# plot\nggplot() +\n  geom_point(data = pigeons, aes(x = population, y = distance),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"gray50\") +\n  geom_errorbar(data = pigeons_summary, \n                aes(x = population, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = pigeons_summary, \n                aes(x = population, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Interorbital distance (mm)\", \n                     limits = c(0, 14), \n                     expand = c(0, 0)) +\n  scale_x_discrete(name = \"Population\") +\n  theme_classic()\n\n\n\n\nüíª The data in blood.csv are measurements of several blood parameters from fifty people with Crohn‚Äôs disease, a lifelong condition where parts of the digestive system become inflamed. Twenty-five of people are in the early stages of diagnosis and 25 have started treatment. The variables in the dataset are:\n\nsodium - Sodium concentration in umol/L, the average of 5 technical replicates\npotassium - Potassium concentration in umol/L, the average of 5 technical replicates\nB12 Vitamin - B12 in pmol/L, the average of 5 technical replicates\nwbc - White blood cell count in 10^9 /L, the average of 5 technical replicates\nrbc count - Red blood cell count in 10^12 /L, the average of 5 technical replicates\nplatlet count - platlet count in 10^9 /L, the average of 5 technical replicates\ninflammation marker - the presence or absence of a marker of inflammation, either 0 or 1\nstatus - whether the individual is before or after treatment.\n\nYour task is to summarise and plot these data in any suitable way. Create a complete RStudio Project for an analysis of these data. You will need to:\n\nMake a new project\nMake folders for data and for figures\nImport the data\nSummarise and plot variables of your choice. It doesn‚Äôt matter what you chose - the goal is the practice the project workflow and selecting appropriate plotting and summarising methods for particular data sets.",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs1/week-9/workshop.html",
    "href": "r4babs1/week-9/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Data data Artwork from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst\n\n\nIn this workshop you will learn to summarise and plot datasets with more than one variable and how to write figures to files. You will also get more practice with working directories, importing data, formatting figures and the pipe.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start , make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-9/workshop.html#session-overview",
    "href": "r4babs1/week-9/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will learn to summarise and plot datasets with more than one variable and how to write figures to files. You will also get more practice with working directories, importing data, formatting figures and the pipe.",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-9/workshop.html#philosophy",
    "href": "r4babs1/week-9/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start , make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-9/workshop.html#myoglobin-in-seal-muscle",
    "href": "r4babs1/week-9/workshop.html#myoglobin-in-seal-muscle",
    "title": "Workshop",
    "section": "Myoglobin in seal muscle",
    "text": "Myoglobin in seal muscle\nThe myoglobin concentration of skeletal muscle of three species of seal in grams per kilogram of muscle was determined and the data are given in seal.csv. Each row represents an individual seal. The first column gives the myoglobin concentration and the second column indicates species.\nImport\n Save seal.csv to your data-raw folder.\nIn the next step you will import the daya and I suggest you look up data import from last week. There are two ways you could do that.\n\nOpen your own script from last week. You do not need to open the week-8 RStudio Project itself - you can open the script you used by navigating to through the File pane. After you have found it and clicked on it to open, I suggest showing your working directory in your File Pane again. You can do that by clicking on the little arrow at the end of the path printed on the Console window.\nGo the the workshop page from last week.\n\n Read the data into a dataframe called seal.\n What types of variables do you have in the seal dataframe? What role would you expect them to play in analysis?\n\n\n\n\nA key point here is that the fundamental structure of:\n\none continuous response and one nominal explanatory variable with two groups (adipocytes), and\none continuous response and one nominal explanatory variable with three groups (seals)\n\nis the same! The only thing that differs is the number of groups (the number of values in the nominal variable). This means the code for summarising and plotting is identical except for the variable names!\n\n\n\n\n\n\nTip\n\n\n\nWhen two datasets have the same number of columns and the response variable and the explanatory variables have the same data types then the code you need is the same.\n\n\nSummarise\nSummarising the data for each species is the next sensible step. The most useful summary statistics for a continuous variable like myoglobin are:\n\nmean\nstandard deviation\nsample size\nstandard error\n\nWe can get those for the whole myoglobin column, like we did for the FSA column in the cells dataset last week. However, it is likely to be more useful to summarise myoglobin separately for each seal species. We can achieve this using group_by() before summarise().\n Create a data frame called seal_summary1 that contains the means, standard deviations, sample sizes and standard errors for each of the seal species:\n\nseal_summary &lt;- seal |&gt;\n  group_by(species) |&gt;\n  summarise(mean = mean(myoglobin),\n            std = sd(myoglobin),\n            n = length(myoglobin),\n            se = std/sqrt(n))\n\nYou should get the following numbers:\n\n\n\n\nspecies\nmean\nstd\nn\nse\n\n\n\nBladdernose Seal\n42.31600\n8.020634\n30\n1.464361\n\n\nHarbour Seal\n49.01033\n8.252004\n30\n1.506603\n\n\nWeddell Seal\n44.66033\n7.849816\n30\n1.433174\n\n\n\n\n\nVisualise\nMost commonly, we put the explanatory variable on the x axis and the response variable on the y axis. A continuous response, particularly one that follows the normal distribution, is best summarised with the mean and the standard error. In my opinion, you should also show all the raw data points wherever possible.\nWe are going to create a figure like this:\n\n\n\n\n\n\n\n\nIn this figure, we have two dataframes:\n\nthe seal dataframe which contains the raw data points\nthe seal_summary dataframe which contains the means and standard errors.\n\nSo far we have plotted just one dataframe on a figure and we have specified the dataframe to be plotted and the columns to plot inside the ggplot() command. For examples:\n\nggplot(cats, \n       aes(x = reorder(coat, mass), y = mass)) +\n  geom_boxplot(fill = \"darkcyan\") +\n  scale_x_discrete(name = \"Coat colour\") +\n  scale_y_continuous(name = \"Mass (kg)\", \n                     expand = c(0, 0),\n                     limits = c(0, 8)) +\n  theme_classic()\n\nOr\n\nggplot(fly_bristles_means, aes(x = mean_count)) +\n  geom_histogram(bins = 10, \n                 colour = \"black\",\n                 fill = \"skyblue\") +\n  scale_x_continuous(name = \"Number of bristles\",\n                     expand = c(0, 0)) +\n  scale_y_continuous(name = \"Frequency\",\n                     expand = c(0, 0),\n                     limits = c(0, 35)) +\n  theme_classic()\n\nHere you will learn that dataframes and aesthetics can be specified within a geom_xxxx rather than within ggplot(). This is very useful if the geom only applies to some of the data you want to plot.\n\n\n\n\n\n\nTip: ggplot()\n\n\n\nYou put the data argument and aes() inside ggplot() if you want all the geoms to use that dataframe and variables. If you want a different dataframe for a geom, put the data argument and aes() inside the geom_xxxx()\n\n\nI will build the plot up in small steps but you should edit your existingggplot() command as we go.\n Plot the raw data points first:\n\nggplot() +\n  geom_point(data = seal, \n             aes(x = species, y = myoglobin))\n\n\n\n\n\n\n\nNotice:\n\ngeom_point() is the geom to plot points\nwe have given the data argument and the aesthetics inside the geom.\nthe variables given in the aes(), species and myoglobin, are columns in the dataframe, seal, given in the data argument.\n\n We can ensure the points do not overlap, by adding some random jitter in the x direction (edit your existing code):\n\nggplot() +\n  geom_point(data = seal, \n             aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0))\n\n\n\n\n\n\n\nNotice:\n\nposition = position_jitter(width = 0.1, height = 0) is inside the geom_point() parentheses, after the aes() and a comma.\nWe‚Äôve set the vertical jitter to 0 because, in contrast to the categorical x-axis, movement on the y-axis has meaning (the myoglobin levels).\n\n Let‚Äôs make the points a light grey (edit your existing code):\n\nggplot() +\n  geom_point(data = seal, \n             aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\")\n\n\n\n\n\n\n\nNow to add the errorbars. These go from one standard error below the mean to one standard error above the mean.\n Add a geom_errorbar() for errorbars (edit your existing code):\n\nggplot() +\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) \n\n\n\n\n\n\n\nNotice:\n\ngeom_errorbar() is the geom to plot error bars\nwe have given the data argument and the aesthetics inside the geom.\nthe variables given in the aes(), species, mean and se, are columns in the dataframe, seal_summary, given in the data argument.\n\nWe would like to add the mean. You could use geom_point() but I like to use another geom_errorbar() to get a line by setting ymin and ymax to the mean.\n Add a geom_errorbar() for the mean (edit your existing code):\n\nggplot() +\n  # raw data\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  # error bars\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  # line for the mean\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean, ymax = mean),\n                width = 0.2)\n\n\n\n\n\n\n\n Alter the axis labels and limits using scale_y_continuous() and scale_x_discrete() (edit your existing code):\n\nggplot() +\n  # raw data\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  # error bars\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  # line for the mean\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Myoglobin (g/kg)\", \n                     limits = c(0, 80), \n                     expand = c(0, 0)) +\n  scale_x_discrete(name = \"Species\")\n\n\n\n\n\n\n\nYou only need to use name in scale_y_continuous() and scale_x_discrete() to use labels that are different from those in the dataset. Often this is to use proper terminology and captialisation.\n Format the figure in a way that is more suitable for including in a report using theme_classic() (edit your existing code):\n\nggplot() +\n  # raw data\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  # error bars\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  # line for the mean\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Myoglobin (g/kg)\", \n                     limits = c(0, 80), \n                     expand = c(0, 0)) +\n   scale_x_discrete(name = \"Species\") +\n  theme_classic()\n\n\n\n\n\n\n\nWriting figures to file\n Make a new folder called figures.\n Edit your ggplot code so that you assign the figure to a variable.\n\nsealfig &lt;- ggplot() +\n  # raw data\n  geom_point(data = seal, aes(x = species, y = myoglobin),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"grey50\") +\n  # error bars\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  # line for the mean\n  geom_errorbar(data = seal_summary, \n                aes(x = species, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Myoglobin (g/kg)\", \n                     limits = c(0, 80), \n                     expand = c(0, 0)) +\n  scale_x_discrete(name = \"Species\") +\n  theme_classic()\n\nThe figure won‚Äôt be shown in the Plots tab - the output has gone into sealfig rather than to the Plots tab. To make it appear in the Plots tab type sealfig\nThere is a command to save the figure to a file. This is useful if you want to include the figure in a report or presentation especially if you want good control over the size and format of multiple figures.\n The ggsave() command will write a ggplot figure to a file:\n\nggsave(\"figures/seal-muscle.png\",\n       plot = sealfig,\n       device = \"png\",\n       width = 4,\n       height = 3,\n       units = \"in\",\n       dpi = 300)\n\nfiguresseal-muscle.png is the name of the file, including the relative path.\n Look up ggsave() in the manual to understand the arguments. You can do this by putting your cursor on the command and pressing F1",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-9/workshop.html#pigeons",
    "href": "r4babs1/week-9/workshop.html#pigeons",
    "title": "Workshop",
    "section": "Pigeons",
    "text": "Pigeons\nThe data in pigeon.txt are 40 measurements of interorbital width (in mm) for two populations of domestic pigeons measured to the nearest 0.1mm\n\n\nInterorbital width is the distance between the eyes\n\nImport\n Save pigeon.txt to your data-raw folder.\n Read the data into a dataframe called pigeons.\n What variables are there in the pigeons dataframe?\n\n\n\n\nHummmm, these data are not organised like the other data sets we have used. The population is given as the column names and the interorbital distances for one population are given in a different column than those for the other population. The first row has data from two pigeons which have nothing in common, they just happen to be the first individual recorded in each population.\n\n\n\n\n\nA\nB\n\n\n\n12.4\n12.6\n\n\n11.2\n11.3\n\n\n11.6\n12.1\n\n\n12.3\n12.2\n\n\n11.8\n11.8\n\n\n10.7\n11.5\n\n\n11.3\n11.2\n\n\n11.6\n11.9\n\n\n12.3\n11.2\n\n\n10.5\n12.1\n\n\n12.1\n11.9\n\n\n10.4\n10.7\n\n\n10.8\n11.0\n\n\n11.9\n12.2\n\n\n10.9\n12.6\n\n\n10.8\n11.6\n\n\n10.4\n10.7\n\n\n12.0\n12.4\n\n\n11.7\n11.8\n\n\n11.3\n11.1\n\n\n11.5\n12.9\n\n\n11.8\n11.9\n\n\n10.3\n11.1\n\n\n10.3\n12.2\n\n\n11.5\n11.8\n\n\n10.7\n11.5\n\n\n11.3\n11.2\n\n\n11.6\n11.9\n\n\n13.3\n11.2\n\n\n10.7\n11.1\n\n\n12.1\n11.6\n\n\n10.2\n12.7\n\n\n10.8\n11.0\n\n\n11.4\n12.2\n\n\n10.9\n11.3\n\n\n10.3\n11.6\n\n\n10.4\n12.2\n\n\n10.0\n12.4\n\n\n11.2\n11.3\n\n\n11.3\n11.1\n\n\n\n\n\n\n\nThis data is not in ‚Äòtidy‚Äô format (Wickham 2014).\nTidy format has variables in columns and observations in rows. All of the distance measurements should be in one column with a second column giving the population.\n\n\n\n\n\npopulation\ndistance\n\n\n\nA\n12.4\n\n\nB\n12.6\n\n\nA\n11.2\n\n\nB\n11.3\n\n\nA\n11.6\n\n\nB\n12.1\n\n\nA\n12.3\n\n\nB\n12.2\n\n\nA\n11.8\n\n\nB\n11.8\n\n\nA\n10.7\n\n\nB\n11.5\n\n\nA\n11.3\n\n\nB\n11.2\n\n\nA\n11.6\n\n\nB\n11.9\n\n\nA\n12.3\n\n\nB\n11.2\n\n\nA\n10.5\n\n\nB\n12.1\n\n\nA\n12.1\n\n\nB\n11.9\n\n\nA\n10.4\n\n\nB\n10.7\n\n\nA\n10.8\n\n\nB\n11.0\n\n\nA\n11.9\n\n\nB\n12.2\n\n\nA\n10.9\n\n\nB\n12.6\n\n\nA\n10.8\n\n\nB\n11.6\n\n\nA\n10.4\n\n\nB\n10.7\n\n\nA\n12.0\n\n\nB\n12.4\n\n\nA\n11.7\n\n\nB\n11.8\n\n\nA\n11.3\n\n\nB\n11.1\n\n\nA\n11.5\n\n\nB\n12.9\n\n\nA\n11.8\n\n\nB\n11.9\n\n\nA\n10.3\n\n\nB\n11.1\n\n\nA\n10.3\n\n\nB\n12.2\n\n\nA\n11.5\n\n\nB\n11.8\n\n\nA\n10.7\n\n\nB\n11.5\n\n\nA\n11.3\n\n\nB\n11.2\n\n\nA\n11.6\n\n\nB\n11.9\n\n\nA\n13.3\n\n\nB\n11.2\n\n\nA\n10.7\n\n\nB\n11.1\n\n\nA\n12.1\n\n\nB\n11.6\n\n\nA\n10.2\n\n\nB\n12.7\n\n\nA\n10.8\n\n\nB\n11.0\n\n\nA\n11.4\n\n\nB\n12.2\n\n\nA\n10.9\n\n\nB\n11.3\n\n\nA\n10.3\n\n\nB\n11.6\n\n\nA\n10.4\n\n\nB\n12.2\n\n\nA\n10.0\n\n\nB\n12.4\n\n\nA\n11.2\n\n\nB\n11.3\n\n\nA\n11.3\n\n\nB\n11.1\n\n\n\n\n\n\n\nData which is in tidy format is easier to summarise, analyses and plot because the organisation matches the conceptual structure of the data:\n\nit is more obvious what the variables are because they columns are named with them - in the untidy format, that the measures are distances is not clear, and what A and B are isn‚Äôt clear\nit is more obvious that there is no relationship between any of the pigeons except for population\nfunctions are designed to work with variables in columns\nTidying data\nWe can put this data in such a format with the pivot_longer() function from the tidyverse:\npivot_longer() collects the values from specified columns (cols) into a single column (values_to) and creates a column to indicate the group (names_to).\n Put the data in tidy format:\n\npigeons &lt;- pivot_longer(data = pigeons, \n                        cols = everything(), \n                        names_to = \"population\", \n                        values_to = \"distance\")\n\nWe have overwritten the original dataframe. If you wanted to keep the original you would need to give a new name on the left side of the assignment &lt;- Note: the actual data in the file are unchanged, only the dataframe in R is changed.",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-9/workshop.html#ulna-and-height",
    "href": "r4babs1/week-9/workshop.html#ulna-and-height",
    "title": "Workshop",
    "section": "Ulna and height",
    "text": "Ulna and height\nThe datasets we have used up to this point, have had a continuous variable and a categorical variable where it makes sense to summarise the response for each of the different groups in the categorical variable and plot the response on the y-axis. We will now summarise a dataset with two continuous variables. The data in height.txt are the ulna length (cm) and height (m) of 30 people. In this case, it is more appropriate to summarise both of thee variables and to plot them as a scatter plot.\nWe will use summarise() again but we do not need the group_by() function this time. We will also need to use each of the summary functions, such as mean(), twice, once for each variable.\nImport\n Save height.txt to your data-raw folder\n Read the data into a dataframe called ulna_heights.\nSummarise\n Create a data frame called ulna_heights_summary that contains the sample size and means, standard deviations and standard errors for both variables.\n\nulna_heights_summary &lt;- ulna_heights |&gt;\n  summarise(n = length(ulna),\n            mean_ulna = mean(ulna),\n            std_ulna = sd(ulna),\n            se_ulna = std_ulna/sqrt(n),\n            mean_height = mean(height),\n            std_height = sd(height),\n            se_height = std_height/sqrt(n))\n\nYou should get the following numbers:\n\n\n\n\nn\nmean_ulna\nstd_ulna\nse_ulna\nmean_height\nstd_height\nse_height\n\n\n30\n24.72\n4.137332\n0.75537\n1.494\n0.2404823\n0.0439059\n\n\n\n\nVisualise\nTo plot make a scatter plot we need to use geom_point() again but without any scatter. In this case, it does not really matter which variable is on the x-axis and which is on the y-axis.\n Make a simple scatter plot:\n\nggplot(data = ulna_heights, aes(x = ulna, y = height)) +\n  geom_point()\n\n\n\n\n\n\n\nIf you have time, you may want to format the figure more appropriately.",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-9/workshop.html#look-after-future-you",
    "href": "r4babs1/week-9/workshop.html#look-after-future-you",
    "title": "Workshop",
    "section": "Look after future you!",
    "text": "Look after future you!\nFuture you is going to summarise and plot data from the ‚ÄúRiver practicals‚Äù. You can make this much easier by documenting what you have done now. Go through your script (summarise-plot-data-with-several-vars.R) and remove code that you do not need. Add comments to the code you do need to explain what it does.\n\n\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-9/workshop.html#footnotes",
    "href": "r4babs1/week-9/workshop.html#footnotes",
    "title": "Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\n‚ÄúCreate a dataframe called seal_summary‚Äù means assign the output of the group_by() and summarise() code to something called seal_summary.‚Ü©Ô∏é",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-9/study_before_workshop.html",
    "href": "r4babs1/week-9/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read From importing to reporting. The first part of this chapter is about data import which we covered in the last workshop. You may be able to skip that part or you may find it useful to revise. The section on Summarising data will be mainly new.",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs1/week-9/overview.html",
    "href": "r4babs1/week-9/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Last week you summarised and plotted data sets with one variable. This week you will start plotting data sets with more than one variable. This means you need to be able determine which variable is the response and which is the explanatory. You will find out what is meant by ‚Äútidy‚Äù data and how to perform a simple data tidying task. Finally you will discover how to save your figures to file.\n\nLearning objectives\n\nsummarise and plot, appropriately, datasets with more than one variable\nrecognise that variables can be categorised by their role in analysis\nexplain what is meant by ‚Äòtidy‚Äô data and be able to perform some data tidying tasks.\nsave figures to file by scripting\n\n\n\nInstructions\n\nPrepare\n\nüìñ From importing to reporting\n\nWorkshop\n\nüíª Summarise and plot datasets with more than one variable.\nüíª Practice with working directories, importing data, formatting figures and the pipe\nüíª Script saving figures to file for reproducibility\n\nConsolidate\n\nüíª Summarise and plot a dataframe from the workshop\nüíª Practice the complete RStudio Project worklfow for a new dataset",
    "crumbs": [
      "BABS 1",
      "Week 9: Summarising data with several variables",
      "About"
    ]
  },
  {
    "objectID": "r4babs1/week-8/study_before_workshop.html",
    "href": "r4babs1/week-8/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read Ideas about data",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs1/week-8/overview.html",
    "href": "r4babs1/week-8/overview.html",
    "title": "Overview",
    "section": "",
    "text": "The type of values our data can take is important in how we analyse and visualise it. This week you will learn the difference between continuous and discrete values and how we summarise and visualise them. You will also learn about the ‚Äúnormal distribution‚Äù which is the most important continuous distribution.\n\n\n\nDiscrete variable\n\n\n\nLearning objectives\nThe successful student will be able to:\n\ndistinguish between continuous, discrete, nominal and ordinal variable\nread in data in to RStudio from a plain text file and Excel files\nsummarise and plot variables appropriately for the data type\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read: Ideas about data\n\nWorkshop\n\nüíª Importing data\nüíª Summarising discrete data\nüíª Summarising count data\nüíª Summarising continuous data\n\nConsolidate\n\nüíª Summarise some data\nüíª Plot some data\nüíª Format a plot (1)\nüíª Format a plot (2)\nüìñ Read Understanding the pipe |&gt;",
    "crumbs": [
      "BABS 1",
      "Week 8: Types of variable, summarising and plotting data",
      "About"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html",
    "href": "r4babs1/week-7/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚ÄúWelcome to Rstats‚Äù\n\n\nIn this workshop you will use RStudio to write R code. You will type in some data, plot it and then customise your plot.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#session-overview",
    "href": "r4babs1/week-7/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will use RStudio to write R code. You will type in some data, plot it and then customise your plot.",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#philosophy",
    "href": "r4babs1/week-7/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#coat-colour-of-cats",
    "href": "r4babs1/week-7/workshop.html#coat-colour-of-cats",
    "title": "Workshop",
    "section": "üêà Coat colour of cats",
    "text": "üêà Coat colour of cats\nThe goal\nWe will work with some data on the coat colour of 62 cats. You are going to type data in R, summarise and plot it\nThe data are as a frequency table:\n\n\n\nFrequency of coat colours in 62 cats\n\nCoat colour\nNo. cats\n\n\n\nblack\n23\n\n\nwhite\n15\n\n\ntabby\n8\n\n\nginger\n10\n\n\ntortoiseshell\n5\n\n\ncalico\n1\n\n\n\n\n\nYou will create a figure like this:",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#creating-the-data",
    "href": "r4babs1/week-7/workshop.html#creating-the-data",
    "title": "Workshop",
    "section": "Creating the data",
    "text": "Creating the data\nStart by making a vector called coat that holds coat colours\n Write the following in your script:\n\n# coat colours\ncoat &lt;- c(\"black\", \"white\", \"tabby\", \"ginger\", \"tortoiseshell\", \"calico\")\n\nRemember, the shortcut for &lt;- is Alt+- (hold the Alt key down then hit the minus key ).\nNotice I have used a comment. Comment your code as much as possible!\n Ensure your cursor is on the line with the command and do Control+Enter to send the command to the console to be executed.\n Examine the ‚Äòstructure‚Äô of the coat object using str()\n\nstr(coat)\n\n chr [1:6] \"black\" \"white\" \"tabby\" \"ginger\" \"tortoiseshell\" \"calico\"\n\n\nIt‚Äôs vector of 6 character values, chr\n Create a vector called freq containing the numbers of cats with each coat colour and examine it with str().\n Check sum(freq) gives the answer you expect:\n\n# the total Number of cats\nsum(freq)\n\n[1] 62",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#packages",
    "href": "r4babs1/week-7/workshop.html#packages",
    "title": "Workshop",
    "section": "Packages",
    "text": "Packages\nCommands like c(), sum(), and str() are in packages which are part the ‚Äòbase‚Äô R system. A package is a collection of related commands. Base packages are installed automatically when you install R.\nOther packages, such as ggplot2 (Wickham 2016) need to be installed once and then loaded each session. ggplot2 is one of the tidyverse (Wickham et al. 2019) packages.\n\n\n\n\n\n\nImportant\n\n\n\nIf you are working on a University computer (or the VDS) you do not need to install tidyverse.\nIf you are working on your own computer or using RStudio cloud you do need to install tidyverse.\n\n\nTo install a package:\n Go the Packages tab on the lower right pane. Click Install and type tidyverse into the box that appears. DO not do if working on a Uni computer.\nWait until you get the prompt back. It will take a few moments, be patient!\nTo use a package which is installed you have to load it with the library() function. You will need to do this whether you are working on your own computer or on a University computer\n Load the tidyverse:\n\nlibrary(tidyverse)\n\nYou will likely be warned of some function name conflicts but these will not be a problem for you.",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#plotting-the-data-with-ggplot",
    "href": "r4babs1/week-7/workshop.html#plotting-the-data-with-ggplot",
    "title": "Workshop",
    "section": "Plotting the data with ggplot()\n",
    "text": "Plotting the data with ggplot()\n\nggplot() takes a dataframe for an argument\nWe can make a dataframe of the two vectors, coat and freq using the data.frame() function.\n Make a dataframe called coat_data\n\ncoat_data &lt;- data.frame(coat, freq)\n\n Check the structure of coat_data\nClick on coat_data in the Environment to open a spreadsheet-like view of it.",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#a-barplot",
    "href": "r4babs1/week-7/workshop.html#a-barplot",
    "title": "Workshop",
    "section": "A barplot",
    "text": "A barplot\n Create a simple barplot using ggplot like this:\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col()\n\n\n\n\n\n\n\nggplot() alone creates a blank plot.\nggplot(data = coat_data) looks the same.\naes() gives the ‚ÄòAesthetic mappings‚Äô. How variables (columns) are mapped to visual properties (aesthetics) e.g., axes, colour, shapes.\nThus‚Ä¶\nggplot(data = coat_data, aes(x = coat, y = freq)) produces a plot with axes\ngeom_col A ‚ÄòGeom‚Äô (Geometric object) gives the visual representations of the data: points, lines, bars, boxplots etc.\nNote that ggplot2 is the name of the package and ggplot() is its most important command.",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#using-the-help-manual",
    "href": "r4babs1/week-7/workshop.html#using-the-help-manual",
    "title": "Workshop",
    "section": "Using the help manual",
    "text": "Using the help manual\n‚ÄòArguments‚Äô can be added to the geom_col() command inside the brackets.\nCommands do something and their arguments (in brackets) and can specify:\n\nwhat object to do it to\n\nhow exactly to do it\n\nMany arguments have defaults so you don‚Äôt always need to supply them.\n Open the manual page for geom_col() using:\n\n?geom_col\n\nThe manual page has several sections.\n\n\nDescription an overview of what the command does\n\n\nUsage lists arguments\n\nform: argument name = default value\n\nsome arguments MUST be supplied others have defaults\n\n... means etc and includes arguments that can be passed to many ‚Äògeoms‚Äô\n\n\n\nArguments gives the detail about the arguments\n\nDetails describes how the command works in more detail\n\n\nValue gives the output of the command\nDon‚Äôt be too perturbed by not fully understanding the information",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#customising-the-plot",
    "href": "r4babs1/week-7/workshop.html#customising-the-plot",
    "title": "Workshop",
    "section": "Customising the plot",
    "text": "Customising the plot\nBar colour\n Change the fill of the bars using fill:\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col(fill = \"lightblue\")\n\n\n\n\n\n\n\nColours can be given by their name, ‚Äúlightblue‚Äù or code, ‚Äú#ADD8E6‚Äù.\nLook up by name or code\n Change the bars to a colour you like.\nfill is one of the arguments covered by .... fill is an ‚Äòaesthetic‚Äô. If you look for ... in the list of arguments you will see it says:\n\nOther arguments passed on to layer(). These are often aesthetics, used to set an aesthetic to a fixed value, like colour = ‚Äúred‚Äù or size = 3. They may also be parameters to the paired geom/stat.\n\nWe just set the `fill` aesthetic to a fixed value.\nFurther down the manual, there is a section on Aesthetics which lists those understood by geom_col()\nWe can set (map) the fill aesthetic to a fixed colour inside geom_col() or map it to a variable from the dataframe inside the aes() instead. This means the colour will be different for different values in that variable.\n Map the fill aesthetic to the coat variable:\n\nggplot(data = coat_data, aes(x = coat, y = freq, fill = coat)) +\n  geom_col()\n\n\n\n\n\n\n\nNote that we have taken fill = \"lightblue\" out of the geom_col() and instead put fill = coat in the aes().\n Use the manual to put the bars next to each other. Look for the argument that will mean there is no space between the bars.\n\n\n\n\n\n\n\n\n Use the manual to change the colour of the lines around each bar to black.\n\n\n\n\n\n\n\n\nChanging the axes\nWe can make changes to the axes using:\n\nChanges to a discrete x axis: scale_x_discrete()\n\nChanges to a continuous y axis: scale_y_continuous()\n\n\nggplot automatically extends the axes slightly. You can turn this behaviour off with the expand argument in scale_x_discrete() and scale_y_continuous().1\n Remove the gap between the axes and the data:\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col(fill = \"lightblue\", \n           width = 1, \n           colour = \"black\") +\n  scale_x_discrete(expand = c(0, 0)) + \n  scale_y_continuous(expand = c(0, 0)) \n\n\n\n\n\n\n\nEach ‚Äòlayer‚Äô is added to the ggplot() command with a +\n\n\n\n\n\n\nTop Tip\n\n\n\nMake your code easier to read by using white space and new lines\n\nput spaces around = , -&gt; and after ,\n\nuse a newline after every comma in a command with lots of arguments\n\n\n\n Look up scale_x_discrete in the manual and work out how to change the axis title from ‚Äúcoat‚Äù to ‚ÄúCoat colour‚Äù. Also change the y-axis title.\n\n\n\n\n\n\n\n\n I would prefer to see the y-axis extend a little beyond the data and we can change the axis ‚Äúlimits‚Äù in the scale_y_continuous()\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col(fill = \"lightblue\", \n           width = 1, \n           colour = \"black\") +\n  scale_x_discrete(expand = c(0, 0),\n                   name = \"Coat colour\") + \n  scale_y_continuous(expand = c(0, 0),\n                     name = \"Number of cats\",\n                     limits = c(0, 25)) \n\n\n\n\n\n\n\nGetting rid of the grey background\nThe grey grid background is useful for examining plots on a screen but for a report of publication you will want a more scientific style. Every aspect of the ‚Äútheme‚Äù of a plot - the non-data elements such as fonts, background colours, axis line colours etc - can be controlled individually2 but there are some handy built in themes that apply several changes at once. One of these is theme_classic()\n Add theme_classic() to the plot:\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col(width = 1, \n           colour = \"black\",\n           fill = \"lightblue\") +\n  scale_x_discrete(expand = c(0, 0),\n                   name = \"Coat colour\") + \n  scale_y_continuous(expand = c(0, 0),\n                     name = \"Number of cats\",\n                     limits = c(0, 25)) +\n  theme_classic()\n\n\n\n\n\n\n\nChanging the order of bars\nThe default ordering of a categorical variable like coat is alphabetical. Often we want to change the order. For example, you might want a ‚ÄúControl‚Äù on the left or the categories might have an inherent order (e.g., small, medium and large). We can alter (mutate) the coat variable using fct_relevel().\n Make ‚Äúwhite‚Äù the first category:\n\ncoat_data &lt;- coat_data |&gt; \n  mutate(coat = fct_relevel(coat, \"white\"))\n\n\n\n\n\n\n\nThe pipe |&gt;\n\n\n\n|&gt; is called the ‚Äúpipe‚Äù. A keyboard shortcut is Control+Shift+M\nThe pipe puts the output of one command (one the left) as input to another command (on the right). It can be read as ‚Äúand then‚Äù. You will more about it next week.\n\n\n Now plot again.\n\n\n\n\n\n\n\n\nIf you wanted white and then ginger you would do fct_relevel(coat, c(\"white\", \"ginger\")\nWe can also order the categories by the values in another variable by using reorder() in the plot code.\n Reorder the categories in coat by the the value in freq:\n\nggplot(data = coat_data, \n       aes(x = reorder(coat, freq, decreasing = TRUE), \n           y = freq)) +\n  geom_col(width = 1, \n           colour = \"black\",\n           fill = \"lightblue\") +\n  scale_x_discrete(expand = c(0, 0),\n                   name = \"Coat colour\") + \n  scale_y_continuous(expand = c(0, 0),\n                     name = \"Number of cats\",\n                     limits = c(0, 25)) +\n  theme_classic()\n\n\n\n\n\n\n\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/workshop.html#footnotes",
    "href": "r4babs1/week-7/workshop.html#footnotes",
    "title": "Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\nThere are also scale_x_continous() and scale_y_discrete() functions when you have those types of variable‚Ü©Ô∏é\nModify components of a theme‚Ü©Ô∏é",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#outline",
    "href": "r4babs1/week-7/rstudio-projects.html#outline",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Outline",
    "text": "Outline\n\nWho\nA One-line what\nThe high-level why\n\n\nMight be enough!\n\n\n\nMore detailed why\nMore detailed what"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#audience",
    "href": "r4babs1/week-7/rstudio-projects.html#audience",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Audience",
    "text": "Audience\n\nYou teach using R directly\n\nBecoming a Bioscientist 1 - 4\nIM group project\nPGT\n\nYou teach or supervise students using R\n\nfield courses, practical work\nprojects\n\nYou use R"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#an-rstudio-project",
    "href": "r4babs1/week-7/rstudio-projects.html#an-rstudio-project",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "üìÅ An RStudio Project",
    "text": "üìÅ An RStudio Project\n\nis a folder!\n\n\n\nhave been part of the stage 1 and IM stage 3 for &gt; 5 years\n\n\n\nStage 1\n\nUse an RStudio project containing the script you used to analyse and plot the data for your report, your figures and and the data itself. The Project should be structured and the script should be well-commented, well-organised and follow good practice in the use of spacing, indentation, and variable naming. It should include all the code required to reproduce data import and formatting as well as the summary information, analyses, and figures in your report."
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#y12345678",
    "href": "r4babs1/week-7/rstudio-projects.html#y12345678",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Y12345678",
    "text": "Y12345678\ndemo"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#babs-1-4-lo-progression",
    "href": "r4babs1/week-7/rstudio-projects.html#babs-1-4-lo-progression",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "BABS 1-4 LO progression",
    "text": "BABS 1-4 LO progression\nBABS 1-5 LO progression"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#why-use-rstudio-projects",
    "href": "r4babs1/week-7/rstudio-projects.html#why-use-rstudio-projects",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Why use RStudio Projects",
    "text": "Why use RStudio Projects\n\nthe same reason we keep lab books: reproducibility and validation\n\n\nIt‚Äôs science!\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#why-use-rstudio-projects-1",
    "href": "r4babs1/week-7/rstudio-projects.html#why-use-rstudio-projects-1",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Why use RStudio Projects",
    "text": "Why use RStudio Projects\n\nTransferable: explicit training in organising work"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#why-use-rstudio-projects-2",
    "href": "r4babs1/week-7/rstudio-projects.html#why-use-rstudio-projects-2",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Why use RStudio Projects",
    "text": "Why use RStudio Projects\n\n\n\nhelp you to work with your most important collaborator\n\n\n\n\n\nfutureself, CC-BY-NC, by Julen Colomb"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#section",
    "href": "r4babs1/week-7/rstudio-projects.html#section",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "",
    "text": "via GIPHY"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#working-directories-and-paths",
    "href": "r4babs1/week-7/rstudio-projects.html#working-directories-and-paths",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Working directories and Paths",
    "text": "Working directories and Paths\n\ndirectory means folder\nimportant concepts when you interact with computers without clicking\n\n\nAllison Horst cartoon ‚Äúcode gets the blame‚Äù"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#working-directories",
    "href": "r4babs1/week-7/rstudio-projects.html#working-directories",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Working directories",
    "text": "Working directories\n\nDefault folder a program will read and write to.\nYou will have some understanding\n\nWord demo"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#paths",
    "href": "r4babs1/week-7/rstudio-projects.html#paths",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Paths",
    "text": "Paths\n\nlocation of a file/folder\nappear in the address bar of explorer/finder and browsers\n\ndemo\n\n\nwhen you can‚Äôt click, you need the path\n\n\nchaffinch &lt;- read_table(\"chaff.txt\")"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#absolute-path",
    "href": "r4babs1/week-7/rstudio-projects.html#absolute-path",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Absolute path",
    "text": "Absolute path\n\nchaffinch &lt;- read_table(\"C:/Users/er13/OneDrive - University of York/Desktop/Desktop/undergrad-teaching-york/BIO00017C/BIO00017C-Data-Analysis-in-R-2020/data/chaff.txt\")\n\n\nOnly exists on my computer!"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#relative-paths",
    "href": "r4babs1/week-7/rstudio-projects.html#relative-paths",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Relative paths",
    "text": "Relative paths\n\nlocation of a file/folder relative to the working directory\nIf my working directory is BIO00017C-Data-Analysis-in-R-2020:\n\n\nchaffinch &lt;- read_table(\"data/chaff.txt\")"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#rstudio-projects",
    "href": "r4babs1/week-7/rstudio-projects.html#rstudio-projects",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nSets the working directory to be the project folder\nCode is portable: you send someone the folder and everything just works!"
  },
  {
    "objectID": "r4babs1/week-7/rstudio-projects.html#demo",
    "href": "r4babs1/week-7/rstudio-projects.html#demo",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "demo",
    "text": "demo"
  },
  {
    "objectID": "r4babs1/week-7/overview.html",
    "href": "r4babs1/week-7/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week you will start using RStudio to write R code and you will create your first graph! You will learn about data types such as ‚Äúnumerics‚Äù and ‚Äúcharacters‚Äù and object types such as ‚Äúvectors‚Äù and ‚Äúdataframes‚Äù. These are the building blocks for the rest of your R journey. You will also learn about the layout of RStudio and a workflow using scripts and RStudio Projects to keep your work organised.\n\n\n\nArtwork by Horst (2023): ‚Äúbless this workflow‚Äù\n\n\n\nLearning objectives\nThe successful student will be able to:\n\nuse the R command line as a calculator and to assign variables\ncreate and use the basic data types in R\nfind their way around the RStudio windows\nuse an RStudio Project to organise work\nuse a script to run R commands\ncreate and customise a barplot\nsearch and understand manual pages\n\n\n\nInstructions\n\nPrepare\n\nFirst Steps in RStudio: Either üìñ Read the book OR üìπ Watch two videos\n\nWorkshop\n\nüíª üêà Coat colour of cats. Type in some data, perform calculations on, and plot it.\n\nConsolidate\n\nüíª Create a plot\nüìñ Read Workflow in RStudio\n\n\n\n\n\n\n\nReferences\n\nHorst, Allison. 2023. ‚ÄúData Science Illustrations.‚Äù https://allisonhorst.com/allison-horst.",
    "crumbs": [
      "BABS 1",
      "Week 7: Introduction to R and project organisation",
      "About"
    ]
  },
  {
    "objectID": "r4babs1/week-6/study_before_workshop.html",
    "href": "r4babs1/week-6/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ If you have not done so already, read An overview of Data Analysis in R for BABS in your degree and An overview of Data Analysis in R for BABS 1. Both are also linked on the VLE.\nüìñ Read What they forgot to teach you about computers in Computational Analysis for Bioscientists\nüìñ Read What are R and Rstudio?. You only need to read this section, you do not need to the read the rest of the chapter (yet!)\nüñ•Ô∏è Join the video conference Intro: Data Handling - BIO00027C-A (Lecture) on your timetable. The main purpose of this session is to highlight how Data Analysis in R for BABS 1 is organised and give you an opportunity to ask questions.",
    "crumbs": [
      "BABS 1",
      "Week 6: Understanding file systems",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs1/week-6/overview.html",
    "href": "r4babs1/week-6/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week you will carry out some independent study to ensure you have some understanding of computer file systems. We will introduce you to the concepts of paths and working directories. You will also set your own machine up to use the Virtual Desktop Service which allows you to log in to a university machine from your own computer so you can work easily at home outside of workshops.\n\n\n\nArtwork by Horst (2023): ‚Äúcode gets the blame‚Äù\n\n\n\nLearning objectives\nThe parentheses after each learning objective indicate where the content covers that objective.\nThe successful student will be able to:\n\nexplain what an operating system is\nexplain the organisation of files and directories in a file systems\nexplain what a file is and give some common files types\nexplain what is meant by a plain text file\nexplain the relationship between the file extensions, the file format and associations with programs\nuse a file manager\nexplain root, home and working directories\nexplain absolute and relative file paths\nknow what R and RStudio are\nknow how to organise their work\nuse the Virtual Desktop Service\n\n\n\nInstructions\n\nPrepare\n\nIf you have not done so already, read ‚ÄúAn overview of Data Analysis in R for BABS‚Äù in your degree and ‚ÄúAn overview of Data Analysis in R for BABS 1‚Äù\nRead What they forgot to teach you about computers\nRead What are R and Rstudio?\nJoin the video conference Intro: Data Handling - BIO00027C-A (Lecture) on your timetable\n\nWorkshop\n\nSet up the Virtual Desktop Service\n\nConsolidate\n\n\n\n\n\n\nReferences\n\nHorst, Allison. 2023. ‚ÄúData Science Illustrations.‚Äù https://allisonhorst.com/allison-horst.",
    "crumbs": [
      "BABS 1",
      "Week 6: Understanding file systems",
      "About"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html",
    "href": "r4babs4/week-1/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "In the first part of the workshop I will talk about Project organisation for reproducible analysis and data that has many variables and observations. In the second part of the workshop you will practice getting an overview of such data with summaries and distribution plots, filtering rows and columns.",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#session-overview",
    "href": "r4babs4/week-1/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In the first part of the workshop I will talk about Project organisation for reproducible analysis and data that has many variables and observations. In the second part of the workshop you will practice getting an overview of such data with summaries and distribution plots, filtering rows and columns.",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#why-does-it-matter",
    "href": "r4babs4/week-1/workshop.html#why-does-it-matter",
    "title": "Workshop",
    "section": "Why does it matter?",
    "text": "Why does it matter?\n\n\nfutureself, CC-BY-NC, by Julen Colomb\n\n\nFive selfish reasons to work reproducibly (Markowetz 2015). Alternatively, see the very entertaining talk which covers the the ‚ÄúDuke Scandal‚Äù.\nMany high profile cases of work which did not reproduce e.g.¬†Anil Potti‚Äôs work unravelled by Baggerly and Coombes (2009) in the ‚ÄúDuke Scandal‚Äù\nWill become standard in Science and publishing e.g OECD Global Science Forum Building digital workforce capacity and skills for data-intensive science (OECD Global Science Forum 2020)",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#how-to-achieve-reproducibility",
    "href": "r4babs4/week-1/workshop.html#how-to-achieve-reproducibility",
    "title": "Workshop",
    "section": "How to achieve reproducibility",
    "text": "How to achieve reproducibility\n\nScripting\nOrganisation: Project-oriented workflows with file and folder structure, naming things\nDocumentation: Comment your code.",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#project-oriented-workflow",
    "href": "r4babs4/week-1/workshop.html#project-oriented-workflow",
    "title": "Workshop",
    "section": "Project-oriented workflow",
    "text": "Project-oriented workflow\n\nuse folders to organise your work\nyou are aiming for structured, systematic and repeatable.\ninputs and outputs should be clearly identifiable from structure and/or naming\n\nExample\n-- stem-cells\n   |__stem-cells.Rproj\n   |__analysis.R\n   |__data-raw\n      |__2019-03-21_donor_1.csv\n      |__2019-03-21_donor_2.csv\n      |__2019-03-21_donor_3.csv\n   |__figures\n      |__01_volcano_donor_1_vs_donor_2.png\n      |__02_volcano_donor_1_vs_donor_3.png",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#set-up-a-project",
    "href": "r4babs4/week-1/workshop.html#set-up-a-project",
    "title": "Workshop",
    "section": "Set up a Project",
    "text": "Set up a Project\nüé¨ Start RStudio from the Start menu\nüé¨ Make an RStudio project. Be deliberate about where you create it so that it is a good place for you\nüé¨ Use the Files pane to make a folder for the data. I suggest data-raw/\nüé¨ Make a new script called core-data-analysis.R to carry out the rest of the work.",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#load-packages",
    "href": "r4babs4/week-1/workshop.html#load-packages",
    "title": "Workshop",
    "section": "Load packages",
    "text": "Load packages\nWe need the following packages for this workshop:\n\n\ntidyverse (Wickham et al. 2019): importing the meta data which is in a text file, working with the data once it is in a dataframe to filter, summarise and plot.\n\nüé¨ Load tidyverse\n\nlibrary(tidyverse)",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#look-at-the-data",
    "href": "r4babs4/week-1/workshop.html#look-at-the-data",
    "title": "Workshop",
    "section": "Look at the data!",
    "text": "Look at the data!\nIt is almost always useful to take a look at your data (or at least think about its format) before you attempt to read it in.\nWe will be working with the following data files in this workshop\n\nbiotech-cts.txt. These are RNA-Seq data from three replicates for each of two of wheat varieties (Susceptible and Tolerant) grown at two potassium conditions (Control K and Low K). The data are counts of the number of reads.\ncell-bio.tsv. These are measurements from a Livecyte microscope, which performs live cell imaging, tracking individual cells, and measurings cell shape and size parameters for thousands of cells as they grow and divide. Measurements are taken for three replicates from each of two cell lines A and B.\nimmuno.csv. These are flow cytometry data for three treatments with each of two antibodies. The measures are Forward scatter, side scatter, red fluorescence and green fluorescence.\nxlaevis_counts_S20.csv. These are RNA-Seq data from frogs. There are 2 siblings from each of three fertilisations and one sibling was treated with FGF and the other was a control. The data are counts of the number of reads.\n\nüé¨ Save these data files to the data-raw/ folder:\nüé¨ Consider the file extensions. What you think the extensions indicate?\n\n\n\n\n\n\n\n\nüé¨ Go to the Files pane click on the xlaevis_counts_S20.csv file and choose View File1\n\n\nRStudio Files Pane\n\nAny plain text file will open in the top left pane. Note that this is NOT importing the data, it‚Äôs just viewing the file.\nüé¨ Does it seem to be a csv file?\nüé¨ Try opening the other files from the Files pane. What happens?\nüé¨ Open each file in Excel. For the .txt and .tsv files you will need to show ‚ÄúAll files (.)‚Äù in the file type dropdown to see them and you will need to work through the ‚ÄúText Import Wizard‚Äù to open them.\nWe are opening them each in Excel to see what they look like and to get a sense of the structure of the data. We are not going to use Excel to do anything.\nüé¨ What do you notice? Does it look like this data will be easy to import and work with?",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#import-the-data",
    "href": "r4babs4/week-1/workshop.html#import-the-data",
    "title": "Workshop",
    "section": "Import the data",
    "text": "Import the data\nüé¨ Import each of the data files into R:\n\nbiotech &lt;- read_tsv(\"data-raw/biotech-cts.txt\")\n\n\ncell_bio &lt;- read_tsv(\"data-raw/cell-bio.tsv\")\n\n\nimmuno &lt;- read_csv(\"data-raw/immuno.csv\")\n\n\nfrogs &lt;- read_csv(\"data-raw/xlaevis_counts_S20.csv\")\n\nüé¨ Click on each of the dataframes in the Environment pane to see what they look like. An alternative to clicking is to use the View() function:\n\nView(cell_bio)\n\nüé¨ In each case, describe what is in the rows and the columns of the dataframe. Where are the replicates/samples and where are the variables? Are there any things you‚Äôd like to fix/change?\n\nüé¨ Name of the first column in the biotech dataframe:\n\nnames(biotech)[1] &lt;- \"transcript\"\n\nüé¨ Column names in the cell_bio dataframe:\n\ncell_bio &lt;- janitor::clean_names(cell_bio)",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#getting-an-overview-1",
    "href": "r4babs4/week-1/workshop.html#getting-an-overview-1",
    "title": "Workshop",
    "section": "Getting an overview 1",
    "text": "Getting an overview 1\nsummary()\nR‚Äôs summary() function is a quick way to get an overview of datasets. It gives you a six number summary for every numeric variable (the minimum, lower quartile, median, mean, upper quartile, and maximum). It also gives you a count of the number of missing values.\nüé¨ Use the summary() function to get an overview of each dataframe. It works well for these datasets. What types of dataset might this be less useful for? Which dataframes and columns have missing values? Which dataframes and variables seem very skewed? Which dataframe has more than one character variable?",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#quality-control",
    "href": "r4babs4/week-1/workshop.html#quality-control",
    "title": "Workshop",
    "section": "Quality Control",
    "text": "Quality Control\nFiltering rows\nThe filter function selects/drops a whole row on a condition. The condition can be based on the value in one, or a combination, of columns. We specify what we want to keep with the filter() function. This means you might often want to negate a condition with !.\nüé¨ To remove the rows in cell_bio with missing values in the perimeter column:\n\ncell_bio &lt;- cell_bio |&gt; filter(!is.na(perimeter))\n\nis.na(perimeter) returns a logical vector (a vector of TRUEs and FALSEs) of the same length as the column. The ! negates the logical vector so the TRUEs become FALSEs and the FALSEs become TRUE. This means that the filter() function keeps the rows where the perimeter column is not missing.\nüé¨ There‚Äôs actually a tidyverse function that does the same thing as filter(!is.na())\n\ncell_bio &lt;- cell_bio |&gt; drop_na(perimeter)\n\nSometimes you might want to work with a subset of data. For example, you might want to examine just the Media treated cells in the immuno dataset.\nüé¨ Create a new dataframe called immuno_media that contains only the rows where treatment is ‚ÄúMEDIA‚Äù\n\nimmuno_media &lt;- immuno |&gt; \n  filter(treatment == \"MEDIA\")\n\nOr just the Media treated cells with a FS_Lin between two values. You can apply two filters and the between() function to achieve this:\nüé¨ Create a new dataframe called immuno_media_live that contains only the rows where treatment is ‚ÄúMEDIA‚Äù and FS_Lin is between 7500 and 28000:\n\nimmuno_media_live &lt;- immuno |&gt;\n  filter(treatment == \"MEDIA\") |&gt;\n  filter(between(FS_Lin, 7500, 28000))\n\nüé¨ Now you try. Create a dataframe called immuno_live that contains only the rows where FS_Lin is between 7500 and 28000 and SS_Lin is between 15000 and 35000:\nSelecting columns\nWhilst we can always specify the columns we want to use when working with data, sometimes we find it less overwhelming to create a new dataframe with only the columns we want. The select() function help us here.\nüé¨ Suppose we only want to work with the Susceptible varieties of wheat in the biotech dataframe. We can create a new dataframe with only the columns we want:\n\nbiotech_susceptible &lt;- biotech |&gt; \n  select(SCK14_1,\n         SCK14_2,\n         SCK14_3,\n         SLK14_1,\n         SLK14_2,\n         SLK14_3)\n\nIn fact, there are a couple of alternatives to this. We can use the starts_with() function to select all the columns that start with a certain string:\nüé¨ Select columns starting with S\n\nbiotech_susceptible &lt;- biotech |&gt; \n  select(starts_with(\"S\"))\n\nThere is an ends_with() function too!\nüé¨ The colon notation allows us to select a range of columns. Select columns from SCK14_1 to SLK14_3\n\nbiotech_susceptible &lt;- biotech |&gt; \n  select(SCK14_1:SLK14_3)\n\nNote that you need to pay attention to the order of the columns in your dataframe to use this.\nüé¨ You can use select and filter together. Try creating a dataframe from frogs which has only the columns from sibling ‚Äú_A‚Äù and only the rows where S20_C_5 is above 20.\nVisualisation\nHistograms and density plots are useful for visualising the distribution of variables when we have many observations. Theya allow you to see features in the data that are not obvious from the summary statistics.\n\nA histogram shows the number of values in each range (bin), it is composed of touching bars. How a histogram looks depends on the number of bins used.\nA density plot shows the proportions on values in a range. The appearance of the distribution is not affected by the number of bins.\n\nüé¨ To plot a histogram of S20_C_5 in the frogs dataframe:\n\nfrogs |&gt; \n  ggplot(aes(x = S20_C_5)) +\n  geom_histogram() \n\n\n\n\n\n\n\nThis data is very skewed - there are so many low values that we can‚Äôt see the tiny bars for the higher values. Logging the counts is a way to make the distribution more visible.\nüé¨ To plot the distribution of log S20_C_5 in the frogs dataframe as a histogram:\n\nfrogs |&gt; \n  ggplot(aes(x = log10(S20_C_5))) +\n  geom_histogram() \n\n\n\n\n\n\n\nüé¨ Or a density plot:\n\nfrogs |&gt; \n  ggplot(aes(x = log10(S20_C_5))) +\n  geom_density()\n\n\n\n\n\n\n\nI‚Äôve used base 10 only because it is easy to convert to the original scale (1 is 10, 2 is 100, 3 is 1000 etc). The warning about rows being removed is expected - these are the counts of 0 since you can‚Äôt log a value of 0. The peak at zero suggests quite a few counts of 1. We would expect we would expect the distribution of counts to be roughly log normal because this is expression of all the genes in the genome2. That peak near the low end is not expected for this distribution and suggests that these lower counts might be anomalies.\nThe excess number of low counts indicates we might want to create a cut off for quality control. The removal of low counts is a common processing step in ‚Äôomic data.\nIf you have two groups of data, you can compare their distributions on the same plot using the fill aesthetic and making the fill transparent with the alpha argument.\nüé¨ To plot the distribution of area in the cell_bio dataframe as a density plot, with the clone variable as the fill:\n\ncell_bio |&gt; \n  ggplot(aes(x = area, fill = clone)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nBoxplots and violin plots are also useful for visualising the distribution of a variable, especially when there are more than about 5 groups.\nüé¨ To plot the distribution of area in the cell_bio dataframe as a boxplot, with the clone variable on the x-axis:\n\ncell_bio |&gt; \n  ggplot(aes(x = clone, y = area)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nSuppose you want to see the distribution of many similar variables such as we have in biotech. You cannot map a variable to x or fill as we did in the two previous cases because the values are in separate columns rather than than in one column with a second column giving a group. However, we can use the pivot_longer() function to reformat the data and then pipe it into ggplot.\nüé¨ Plot the distribution of the logged counts in the biotech dataframe as a boxplot, the samples on the x axis:\n\nbiotech |&gt; \n  pivot_longer(cols = -transcript,\n               names_to = \"sample\",\n               values_to = \"count\") |&gt; \n  ggplot(aes(x = sample, y = log10(count))) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\nThis code takes the biotech dataframe and transforms it dataset from wide format to long format. It takes all columns except transcript (cols = -transcript) and gathers them into two new columns:\n\n\n\"sample\" ‚Üí Stores the original column names (SCK14_1, SCK14_2, etc.).\n\n\"count\" ‚Üí Stores the values from those columns.\n\nNow, instead of multiple sample columns, we have a table like this:\n\n\ntranscript\nsample\ncount\n\n\n\nMSTRG.1\nSCK14_1\n560\n\n\nMSTRG.1\nSCK14_2\n1526\n\n\nMSTRG.1\nSCK14_3\n4168\n\n\nMSTRG.10\nSCK14_1\n0\n\n\n\nwhich is piped straight into ggplot. The nice thing about the pipe, is that you need not create a new dataframe to do this. You can pipe the output of pivot_longer() directly into ggplot(). This is very useful when you are exploring the data and want to try out different visualisations.\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/workshop.html#footnotes",
    "href": "r4babs4/week-1/workshop.html#footnotes",
    "title": "Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\nDo not be tempted to import data this way. Unless you are careful, your data import will not be scripted or will not be scripted correctly. This means your work will not be reproducible.‚Ü©Ô∏é\nThis a result of the¬†Central limit theorem,one consequence of which is that adding together lots of distributions - whatever distributions they are - will tend to a normal distribution.‚Ü©Ô∏é",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-1/study_after_workshop.html",
    "href": "r4babs4/week-1/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "üíª Set up the Virtual Desktop\nI very strongly recommend working on the University computers for this work. You will be using more specialised R packages than you might be used to. This is especially important if you often have difficulty updating and or installing software on your own machine, wouldn‚Äôt know what what version of R you are using or don‚Äôt realise there is a difference between R and RStudio. The uni machines always have up-to-date R and R packages and all the packages that appear in teaching materials. It is our responsibility to ensure everything works on here.\nYou can still work from home by using the Virtual Desktop Service. The VDS allows you to log on to a university computer from your own computer. It means you can access all software and filestores. When using the VDS for R and RStudio, it usually makes sense to use other software - such as a browser or file explorer - also through the VDS.\nIf you are confident in your ability to set up your own machine, you need:\n\nto know the difference between R and RStudio\nto use R 4.4 and RStudio 2024.09.0 Build 375 (‚ÄúCranberry Hibiscus‚Äù)\nbe certain you are actually using R 4.4 - it is written in the top edge of the console window. By default RStudio uses the latest version on R on your machine. However, windows users are able to change this to a ‚Äúspecific version‚Äù. You might have done that previously. Change it back using Tools | Global Options R version ‚ÄúUse your machine‚Äôs default 64-bit version of R‚Äù\nto make sure you do the independent study where it tells you what steps you need to take to get packages (and versions that are unlikely to cause issues) used in the workshop\n\nIt is possible to access all your files on your university account without using the VDS. For example, if you want to work on uni machines at uni and your machine at home. You can best do this by mapping a drive: https://support.york.ac.uk/s/topic/0TO4K000000lA5ZWAU/filestores. If you store everything on google drive you can also read/write to that like any other drive using google drive app.\nEven if you plan to use your own machine I really recommend you take the time to set the VDS up now while you‚Äôre not time pressured so you always have that option ready.",
    "crumbs": [
      "BABS 4",
      "Week 1: DA 1 Core",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html",
    "href": "r4babs4/week-2/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will learn how to analyse some sample flow cytometry data which is formatted in the same way as the data you will produce.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#session-overview",
    "href": "r4babs4/week-2/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will learn how to analyse some sample flow cytometry data which is formatted in the same way as the data you will produce.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#set-up",
    "href": "r4babs4/week-2/workshop.html#set-up",
    "title": "Workshop",
    "section": "Set up",
    "text": "Set up\nMake a RStudio Project\nüé¨ Start RStudio from the Start menu.\nüé¨ Make an RStudio project. Be deliberate about where you create it so that it is a good place for you.\nüé¨ Use the Files pane to make a folders for the data. I suggest data-raw/, data-processed/ and data-meta/\nüé¨ Make a new script called sample-data-analysis.R to carry out the rest of the work.\nüé¨ Record what you do and what you find out. All of it! Make notes on the inputs and outputs of each command. This will help you work out problems analysing your own data.\nLoad packages\nWe need three packages for this workshop:\n\ntidyverse (Wickham et al. 2019): importing the meta data which is in a text file, working with the data once it is in a dataframe to filter, summarise and plot.\nflowCore (Ellis et al. 2024): to import data from flow cytometry files (.fcs), apply the logicle transformation, and use functions for using a ‚ÄúflowSet‚Äù data structure.\nflowAI (Monaco et al. 2016): which performs automated quality control by checking for changes in instrument speed and signal intensity that indicate a problem for the reading for that cells\n\n\n\n\n\n\n\nWorking on University computers or using the Virtual Desktop Service\n\n\n\nThese packages are installed already. You can go straight to loading them.\n\n\n\n\n\n\n\n\nWorking on your own machine\n\n\n\nI recommend working on the University computers for this work. You can still work from home by using the Virtual Desktop Service. The VDS allows you to log on to a university computer from your own computer. It means you can access all software and filestores. When using the VDS for R a nd RStudio, it usually makes sense to use other software - such as a browser or file explorer - also through the VDS. Go to the Virtual Desktop Service for set up instructions.\nHowever, If you are confident in your ability to set up your own machine, you will need to install these packages.\nYou can install tidyverse from CRAN in the normal way.\nflowCore and flowAI are not on CRAN but come from Bioconductor.\n\nfirst install BiocManager from CRAN in the normal way.\nthen install from Bioconductor using BiocManager::install(\"flowCore\") and BiocManager::install(\"flowAI\")\n\nIf you have difficulty installing these packages, use the Virtual Desktop Service which allows you to log into a university machine from your laptop.\n\n\nüé¨ Load tidyverse,flowCore and flowAI\n\nlibrary(flowCore)\nlibrary(flowAI)\nlibrary(tidyverse)\n\n\n\n\n\n\n\nOrder of package loading\n\n\n\nLoad tidyverse last because flowCore also has some functions with the same names as functions in tidyverse and you will want the tidyverse ones.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#import-the-data",
    "href": "r4babs4/week-2/workshop.html#import-the-data",
    "title": "Workshop",
    "section": "Import the data",
    "text": "Import the data\nThere are six data files, one for each treatment and antibody combination:\n\nECOLIGreen_ISOTYPE.fcs\nECOLIGreen_TNFAPC.fcs\nLPS_ISOTYPE.fcs\nLPS_TNFAPC.fcs\nMEDIA_ISOTYPE.fcs\nMEDIA_TNFAPC.fcs\n\nüé¨ Save copies of each file (right click and save as) to your data-raw/ folder.\nThese are six files associated with one experiment.\nWe are going to use the command read.flowSet() from the flowCore package to import the data. In R, the data from one file is stored in a ‚ÄúflowFrame‚Äù object. A flowFrame is a data structure in the same way that a dataframe or a vector is a data structure. A flowFrame has ‚Äúslots‚Äù.\n\nThe first slot is called exprs and contains the data itself in matrix which looks just like a dataframe.\nThe second is called parameters and contains the names of the columns in exprs.\nThe third is called description and contains information about the .fcs file.\n\nA ‚ÄúflowSet‚Äù is a list of related flowFrames. They are related in that they have the same column names, came from the same machine, and are part of the same experiment. Such data needs to be treated in the same way which is why it is useful to have a structure like a flowSet.\nüé¨ Make a variable to hold the file names:\n\nmyfiles &lt;- list.files(\"data-raw\", pattern = \".fcs$\")\n\nlist.files() will return a character vector of the names of the files data-raw/. The pattern argument is a ‚Äúregular expression‚Äù which is used to filter the names of the files. Here we are asking for the names of the files which end in .fcs. This would be very useful if you had other file types in that folder. In our case, there are only .fcs files in that folder.\nüé¨ Type myfiles to check it contains what you expect.\nüé¨ Use read.flowSet() to import the files from the folder data-raw/ that are listed in the variable myfiles and name the resulting flowSet fs:\n\nfs &lt;- read.flowSet(myfiles, \n                   path = \"data-raw\")\n\nYou now have a flowSet which is a list of 6 flowFrames, one for each .fcs file.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#explore-the-data-structure",
    "href": "r4babs4/week-2/workshop.html#explore-the-data-structure",
    "title": "Workshop",
    "section": "Explore the data structure",
    "text": "Explore the data structure\nüé¨ Type fs to see what it contains:\n\nfs \n\nA flowSet with 6 experiments.\n\ncolumn names(16): TIME Time MSW ... FL 8 Log Event Count\n\n\nWe can index the list to access the first flowFrame in the flowSet.\nüé¨ Type fs[[1]] to see the information about the first flowFrame in the flowSet:\n\nfs[[1]] \n\nflowFrame object 'ECOLIGreen_ISOTYPE.fcs'\nwith 50000 cells and 16 observables:\n            name        desc     range  minRange  maxRange\n$P1         TIME        TIME     65536         0     65536\n$P2     Time MSW    Time MSW         7         0         7\n$P3  Pulse Width Pulse Width       397         0       397\n$P4       FS Lin      FS Lin     55001         0     55001\n$P5      FS Area     FS Area     65536         0     65536\n...          ...         ...       ...       ...       ...\n$P12    FL 1 Log    FL 1 Log     64962         0     64962\n$P13    FL 8 Lin    FL 8 Lin       758         0       758\n$P14   FL 8 Area   FL 8 Area      2217         0      2217\n$P15    FL 8 Log    FL 8 Log     28864         0     28864\n$P16 Event Count Event Count     50002         0     50002\n130 keywords are stored in the 'description' slot\n\n\nThis tells you there are 50000 cells (rows) and 16 columns in this dataset. The first two columns TIME and Time MSW give the time in binary format since the beginning of the data acquisition.\nüé¨ You can use the exprs() function to access the actual data and pipe it to View() to show it in a window:\n\nexprs(fs[[1]]) |&gt; View()\n\nüé¨ List the column names in each of the flowFrames:\n\ncolnames(fs)\n\n [1] \"TIME\"        \"Time MSW\"    \"Pulse Width\" \"FS Lin\"      \"FS Area\"    \n [6] \"FS Log\"      \"SS Lin\"      \"SS Area\"     \"SS Log\"      \"FL 1 Lin\"   \n[11] \"FL 1 Area\"   \"FL 1 Log\"    \"FL 8 Lin\"    \"FL 8 Area\"   \"FL 8 Log\"   \n[16] \"Event Count\"\n\n\nThe side scatter (SS) and forward scatter (FS) columns are used to select the live cells. The fluorescence measurements are in the FL columns and it is the linear values, FL 1 Lin and FL 8 Lin that have our FITC and APC signals respectively.\n\n\n\n\n\n\nTip\n\n\n\nThese exploratory steps are to help you understand the R objects you have. They are not essential parts of the analysis.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#improve-the-column-names",
    "href": "r4babs4/week-2/workshop.html#improve-the-column-names",
    "title": "Workshop",
    "section": "Improve the column names",
    "text": "Improve the column names\nNames like FL 1 Lin meaning ‚Äúfluorescence channel 1 linear‚Äù are not very informative. A list of more useful column names are given in meta.csv. We can import this file and use the resulting dataframe to rename columns in our flowFrames. This will make it easier to understand our data and results.\nüé¨ Save a copy of the file (right click and save as) to your data-meta/ folder\nüé¨ Import the meta data and examine it:\n\nmeta &lt;- read_csv(\"data-meta/meta.csv\")\n\n\n\n\n\n\nname\n\n\n\nTIME\n\n\nTime_MSW\n\n\nPulse_Width\n\n\nFS_Lin\n\n\nFS_Area\n\n\nFS_Log\n\n\nSS_Lin\n\n\nSS_Area\n\n\nSS_Log\n\n\nE_coli_FITC_Lin\n\n\nE_coli_FITC_Area\n\n\nE_coli_FITC_Log\n\n\nTNFa_APC_Lin\n\n\nTNFa_APC_Area\n\n\nTNFa_APC_Log\n\n\nEvent_Count\n\n\n\n\n\n\n\nüé¨ Assign the names in meta$name to the columns in the flowFrames:\n\ncolnames(fs) &lt;- meta$name\n# view the effect\ncolnames(fs) \n\n [1] \"TIME\"             \"Time_MSW\"         \"Pulse_Width\"      \"FS_Lin\"          \n [5] \"FS_Area\"          \"FS_Log\"           \"SS_Lin\"           \"SS_Area\"         \n [9] \"SS_Log\"           \"E_coli_FITC_Lin\"  \"E_coli_FITC_Area\" \"E_coli_FITC_Log\" \n[13] \"TNFa_APC_Lin\"     \"TNFa_APC_Area\"    \"TNFa_APC_Log\"     \"Event_Count\"     \n\n\n\n\n\n\n\n\nTip\n\n\n\nYou don‚Äôt have to use the names I have used for your own analysis if you prefer different names. Simply edit the meta.csv file. However, you do need to keep the Time column named that way for the next step to proceed.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#quality-control-1-automated-instrument-issues",
    "href": "r4babs4/week-2/workshop.html#quality-control-1-automated-instrument-issues",
    "title": "Workshop",
    "section": "Quality control 1: Automated instrument issues",
    "text": "Quality control 1: Automated instrument issues\nflowAI is a package that provides a set of tools for automated QC of flow cytometry data. It checks for:\n\nchanges in instrument speed using the Time column,\nchanges signal intensity\ncells that are outside the dynamic range\n\nIt generates a new flowSet with the problematic events removed along with a folder containing filtered .fcs files and a quality control report in html format. It will take a few minutes to do all files.\nüé¨ Run the automated quality control:\n\n\nQuality control for the file: ECOLIGreen_ISOTYPE\n11.81% of anomalous cells detected in the flow rate check. \n0% of anomalous cells detected in signal acquisition check. \n0% of anomalous cells detected in the dynamic range check. \nQuality control for the file: ECOLIGreen_TNFAPC\n34.82% of anomalous cells detected in the flow rate check. \n0% of anomalous cells detected in signal acquisition check. \n0% of anomalous cells detected in the dynamic range check. \nQuality control for the file: LPS_ISOTYPE\n36.42% of anomalous cells detected in the flow rate check. \n0% of anomalous cells detected in signal acquisition check. \n0% of anomalous cells detected in the dynamic range check. \nQuality control for the file: LPS_TNFAPC\n36.11% of anomalous cells detected in the flow rate check. \n0% of anomalous cells detected in signal acquisition check. \n0% of anomalous cells detected in the dynamic range check. \nQuality control for the file: MEDIA_ISOTYPE\n26.04% of anomalous cells detected in the flow rate check. \n0% of anomalous cells detected in signal acquisition check. \n0% of anomalous cells detected in the dynamic range check. \nQuality control for the file: MEDIA_TNFAPC\n37.82% of anomalous cells detected in the flow rate check. \n0% of anomalous cells detected in signal acquisition check. \n0% of anomalous cells detected in the dynamic range check. \n\n\n\nfs_clean &lt;- flow_auto_qc(fs, \n                         folder_results = \"sample-QC\")\n\n‚ùì What has been removed through the QC process?\n‚ùì What is in the folder ‚Äúsample-QC‚Äù?\nGet a feel of your data: Plot distributions\nPlotting the distributions of our variables is very useful for getting an overview of our data. We‚Äôll just look at the first flowFrame to get over the principles. However, you may wish to examine all of the flow frames of your own data.\nüé¨ Plot the distribution of the linear TNFa_APC signal in the first flowFrame in the flowSet:\n\nexprs(fs_clean[[1]]) |&gt; \n  data.frame() |&gt; \n  ggplot(aes(x = TNFa_APC_Lin)) +\n  geom_histogram(bins = 100)\n\n\n\n\n\n\n\nThis is a very skewed distribution which makes visualisation hard. It is common to log skewed distributions to improve visualisation.\nüé¨ Plot the distribution of the logged TNFa_APC_Lin column:\n\nexprs(fs_clean[[1]]) |&gt; \n  data.frame() |&gt; \n  ggplot(aes(x = log(TNFa_APC_Lin))) +\n  geom_histogram(bins = 100)\n\n\n\n\n\n\n\nNow our data are easier to see.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#transform-the-data",
    "href": "r4babs4/week-2/workshop.html#transform-the-data",
    "title": "Workshop",
    "section": "Transform the data",
    "text": "Transform the data\nIn fact, we will apply a different transformation called ‚Äúlogicle‚Äù (Parks, Roederer, and Moore 2006). This transformation is has a similar effect as logging but avoids some problems that can occur with flow cytometry data and especially flow cytometry data that have been ‚Äúcompensated‚Äù . Compensation is routinely applied to flow cytometry data to correct for fluorophores being detected in in multiple channels. This was not a problem in our experiment.\nThe transformation is applied in two steps: the transformation needed is estimated from the data and then that transformation is applied.\nWe need to apply the transformation only to the TNFa_APC_Lin and E_coli_FITC_Lin columns. The estimateLogicle() function refers to columns as channels.\nüé¨ Estimate the transformation from the data:\n\ntrans &lt;- estimateLogicle(fs_clean[[1]],\n                         channels = c(\"E_coli_FITC_Lin\", \"TNFa_APC_Lin\"))\n\nüé¨ Apply the transformation to all theTNFa_APC_Lin and E_coli_FITC_Lin columns the flowSet:\n\n# apply the transformation\nfs_clean_trans &lt;- transform(fs_clean, trans)\n\nüé¨ Examine the effect on the first flow frame:\n\nexprs(fs_clean_trans[[1]]) |&gt; \n  data.frame() |&gt; \n  ggplot(aes(x = TNFa_APC_Lin)) +\n  geom_histogram(bins = 100)\n\n\n\n\n\n\n\nThat looks better.",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#make-data-easier-to-work-with",
    "href": "r4babs4/week-2/workshop.html#make-data-easier-to-work-with",
    "title": "Workshop",
    "section": "Make data easier to work with",
    "text": "Make data easier to work with\nWe are going to get the data from the flowSet and put in a dataframe. FlowCore contains many functions for gating (filtering), plotting and summarising flowSets but putting the data into a dataframe will make it easier for you to use tools you already know and more easily follow the priciples of what you are doing.\nWe will be using familiar tools like group_by() and summarise(), filter() and ggplot()\nüé¨ Put the transformed data into a data frame:\n\n# Put into a data frame for ease of use\nclean_trans &lt;- fsApply(fs_clean_trans, exprs) |&gt; data.frame() \n\nfsApply(flowSet, function) applies a function to every flowFrame in a flowSet. Here we have accessed the data matirx in each with exprs().\nThe are 191663 rows (cells) in the dataset. You can view it by clicking on the dataframe in the Environment. At the moment, we cannot tell which row (cell) is from which sample but we can add the sample names as a column in that dataframe.\n\nEach sample name needs to appear as many times as there are cells (events) in the corresponding flowFrame. For example, dim(fs_clean_trans[[1]])[\"events\"] is 44095 cells.\nsampleNames(fs_clean_trans) gives the names of the samples.\nWe can use the rep() function to repeat the sample names the correct number of times.\n\nüé¨ Add the sample name to each row:\n\nclean_trans &lt;- clean_trans |&gt; \n  dplyr::mutate(sample = rep(sampleNames(fs_clean_trans),\n                             times = c(dim(fs_clean_trans[[1]])[\"events\"],\n                                       dim(fs_clean_trans[[2]])[\"events\"],\n                                       dim(fs_clean_trans[[3]])[\"events\"],\n                                       dim(fs_clean_trans[[4]])[\"events\"],\n                                       dim(fs_clean_trans[[5]])[\"events\"],\n                                       dim(fs_clean_trans[[6]])[\"events\"])))\n\nThe sample name contains the information about which antibody and treatment the sample was. Our analysis will be a little easier if we add this information to separate columns. We can extract the antibody and treatment from the sample name using the extract() function and two ‚Äúregular expressions‚Äù.\nüé¨ Add columns for treatment and antibody by extracting that information from the sample name:\n\nclean_trans &lt;- clean_trans |&gt; \n  extract(sample, \n          remove = FALSE,\n          c(\"treatment\", \"antibody\"),\n          \"([a-zA-Z]+)_([a-zA-Z]+).fcs\")\n\n\nthe sample name is treatment_antibody\neach pattern matching the treatment and antibody is enclosed in parentheses\nwe want to keep those patterns to go in the new columns\nthe underscore is matched but not enclosed in parentheses so it is not kept\n\n.fcs is matched but not enclosed in parentheses so it is not kept\nthe remove = FALSE argument means that the original column is kept\n\n[] enclose a set of characters\n\na-z means any lower case letter, A-Z means any upper case letter so [a-zA-Z] means any letter\n\n+ means one or more of the preceding character set\nso[a-zA-Z]+ means one or more letters\n\n\n\n\n\n\n\nAdding the treatment and antibody information\n\n\n\nWe have added the treatment and antibody information to each row by processing the names of the fcs files. This works because the file names have a specific format which we have matched with the regex. When you work with your own data, the easist thing to do is ensure your files have the same names as the same data.\n\n\nüé¨ View the dataframe to see the new columns.\nOur treatments have an order. Media is the control, LPS should be next and ECOLIGreen should be last. We can use the fct_relevel() function to put groups in order so that our graphs are better to interpret.\n\nclean_trans &lt;- clean_trans |&gt; \n  mutate(treatment = fct_relevel(treatment, c(\"MEDIA\",\n                                              \"LPS\",\n                                              \"ECOLIGreen\")))",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#save-the-data",
    "href": "r4babs4/week-2/workshop.html#save-the-data",
    "title": "Workshop",
    "section": "Save the data",
    "text": "Save the data\nWe have cleaned and transform our data. It is a good idea to save it at this point so that we can start from here if we need to.\nüé¨ Save the data:\n\nwrite_csv(clean_trans, \"data-processed/ai_clean_logicle_trans.csv\")",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#quality-control-2-gating-to-removing-debris",
    "href": "r4babs4/week-2/workshop.html#quality-control-2-gating-to-removing-debris",
    "title": "Workshop",
    "section": "Quality control 2: ‚ÄòGating‚Äô to Removing debris",
    "text": "Quality control 2: ‚ÄòGating‚Äô to Removing debris\nSome of the cells will have died and broken during the experiment. We need to perform quality control on our data to remove observations that have that have the size and granularity that is not typical of a live cell. This is done by filtering on the forward scatter (size) and side scatter (granularity) channels.\nIn flow cytometry, it is common to describe filtering as ‚Äúgating‚Äù and the observations (cells) being kept as ‚Äúin the gate‚Äù.\nWe create a scatter plot of the forward scatter (size) and side scatter (granularity) for each sample to see where we should put the gate.\nWe could use geom_point() but many points will overlap so it is difficult to see the density of points. geom_hex() puts the points in bins and colours the bin with the number of points.\nüé¨ Plot the forward scatter and side scatter for each sample\n\nggplot(clean_trans, aes(x = FS_Lin, y = SS_Lin)) +\n  geom_hex(bins = 128) +\n  scale_fill_viridis_c() +\n  facet_grid(antibody ~ treatment) +\n  theme_bw()\n\n\n\n\n\n\n\nWe can see a cloud of points in the middle of the plot. This is where the live cells are. Points towards the corners, especially in the bottom left corner are likely to be cell debris. We can draw a gate around the cloud of points to remove the debris. We should use the same filter/gate on all six data sets for consistency. The gates can be a rectangle, polygon, or ellipse. We will use a rectangle.\nManual rectangular gate\nUse the zoom on the plot window to better see the cloud of points and the axis values. You need to use minimum and maximum \\(x\\) and \\(y\\) values to define the rectangle.\nüé¨ Define the minimum and maximum \\(x\\) and \\(y\\) values for the gate:\n\nxmin &lt;- 15000\nxmax &lt;- 35000\nymin &lt;- 7500\nymax &lt;- 28000\n\n\n\n\n\n\n\nChoosing values for your own data\n\n\n\nI chose theses values but you might judge the gate differently. You will certainly need to use different values for your own data. The next plot will help you refine them.\n\n\nüé¨ Put those values in a dataframe so we can plot the gate on the hexbin plot:\n\nbox &lt;- data.frame(x = c(xmin, xmin, xmax, xmax),\n                  y = c(ymin, ymax, ymax, ymin))\n\nüé¨ Plot the forward scatter and side scatter for each sample with the gate:\n\nggplot(clean_trans, aes(x = FS_Lin, y = SS_Lin)) +\n  geom_hex(bins = 128) +\n  scale_fill_viridis_c() +\n  geom_polygon(data = box, aes(x = x, y = y), \n               fill = NA, \n               color = \"red\",\n               linewidth = 1) +\n  facet_grid(antibody ~ treatment) +\n  theme_bw()\n\n\n\n\n\n\n\nüé¨ Adjust the values of xmin, xmax, ymin, and ymax to get a gate that you are happy with.\nWe have drawn the gate on the plot but we need to use it to filter out the debris (rows) from our data. We want only the cells with FS_Lin values that are between the xmin and xmax and SS_Lin that are between ymin and ymax values we chose.\nüé¨ Filter the data to remove the debris:\n\n# filter out the debris\nclean_trans_live &lt;- clean_trans |&gt; \n  filter(between(FS_Lin, xmin, xmax),\n         between(SS_Lin, ymin, ymax)) \n\nclean_trans_live now has 179794 cells. We should report how many cells were in the gate for each sample.\nüé¨ Find the number of cells in each sample after flowAI cleaning:\n\n# \nclean_trans_n &lt;-  clean_trans |&gt; \n  group_by(antibody, treatment) |&gt; \n  summarise(n = n()) \n\nNote than we use the clean and transformed data for summarising the number in each set after cleaning.\n\n\n\n\nantibody\ntreatment\nn\n\n\n\nISOTYPE\nMEDIA\n20154\n\n\nISOTYPE\nLPS\n31789\n\n\nISOTYPE\nECOLIGreen\n44095\n\n\nTNFAPC\nMEDIA\n31089\n\n\nTNFAPC\nLPS\n31945\n\n\nTNFAPC\nECOLIGreen\n32591\n\n\n\n\n\nüé¨ Find the number of cells in each sample after flowAI cleaning and removing debris\n\n# number of cells in each sample\nclean_trans_live_n &lt;-  clean_trans_live |&gt; \n  group_by(antibody, treatment) |&gt; \n  summarise(n_live = n()) \n\nNow we use the clean, transformed and gated data.\n\n\n\n\nantibody\ntreatment\nn_live\n\n\n\nISOTYPE\nMEDIA\n17856\n\n\nISOTYPE\nLPS\n30675\n\n\nISOTYPE\nECOLIGreen\n41927\n\n\nTNFAPC\nMEDIA\n28085\n\n\nTNFAPC\nLPS\n30536\n\n\nTNFAPC\nECOLIGreen\n30715\n\n\n\n\n\nüé¨ Join two data frames together using the combination of the treatment and the antibody and calculate what % cells remained in each sample after gating (i.e., the % live cells):\n\nclean_trans_live_n &lt;- clean_trans_live_n |&gt; \n  left_join(clean_trans_n, by = c(\"antibody\", \"treatment\")) |&gt; \n  mutate(perc_live = round(n_live/n * 100, 1) )\n\n\n\n\n\nantibody\ntreatment\nn_live\nn\nperc_live\n\n\n\nISOTYPE\nMEDIA\n17856\n20154\n88.6\n\n\nISOTYPE\nLPS\n30675\n31789\n96.5\n\n\nISOTYPE\nECOLIGreen\n41927\n44095\n95.1\n\n\nTNFAPC\nMEDIA\n28085\n31089\n90.3\n\n\nTNFAPC\nLPS\n30536\n31945\n95.6\n\n\nTNFAPC\nECOLIGreen\n30715\n32591\n94.2\n\n\n\n\n\nüé¨ Plot the forward scatter and side scatter for each sample with the gate and the number of cells in each sample.\n\nggplot(clean_trans, aes(x = FS_Lin, y = SS_Lin)) +\n  geom_hex(bins = 128) +\n  scale_fill_viridis_c() +\n  geom_polygon(data = box, aes(x = x, y = y), \n               fill = NA, \n               color = \"red\",\n               linewidth = 1) +\n  geom_text(data = clean_trans_live_n, \n            aes(label = paste0(perc_live, \"%\")), \n            x = 45000, \n            y = 1000,\n            colour = \"red\",\n            size = 5) +\n  facet_grid(antibody ~ treatment) +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\n\n\n\nReporting\n\n\n\nThis figure allows you to report what data you included in your analysis of the TNFa_APC_Lin and E_coli_FITC_Lin signals.\n\n\nüé¨ Plot the TNFa_APC_Lin and E_coli_FITC_Lin signals for these live cells:\n\nggplot(clean_trans_live, aes(x = E_coli_FITC_Lin, \n                                  y = TNFa_APC_Lin)) +\n  geom_hex(bins = 128) +\n  scale_fill_viridis_c() +\n  facet_grid(antibody ~ treatment) +\n  theme_bw()",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#quality-control-3-gating-to-determine-a-real-signal",
    "href": "r4babs4/week-2/workshop.html#quality-control-3-gating-to-determine-a-real-signal",
    "title": "Workshop",
    "section": "Quality control 3: Gating to determine a ‚Äòreal‚Äô signal?",
    "text": "Quality control 3: Gating to determine a ‚Äòreal‚Äô signal?\nFrom now on we are working with the cleaned and gated data, that is, the dataframe clean_trans_live.\nWe have two signals:\n\n\nTNFa_APC_Lin is should indicate the amount of TNF-Œ± protein in the cell\n\nE_coli_FITC_Lin should indicate the amount of E. coli in the cell\n\nThe TNFa_APC_Lin signal\nWhen the antibody is ISOTYPE there is no TNF-Œ± so that level of TNFa_APC_Lin signal means no TNF-Œ±. In other words, that signal is a control. If you look at the top row of scatter plots, that level seems to be about 3.8. In the rest of the data set we should assume any signal below 3.8 means there is no TNF-Œ±.\nWe can use this to set a threshold for the TNFa_APC_Lin signal and then label cells as either positive or negative for TNF-Œ±.\nüé¨ Define the threshold for the TNFa_APC_Lin signal:\n\napc_cut &lt;- 3.8\n\nüé¨ Plot the TNFa_APC_Lin and E_coli_FITC_Lin with the threshold for the TNFa_APC_Lin signal:\n\nggplot(clean_trans_live, aes(x = E_coli_FITC_Lin, \n                                  y = TNFa_APC_Lin)) +\n  geom_hex(bins = 128) +\n  geom_hline(yintercept = apc_cut, \n             color = \"red\") +\n  scale_fill_viridis_c() +\n  facet_grid(antibody ~ treatment) +\n  theme_bw()\n\n\n\n\n\n\n\nThat looks about right. We will use this value to label each cell as positive or negative for TNF-Œ±.\nüé¨ Add a label, tnfa, to the data to indicate if the cell is positive or negative for TNF-Œ±\n\nclean_trans_live &lt;- clean_trans_live |&gt; \n  mutate(tnfa = case_when(TNFa_APC_Lin &lt; apc_cut ~ \"TNF-Œ± -'ve\",\n                               TNFa_APC_Lin &gt;= apc_cut ~ \"TNF-Œ± +'ve\"))\n\nüé¨ Summarise each group by finding the number of TNF-Œ± positive cells and the mean TNFa_APC_Lin signal for each group:\n\nclean_trans_live_tfna_pos &lt;- clean_trans_live |&gt; \n  filter(tnfa == \"TNF-Œ± +'ve\") |&gt;\n  group_by(antibody, treatment) |&gt;\n  summarise(n_pos_tnfa = n(),\n            mean_apc = mean(TNFa_APC_Lin))\n\n\n\n\n\nantibody\ntreatment\nn_pos_tnfa\nmean_apc\n\n\n\nISOTYPE\nMEDIA\n38\n3.950328\n\n\nISOTYPE\nLPS\n41\n3.968852\n\n\nISOTYPE\nECOLIGreen\n278\n3.867921\n\n\nTNFAPC\nMEDIA\n20066\n4.121845\n\n\nTNFAPC\nLPS\n30481\n5.075325\n\n\nTNFAPC\nECOLIGreen\n30686\n5.201248\n\n\n\n\n\nüé¨ We can add the number of live cells to this data frame and calculate the percentage of live cells that are positive for TNF-Œ±:\n\nclean_trans_live_tfna_pos &lt;- \n  clean_trans_live_tfna_pos |&gt; \n  left_join(clean_trans_live_n, by = c(\"antibody\", \"treatment\")) |&gt; \n  mutate(perc_pos_tnfa = round(n_pos_tnfa/n_live * 100, 1) )\n\nüé¨ And put the columns into a more logical order:\n\nclean_trans_live_tfna_pos &lt;- \n  clean_trans_live_tfna_pos |&gt; \n  select(antibody,\n         treatment,\n         n,\n         n_live,\n         perc_live,\n         mean_apc,\n         n_pos_tnfa,\n         perc_pos_tnfa)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nantibody\ntreatment\nn\nn_live\nperc_live\nmean_apc\nn_pos_tnfa\nperc_pos_tnfa\n\n\n\nISOTYPE\nMEDIA\n20154\n17856\n88.6\n3.950328\n38\n0.2\n\n\nISOTYPE\nLPS\n31789\n30675\n96.5\n3.968852\n41\n0.1\n\n\nISOTYPE\nECOLIGreen\n44095\n41927\n95.1\n3.867921\n278\n0.7\n\n\nTNFAPC\nMEDIA\n31089\n28085\n90.3\n4.121845\n20066\n71.4\n\n\nTNFAPC\nLPS\n31945\n30536\n95.6\n5.075325\n30481\n99.8\n\n\nTNFAPC\nECOLIGreen\n32591\n30715\n94.2\n5.201248\n30686\n99.9\n\n\n\n\n\nThe fact that a very low percentage of cells are positive for TNF-Œ± in the isotype control is a good indication that cut off we used for the TNFa_APC_Lin signal is a good one.\nTNFAPC-MEDIA combination tells us how much TNF-Œ± we expect in unstimulated cells.\nThis is important data for your write up and will be your contribution to the calss data set so you should write it to file.\nüé¨ Write clean_trans_live_tfna_pos to file:\n\nwrite_csv(clean_trans_live_tfna_pos, \n          \"data-processed/clean_trans_live_tfna_pos.csv\")\n\nThe E_coli_FITC_Lin signal\nWe can apply the same logic to the E_coli_FITC_Lin signal.\nFor either antibody, when the treatment is media or LPS there is no E.coli so that level of E_coli_FITC_Lin signal means zero. That level looks to be about 2.\nüé¨ Define the threshold for the E_coli_FITC_Lin signal:\n\nfitc_cut &lt;- 2\n\nüé¨ Add a label, fitc, to the data to indicate if the cell is positive or negative for FITC\n\nclean_trans_live &lt;- clean_trans_live |&gt; \n  mutate(fitc = case_when(E_coli_FITC_Lin &lt; fitc_cut ~ \"FITC -'ve\",\n                               E_coli_FITC_Lin &gt;= fitc_cut ~ \"FITC +'ve\"))\n\n\n\n\n\n\n\nTip for your own summaries\n\n\n\nYou may wish to repeat the process we used for the TNFa_APC_Lin signal to find out the number of cells that are FITC positive in each sample and the mean intensity of the FITC signal in the FITC positive cells.\n\n\nA figure to report baselines for both signals\nüé¨ Plot the TNFa_APC_Lin and E_coli_FITC_Lin with the thresholds for both signals:\n\nggplot(clean_trans_live, aes(x = E_coli_FITC_Lin, \n                                  y = TNFa_APC_Lin)) +\n  geom_hex(bins = 128) +\n  geom_hline(yintercept = apc_cut, \n             color = \"red\") +\n    geom_vline(xintercept = fitc_cut, \n             color = \"red\") +\n  scale_fill_viridis_c() +\n  facet_grid(antibody ~ treatment) +\n  theme_bw()",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#save-the-data-1",
    "href": "r4babs4/week-2/workshop.html#save-the-data-1",
    "title": "Workshop",
    "section": "Save the data",
    "text": "Save the data\nWe have filtered out the dead cells and debris and added labels to the data to indicate if the cells are positive or negative for TNF-Œ± and E. coli. It would be a good idea to save this data to file so we can start from importing this data in the future rather than having to repeat all of the steps we have done so far.\nüé¨ Save the data:\n\nwrite_csv(clean_trans_live, \"data-processed/live_labelled.csv\")",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/workshop.html#look-after-future-you",
    "href": "r4babs4/week-2/workshop.html#look-after-future-you",
    "title": "Workshop",
    "section": "Look after future you!",
    "text": "Look after future you!\nüé¨ This workshop is a template for the analysis of your own data. Go back through your script and check you understand what you have done. Can you identify where you will need to edit? Do you understand what you will need to assess in order to make edits needed for your own data? Examine all of the objects in the environment to check you understand what they are and why they are there.\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs4/week-2/study_after_workshop.html",
    "href": "r4babs4/week-2/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "üé¨ Go through the prior study and workshop again making notes on the data analysis process. Ignore the code, just check you understand the steps conceptually.\nüé¨ Create a new Project that you will use to analyse your own data and which you will submit as your RStudio Project. Populate it with the folders you will need. The Project does not need to be named with your exam number at this stage. The next workshop will cover how to change the name of Project.\nüé¨ Make a copy of the R script from the workshop that you can use to analyse your own data. Go through the script to tidy it up. You might need to:\n\ncollect together library statements at the top of the script\nedit your comments for clarity\nrename variables for consistency or clarity\nremove house keeping or exploratory code or mark it for later removal\nrestyle code, add code section headers etc",
    "crumbs": [
      "BABS 4",
      "Week 2: DA 2 Biomed. Sci",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs4/r4babs4.html",
    "href": "r4babs4/r4babs4.html",
    "title": "Data Analysis in R for BABS 4",
    "section": "",
    "text": "This is the last of the four BABS modules and you will draw together many of the elements from the previous BABS modules to perform a guided research project in an area of bioscience related to your degree programme. There will be one core workshop and three workshops specific to your project strand.\nThis page has the material for the Core workshop and the three Biomedical sciences workshops. All material is on the VLE.\n\n\nThe BABS4 Module Learning outcomes that relate to the Data Analysis in R content are:\n\nDesign the preprocessing, analysis and visualisation of univariate and multivariate data generated with some degree of automation. Use R to perform these analyses, reproducibly, on data in a variety of formats and present the results graphically\nInterpret combined experimental results in the context of the wider literature to communicate findings to a scientific audience",
    "crumbs": [
      "BABS 4",
      "Data Analysis in R for BABS 4"
    ]
  },
  {
    "objectID": "r4babs4/r4babs4.html#module-learning-objectives",
    "href": "r4babs4/r4babs4.html#module-learning-objectives",
    "title": "Data Analysis in R for BABS 4",
    "section": "",
    "text": "The BABS4 Module Learning outcomes that relate to the Data Analysis in R content are:\n\nDesign the preprocessing, analysis and visualisation of univariate and multivariate data generated with some degree of automation. Use R to perform these analyses, reproducibly, on data in a variety of formats and present the results graphically\nInterpret combined experimental results in the context of the wider literature to communicate findings to a scientific audience",
    "crumbs": [
      "BABS 4",
      "Data Analysis in R for BABS 4"
    ]
  },
  {
    "objectID": "r4babs4/r4babs4.html#week-1-data-analysis-1-core",
    "href": "r4babs4/r4babs4.html#week-1-data-analysis-1-core",
    "title": "Data Analysis in R for BABS 4",
    "section": "Week 1 Data Analysis 1: Core",
    "text": "Week 1 Data Analysis 1: Core\nThis is taken by all students. The independent study to prepare you for the workshop is revision of some stage 1 core concepts. It covers file types, file systems, working directories, paths and RStudio Projects. You may feel completely confident with them but many students will benefit from a refresher. In the workshop we will cover Project organisation, working with data that has many variables and observations, getting an overview with summaries and distribution plots, and how to filter rows and columns.",
    "crumbs": [
      "BABS 4",
      "Data Analysis in R for BABS 4"
    ]
  },
  {
    "objectID": "r4babs4/r4babs4.html#week-2-data-analysis-2-biomedical-sciences---sample-data-analysis",
    "href": "r4babs4/r4babs4.html#week-2-data-analysis-2-biomedical-sciences---sample-data-analysis",
    "title": "Data Analysis in R for BABS 4",
    "section": "Week 2 Data Analysis 2: Biomedical sciences - Sample data analysis",
    "text": "Week 2 Data Analysis 2: Biomedical sciences - Sample data analysis\nThis is the first of the three workshops which are specific to the Biomedical sciences strand. The aim of these workshops is to teach you how to analyse the flow cytometry data you will collect in the practicals. In this workshop, we will guide you through the analysis of a sample data set just like the one you will generate. Jillian collected these data in designing this set of practicals. You will learn both how to analyse the data and what your own data should look like. We will mainly rely on default formats for figures.",
    "crumbs": [
      "BABS 4",
      "Data Analysis in R for BABS 4"
    ]
  },
  {
    "objectID": "r4babs4/r4babs4.html#week-4-data-analysis-3-biomedical-sciences---analysis-of-your-own-data",
    "href": "r4babs4/r4babs4.html#week-4-data-analysis-3-biomedical-sciences---analysis-of-your-own-data",
    "title": "Data Analysis in R for BABS 4",
    "section": "Week 4 Data Analysis 3: Biomedical sciences - Analysis of your own data",
    "text": "Week 4 Data Analysis 3: Biomedical sciences - Analysis of your own data\nIn this workshop, you will apply the workflow you learned in the previous workshop to analyse your own data with our support.",
    "crumbs": [
      "BABS 4",
      "Data Analysis in R for BABS 4"
    ]
  },
  {
    "objectID": "r4babs4/r4babs4.html#week-6-data-analysis-4-biomedical-sciences---customising-figures",
    "href": "r4babs4/r4babs4.html#week-6-data-analysis-4-biomedical-sciences---customising-figures",
    "title": "Data Analysis in R for BABS 4",
    "section": "Week 6 Data Analysis 4: Biomedical sciences - Customising figures",
    "text": "Week 6 Data Analysis 4: Biomedical sciences - Customising figures\nIn this workshop you will how to customise figures with colour or greyscale, labels, and other features to make them more suitable for publication.",
    "crumbs": [
      "BABS 4",
      "Data Analysis in R for BABS 4"
    ]
  },
  {
    "objectID": "r4babs4/week-4/study_before_workshop.html",
    "href": "r4babs4/week-4/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üíª Open the RStudio Project you created in the Consolidation exercise from week 2.\nüíª Save your data files to that project. Are the file names going to be easy for you to work with? Remember that we used the file names to label to rows with their treatment (Media, LPS or ECOLIGreen) and antibody (ISOTYPE or TNFAPC) so if you do not match the names you will need to redesign the code to appropriately. It is easier to rename your files!\nüìñ Go through the script and identify the parts that you will need to change to make it work for your data.\nüìñ Can you identify code that you will not need to include?\nüìñ Go through the Week 2 Workshop and read the text to check you understand what is happening to the data.\nüíª Consider importing and analysing your own data so that you can make good use of the workshop to resolve any issues you encounter.",
    "crumbs": [
      "BABS 4",
      "Week 4: DA 3 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-4/overview.html",
    "href": "r4babs4/week-4/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This is the second of the three workshops which are specific to the Biomedical sciences strand. The aim of these workshops is to teach you how to analyse the flow cytometry data you will collect in the practicals. In this workshop, apply the workflow your learned in Week 2 to your own data.\n\nLearning objectives\nThe successful student will be able to:\n\nExplain the principles of each step in workflow provided in week 2\nEdit the workflow provided in week 2 and apply it to their own data\nDetermine values from their data that contribute to the class data set.\nchange the name of an RStudio project\nApply the principles covered in Data Analysis 1: Core to their analysis\n\n\n\nInstructions\n\nPrepare\nWorkshop\nConsolidate",
    "crumbs": [
      "BABS 4",
      "Week 4: DA 3 Biomed. Sci",
      "About"
    ]
  },
  {
    "objectID": "r4babs4/week-6/study_before_workshop.html",
    "href": "r4babs4/week-6/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "The independent study is to check your progress and understanding. We have covered the steps listed below. If you have got behind, start from wherever you got to.\n\nüìñ Read what the sample data are, get an overview of the analysis and tools\nüíª Go through the sample data analysis and make sure you understand the steps and the code\n\nYou should have a single csv file with data from all 6 samples. The data has been cleaned with flowAI to remove cells ‚Äòbad‚Äô signals. The file has 19 columns with meaningful names. The TNFa_APC_Lin and E_coli_FITC_Lin columns have been logicle transformed. The file names were added to a column sample and columns indicating the treatment and antibody were created by extracting patterns from the file names. The code that does that relies on the names being in the format Treatment_Antibody. You can import this data as a dataframe and use familiar tidyverse tools.\nThe treatments will be plotted in alphabetical order by default. We can change that order to ‚ÄúMEDIA‚Äù, ‚ÄúLPS‚Äù, ‚ÄúECOLIGreen‚Äù using fct_relevel(). The code that does that relies on the treatment names being exactly ‚ÄúMEDIA‚Äù, ‚ÄúLPS‚Äù, ‚ÄúECOLIGreen‚Äù. You can name the treaments differently but you will need to change the levels given in fct_relevel() accordingly.\nYou should be able to plot side scatter against forward scatter for the six samples and add a rectangular gate for the live cells. You should be able to use this gate to filter the data to get a dataframe of live cells.\nYou should be able calculate the number and percentage of live cells in each sample and annotate the figure in iii. with those percentages. These were in a dataframe I named clean_trans_nondebris_n.\nYou should be able to plot the logicle transformed TNFa_APC_Lin against the E_coli_FITC_Lin for the live cells and add a gate for the TNF-Œ± positive cells and label the rows (cells) in the dataframe as TNF-Œ± positive or TNF-Œ± negative. You should be able to calculate the number and percentage of of TNF-Œ± positive cells in each sample. These were in a dataframe I named clean_trans_nondebris_tfna_pos\nYou should be able add a gate for the FITC positive cells and label the rows (cells) in the dataframe as FITC positive or FITC negative. You should be able to calculate the number and percentage of FITC positive cells in each sample using the same logic as in v.\n\nüíª Prepare to analyse your own data / the model data\n\nMake a new RStudio Project, copy in the script and tidy it up\nSave your data. Your data are on googledrive. If you do not have any data you can use the Flow cytometry MODEL DATA\n\nüíª Analyse your own data / the model data\n\nMake your life easier renaming your data files to match the sample data.\nNote that your data has 16 columns. You need a different metadata file than used for the sample data. You will not need to Drop the unused channels\n\nüíª Enter data from your analysis in to BIO00066I Biomedical Sciences class data\nThe columns you must add are:\n\napc_mfi: Mean fluorescence intensity of the logicle transformed TNFa_APC_Lin in the TNF-Œ± positive cells\nperc_tfna_pos: % non debris cells that are TNF-Œ± positive cells\n\nThe other columns are calculations you make along the way and may help you get to the apc_mfi and perc_tfna_pos values. The column names are the same as those used in the Data Analysis 2: Biomedical sciences - Sample data analysis workshop",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs4/week-6/overview.html",
    "href": "r4babs4/week-6/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Learning objectives\nThe successful student will be able to:\n\nevaluate their progress and identify any steps they have missed\ncreate density plots to visualise the distribution, and gating of, the APC TNF-Œ± and FTIC signals in live cells\ncalculate the the percentage of cells in each quadrant of a quadrant gated plot of TNFa_APC_Lin signal against the E_coli_FITC_Lin\nannotate ggplots as desired\nimport data from a googlesheet\n\n\n\nInstructions\n\nPrepare\n\nCheck where you are\n\nWorkshop\n\nüíª Create density plots to visualise the distribution, and gating of, the APC TNF-Œ± and FTIC signals in live cells\nüíª Calculate the the percentage of cells in each quadrant of a quadrant gated gated plot of TNFa_APC_Lin signal against the E_coli_FITC_Lin\nüíª Annotate ggplots\nüíª Import data from a googlesheet\n\nConsolidate\n\nüíª Continue with your analysis and reporting",
    "crumbs": [
      "BABS 4",
      "Week 6: DA 4 Biomed. Sci",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-1/workshop.html",
    "href": "pgt52m/week-1/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "There is no formal workshop this week but you might want to install R and RStudio on your own machine. This is optional because University computers already have R and RStudio installed.\nInstall R and RStudio.\nNote you need a computer - not a tablet.",
    "crumbs": [
      "PGT 52M",
      "Week 1: Understanding file systems",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-1/study_after_workshop.html",
    "href": "pgt52m/week-1/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "There is no additional study this week but you may want to look ahead to next week.",
    "crumbs": [
      "PGT 52M",
      "Week 1: Understanding file systems",
      "Consolidate!"
    ]
  },
  {
    "objectID": "pgt52m/week-9/workshop.html",
    "href": "pgt52m/week-9/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚ÄúBehold R‚Äù\n\n\nThis week we will be looking at the assessment for this module and introducing you to a specimen sample of the assessment so that you can familiarise yourself with the format and what we are expecting you to produce. We will be looking at a Rproject containing a quarto markdown file and a report results section. We will also look at the marking criteria. This material can also be found on the VLE under the module assessment marking criteria section. Next week we will cover how to reproduce a quarto markdown file yourself in more detail.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 9: Introduction to the Assessment",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-9/workshop.html#session-overview",
    "href": "pgt52m/week-9/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "This week we will be looking at the assessment for this module and introducing you to a specimen sample of the assessment so that you can familiarise yourself with the format and what we are expecting you to produce. We will be looking at a Rproject containing a quarto markdown file and a report results section. We will also look at the marking criteria. This material can also be found on the VLE under the module assessment marking criteria section. Next week we will cover how to reproduce a quarto markdown file yourself in more detail.",
    "crumbs": [
      "PGT 52M",
      "Week 9: Introduction to the Assessment",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-9/workshop.html#philosophy",
    "href": "pgt52m/week-9/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 9: Introduction to the Assessment",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-9/study_after_workshop.html",
    "href": "pgt52m/week-9/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Consolidate\n\nüìñ Read Workflow and scripts - Projects\nüìñ Read Intro to quarto",
    "crumbs": [
      "PGT 52M",
      "Week 9: Introduction to the Assessment",
      "Consolidate!"
    ]
  },
  {
    "objectID": "pgt52m/week-8/workshop.html",
    "href": "pgt52m/week-8/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚ÄúDebugging and feelings‚Äù\n\n\nIn this session you will get practice in choosing between, performing, and presenting the results of, one-way ANOVA and Kruskal-Wallis in R.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 8: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-8/workshop.html#session-overview",
    "href": "pgt52m/week-8/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this session you will get practice in choosing between, performing, and presenting the results of, one-way ANOVA and Kruskal-Wallis in R.",
    "crumbs": [
      "PGT 52M",
      "Week 8: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-8/workshop.html#philosophy",
    "href": "pgt52m/week-8/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 8: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-8/workshop.html#myoglobin-in-seal-muscle",
    "href": "pgt52m/week-8/workshop.html#myoglobin-in-seal-muscle",
    "title": "Workshop",
    "section": "Myoglobin in seal muscle",
    "text": "Myoglobin in seal muscle\nThe myoglobin concentration of skeletal muscle of three species of seal in grams per kilogram of muscle was determined and the data are given in seal.csv. We want to know if there is a difference between species. Each row represents an individual seal. The first column gives the myoglobin concentration and the second column indicates species.\n Save a copy of the data file seal.csv to data-raw\n Read in the data and check the structure. I used the name seal for the dataframe/tibble.\n What kind of variables do you have?\n\n\n\nExploring\n Do a quick plot of the data. You may need to refer to a previous workshop\nSummarising the data\nDo you remember Look after future you!\n If you followed that tip you‚Äôll be able to open that script and whizz through summarising,testing and plotting.\n Create a data frame called seal_summary that contains the means, standard deviations, sample sizes and standard errors for each species.\nYou should get the following numbers:\n\n\n\n\nspecies\nmean\nstd\nn\nse\n\n\n\nBladdernose Seal\n42.31600\n8.020634\n30\n1.464361\n\n\nHarbour Seal\n49.01033\n8.252004\n30\n1.506603\n\n\nWeddell Seal\n44.66033\n7.849816\n30\n1.433174\n\n\n\n\n\nApplying, interpreting and reporting\nWe can now carry out a one-way ANOVA using the same lm() function we used for two-sample tests.\n Carry out an ANOVA and examine the results with:\n\nmod &lt;- lm(data = seal, myoglobin ~ species)\nsummary(mod)\n\n\nCall:\nlm(formula = myoglobin ~ species, data = seal)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.306  -5.578  -0.036   5.240  18.250 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           42.316      1.468  28.819  &lt; 2e-16 ***\nspeciesHarbour Seal    6.694      2.077   3.224  0.00178 ** \nspeciesWeddell Seal    2.344      2.077   1.129  0.26202    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.043 on 87 degrees of freedom\nMultiple R-squared:  0.1096,    Adjusted R-squared:  0.08908 \nF-statistic: 5.352 on 2 and 87 DF,  p-value: 0.006427\n\n\nRemember: the tilde (~) means test the values in myoglobin when grouped by the values in species. Or explain myoglobin with species\n What do you conclude so far from the test? Write your conclusion in a form suitable for a report.\n\n\n\n Can you relate the values under Estimate to the means?\n\n\n\n\n\n\n\nThe ANOVA is significant but this only tells us that species matters, meaning at least two of the means differ. To find out which means differ, we need a post-hoc test. A post-hoc (‚Äúafter this‚Äù) test is done after a significant ANOVA test. There are several possible post-hoc tests and we will be using Tukey‚Äôs HSD (honestly significant difference) test (Tukey 1949) implemented in the emmeans (Lenth 2024) package.\n Load the package\n\nlibrary(emmeans)\n\n Carry out the post-hoc test\n\nemmeans(mod, ~ species) |&gt; pairs()\n\n contrast                        estimate   SE df t.ratio p.value\n Bladdernose Seal - Harbour Seal    -6.69 2.08 87  -3.224  0.0050\n Bladdernose Seal - Weddell Seal    -2.34 2.08 87  -1.129  0.4990\n Harbour Seal - Weddell Seal         4.35 2.08 87   2.095  0.0968\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nEach row is a comparison between the two means in the ‚Äòcontrast‚Äô column. The ‚Äòestimate‚Äô column is the difference between those means and the ‚Äòp.value‚Äô indicates whether that difference is significant.\nA plot can be used to visualise the result of the post-hoc which can be especially useful when there are very many comparisons.\n Plot the results of the post-hoc test:\n\nemmeans(mod, ~ species) |&gt; plot()\n\n\n\n\n\n\n\nWhere the purple bars overlap, there is no significant difference.\n What do you conclude from the test?\n\n\n\nCheck assumptions\nThe assumptions of the general linear model are that the residuals ‚Äì the difference between predicted value (i.e., the group mean) and observed values - are normally distributed and have homogeneous variance. To check these we can examine the mod$residuals variable. You may want to refer to Checking assumptions in the ‚ÄúSingle regression‚Äù workshop.\n Plot the model residuals against the fitted values.\n What to you conclude?\n\n\n\nTo examine normality of the model residuals we can plot them as a histogram and do a normality test on them.\n Plot a histogram of the residuals.\n Use the shapiro.test() to test the normality of the model residuals\n What to you conclude?\n\n\n\n\nIllustrating\n Create a figure like the one below. You may need to refer to Visualise from the ‚ÄúSummarising data with several variables‚Äù workshop (Rand 2023)\nWe will again use both our seal and seal_summary dataframes.\n Create the plot:\n\n\n\n\n\n\n\n\n Save your figure to your figures folder.",
    "crumbs": [
      "PGT 52M",
      "Week 8: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-8/workshop.html#leafminers-on-birch",
    "href": "pgt52m/week-8/workshop.html#leafminers-on-birch",
    "title": "Workshop",
    "section": "Leafminers on Birch",
    "text": "Leafminers on Birch\nLarvae of the Ambermarked birch leafminer, Profenusa thomsoni, feed on the interior leaf tissues of Birch (Betula) species. They do not normally kill the tree but can weaken it making it susceptible to attack from other species. Researchers are interested in whether there is a difference in the rates at which white, grey and yellow birch are attacked. They introduce adult female P.thomsoni to a green house containing 30 young trees (ten of each type) and later count the egg laying events on each tree. The data are in leaf.txt.\nExploring\n Read in the data and check the structure. I used the name leaf for the dataframe/tibble.\n What kind of variables do we have?\n\n\n\n Do a quick plot of the data.\n Using your common sense, do these data look normally distributed?\n\n\n Why is a Kruskal-Wallis appropriate in this case?\n\n\n\n\n\n Calculate the medians, means and sample sizes.\nApplying, interpreting and reporting\n Carry out a Kruskal-Wallis:\n\nkruskal.test(data = leaf, eggs ~ birch)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  eggs by birch\nKruskal-Wallis chi-squared = 6.3393, df = 2, p-value = 0.04202\n\n\n What do you conclude from the test?\n\n\n\nA significant Kruskal-Wallis tells us at least two of the groups differ but where do the differences lie? The Dunn test is a post-hoc multiple comparison test for a significant Kruskal-Wallis. It is available in the package FSA\n Load the package using:\n\nlibrary(FSA)\n\n Run the post-hoc test with:\n\ndunnTest(data = leaf, eggs ~ birch)\n\n      Comparison         Z    P.unadj      P.adj\n1   Grey - White  1.296845 0.19468465 0.38936930\n2  Grey - Yellow -1.220560 0.22225279 0.22225279\n3 White - Yellow -2.517404 0.01182231 0.03546692\n\n\nThe P.adj column gives p-value for the comparison listed in the first column. Z is the test statistic.\n What do you conclude from the test?\n\n\n\n Write up the result is a form suitable for a report.\n\n\n\n\n\n\nIllustrating\n A box plot is an appropriate choice for illustrating a Kruskal-Wallis. Can you produce a figure like this?\n\n\n\n\n\n\n\n\nYou‚Äôre finished!",
    "crumbs": [
      "PGT 52M",
      "Week 8: One-way ANOVA and Kruskal-Wallis",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-8/study_after_workshop.html",
    "href": "pgt52m/week-8/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª Sports scientists were investigating the effects of fitness and heat acclimatisation on the sodium content of sweat. They measured the sodium content of the sweat (Œºmoll^‚àí1) of three groups of individuals: unfit and unacclimatised (UU); fit and unacclimatised(FU); and fit and acclimatised (FA). The are in sweat.txt. Is there a difference between the groups in the sodium content of their sweat?\n\n\nAnswer - don‚Äôt look until you have tried!# read in the data and look at structure\nsweat &lt;- read_table(\"data-raw/sweat.txt\")\nstr(sweat)\n\n\n\nAnswer - don‚Äôt look until you have tried!# quick plot of the data\nggplot(data = sweat, aes(x = gp, y = na)) +\n  geom_boxplot()\nAnswer - don‚Äôt look until you have tried!# Since the sample sizes are small and not the same in each group and the \n# variance in the FA gp looks a bit lower, I'm leaning to a non-parametric test K-W.\n# However, don't panic if you decided to do an anova\n\n\n\nAnswer - don‚Äôt look until you have tried!# calculate some summary stats \nsweat_summary &lt;- sweat %&gt;% \n  group_by(gp) %&gt;% \n  summarise(mean = mean(na),\n            n = length(na),\n            median = median(na))\n\n\n\nAnswer - don‚Äôt look until you have tried!# Kruskal-Wallis\nkruskal.test(data = sweat, na ~ gp)\n# We can say there is a difference between the groups in the sodium \n# content of their sweat (chi-squared = 11.9802, df = 2, p-value = 0.002503).\n# Unfit and unacclimatised people have most salty sweat, \n# Fit and acclimatised people the least salty.\n\n\n\nAnswer - don‚Äôt look until you have tried!# a post-hoc test to see where the sig differences lie:\nlibrary(FSA)\ndunnTest(data = sweat, na ~ gp)\n# Fit and acclimatised people (median = 49.5 Œºmoll^‚àí1) have significantly less sodium in their\n#  sweat than the unfit and unacclimatised people (70 Œºmoll^‚àí1) \n# (Kruskal-Wallis multiple comparison p-values adjusted with the Holm method: p = 0.0026).\n# Fit and unacclimatised (54 Œºmoll^‚àí1)  also have significantly less sodium in their\n# people have sodium concentrations than unfit and unacclimatised people (p = 0.033). \n# There was no difference between the Fit and unacclimatised and the Fit and acclimatised. See figure 1.\n\n\n\nAnswer - don‚Äôt look until you have tried!ggplot(sweat, aes(x = gp, y = na) ) +\n  geom_boxplot() +\n  scale_x_discrete(labels = c(\"Fit Acclimatised\", \n                              \"Fit Unacclimatised\", \n                              \"Unfit Unacclimatised\"), \n                   name = \"Group\") +\n  scale_y_continuous(limits = c(0, 110), \n                     expand = c(0, 0),\n                     name = expression(\"Sodium\"~mu*\"mol\"*l^{-1})) +\n  annotate(\"segment\", x = 1, xend = 3, \n           y = 100, yend = 100,\n           colour = \"black\") +\n  annotate(\"text\", x = 2,  y = 103, \n           label = expression(italic(p)~\"= 0.0026\")) +\n  annotate(\"segment\", x = 2, xend = 3, \n           y = 90, yend = 90,\n           colour = \"black\") +\n  annotate(\"text\", x = 2.5,  y = 93, \n           label = expression(italic(p)~\"= 0.0340\")) +\n  theme_classic()\nAnswer - don‚Äôt look until you have tried!#Figure 1. Sodium content of sweat for three groups: Fit and acclimatised\n#(FA), Fit and unacclimatised (FU) and Unfit and unacclimatised (UU). Heavy lines\n#indicate the median, boxes the interquartile range and whiskers the range. \n\n\n\nüíª The data are given in biomass.txt are taken from an experiment in which the insect pest biomass (g) was measured on plots sprayed with water (control) or one of five different insecticides. Do the insecticides vary in their effectiveness? What advice would you give to a person: - currently using insecticide E? - trying to choose between A and D? - trying to choose between C and B?\n\n\nAnswer - don‚Äôt look until you have tried!biom &lt;- read_table(\"data-raw/biomass.txt\")\n# The data are organised with an insecticide treatment group in\n# each column.\n\n\n\nAnswer - don‚Äôt look until you have tried!#Put the data into tidy format.\n\nbiom &lt;- biom |&gt; \n  pivot_longer(cols = everything(),\n               names_to = \"spray\",\n               values_to = \"biomass\")\n\n\n\nAnswer - don‚Äôt look until you have tried!# quick plot of the data\nggplot(data = biom, aes(x = spray, y = biomass)) +\n  geom_boxplot()\nAnswer - don‚Äôt look until you have tried!# Looks like there is a difference between sprays. E doesn't look very effective.\n\n\n\nAnswer - don‚Äôt look until you have tried!# summary statistics\nbiom_summary &lt;- biom %&gt;% \n  group_by(spray) %&gt;% \n  summarise(mean = mean(biomass),\n            median = median(biomass),\n            sd = sd(biomass),\n            n = length(biomass),\n            se = sd / sqrt(n))\n# thoughts so far: the sample sizes are equal, 10 is a smallish but\n# reasonable sample size\n# the means and medians are similar to each other (expected for\n# normally distributed data), A has a smaller variance \n\n# We have one explanatory variable, \"spray\" comprising 6 levels\n# Biomass has decimal places and we would expect such data to be \n# normally distributed therefore one-way ANOVA is the desired test\n# - we will check the assumptions after building the model\n\n\n\nAnswer - don‚Äôt look until you have tried!# arry out an ANOVA and examine the results \nmod &lt;- lm(data = biom, biomass ~ spray)\nsummary(mod)\n# spray type does have an effect F-statistic: 26.46 on 5 and 54 DF,  p-value: 2.081e-13\n\n\n\nAnswer - don‚Äôt look until you have tried!# Carry out the post-hoc test\nlibrary(emmeans)\n\nemmeans(mod, ~ spray) |&gt; pairs()\n\n# the signifcant comparisons are:\n# contrast         estimate   SE df t.ratio p.value\n# A - D              -76.50 21.9 54  -3.489  0.0119\n# A - E             -175.51 21.9 54  -8.005  &lt;.0001\n# A - WaterControl  -175.91 21.9 54  -8.024  &lt;.0001\n# B - E             -154.32 21.9 54  -7.039  &lt;.0001\n# B - WaterControl  -154.72 21.9 54  -7.057  &lt;.0001\n# C - E             -155.71 21.9 54  -7.102  &lt;.0001\n# C - WaterControl  -156.11 21.9 54  -7.120  &lt;.0001\n# D - E              -99.01 21.9 54  -4.516  0.0005\n# D - WaterControl   -99.41 21.9 54  -4.534  0.0004\n# All sprays are better than the water control except E. \n# This is probably the most important result.\n# What advice would you give to a person currently using insecticide E?\n# Don't bother!! It's no better than water. Switch to any of \n# the other sprays\n#  What advice would you give to a person currently\n#   + trying to choose between A and D? Choose A because A has sig lower\n#   insect biomass than D \n#   + trying to choose between C and B? It doesn't matter because there is \n#   no difference in insect biomass. Use other criteria to chose (e.g., price)\n# We might report this like:\n# There is a very highly significant effect of spray type on pest \n# biomass (F = 26.5; d.f., 5, 54; p &lt; 0.001). Post-hoc testing \n# showed E was no more effective than the control; A, C and B were \n# all better than the control but could be equally as good as each\n# other; D would be a better choice than the control or E but \n# worse than A. See figure 1\n\n\n\nAnswer - don‚Äôt look until you have tried!# I reordered the bars to make is easier for me to annotate with\n# I also used * to indicate significance\n\nggplot() +\n  geom_point(data = biom, aes(x = reorder(spray, biomass), y = biomass),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"gray50\") +\n  geom_errorbar(data = biom_summary, \n                aes(x = spray, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = biom_summary, \n                aes(x = spray, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Pest Biomass (units)\",\n                     limits = c(0, 540),\n                     expand = c(0, 0)) +\n  scale_x_discrete(\"Spray treatment\") +\n  # E and control are one group\n  annotate(\"segment\", x = 4.5, xend = 6.5, \n           y = 397, yend = 397,\n           colour = \"black\", linewidth = 1) +\n  annotate(\"text\", x = 5.5,  y = 385, \n           label = \"N.S\", size = 4) +\n  # WaterControl-D and E-D    ***\n  annotate(\"segment\", x = 4, xend = 5.5, \n           y = 410, yend = 410,\n           colour = \"black\") +\n  annotate(\"text\", x = 4.5,  y = 420, \n           label = \"***\", size = 5) +\n  # WaterControl-B ***\n  annotate(\"segment\", x = 3, xend = 5.5, \n         y = 440, yend = 440,\n         colour = \"black\") +\n  annotate(\"text\", x = 4,  y = 450,\n           label = \"***\", size = 5) +\n  # WaterControl-C ***\n  annotate(\"segment\", x = 2, xend = 5.5, \n           y = 475, yend = 475,\n           colour = \"black\") +\n  annotate(\"text\", x = 3.5,  y = 485, \n           label = \"***\", size = 5) +\n  # WaterControl-A ***\n  annotate(\"segment\", x = 1, xend = 5.5, \n         y = 510, yend = 510,\n         colour = \"black\") +\n  annotate(\"text\", x = 3.5,  y = 520, \n           label = \"***\", size = 5) +  \n# A-D ***\n  annotate(\"segment\", x = 1, xend = 4, \n         y = 330, yend = 330,\n         colour = \"black\") +\n  annotate(\"text\", x = 2.5,  y = 335, \n           label = \"*\", size = 5) +\n  theme_classic()\nAnswer - don‚Äôt look until you have tried!# Figure 1. The mean pest biomass following various insecticide treatments.\n# Error bars are +/- 1 S.E. Significant comparisons are indicated: * is p &lt; 0.05, ** p &lt; 0.01 and *** is p &lt; 0.001",
    "crumbs": [
      "PGT 52M",
      "Week 8: One-way ANOVA and Kruskal-Wallis",
      "Consolidate!"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html",
    "href": "pgt52m/week-2/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚ÄúWelcome to Rstats‚Äù\n\n\nIn this introduction you will start working with RStudio. You will type in some data plot it and then customise your plot.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#session-overview",
    "href": "pgt52m/week-2/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this introduction you will start working with RStudio. You will type in some data plot it and then customise your plot.",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#philosophy",
    "href": "pgt52m/week-2/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#coat-colour-of-cats",
    "href": "pgt52m/week-2/workshop.html#coat-colour-of-cats",
    "title": "Workshop",
    "section": "üêà Coat colour of cats",
    "text": "üêà Coat colour of cats\nThe goal\nWe will work with some data on the coat colour of 62 cats. You are going to type data in R, summarise and plot it\nThe data are as a frequency table:\n\n\n\nFrequency of coat colours in 62 cats\n\nCoat colour\nNo. cats\n\n\n\nblack\n23\n\n\nwhite\n15\n\n\ntabby\n8\n\n\nginger\n10\n\n\ntortoiseshell\n5\n\n\ncalico\n1\n\n\n\n\n\nYou will create a figure like this:",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#creating-the-data",
    "href": "pgt52m/week-2/workshop.html#creating-the-data",
    "title": "Workshop",
    "section": "Creating the data",
    "text": "Creating the data\nStart by making a vector called coat that holds coat colours\n Write the following in your script:\n\n# coat colours\ncoat &lt;- c(\"black\", \"white\", \"tabby\", \"ginger\", \"tortoiseshell\", \"calico\")\n\nRemember, the shortcut for &lt;- is Alt+- (hold the Alt key down then hit the minus key ).\nNotice I have used a comment. Comment your code as much as possible!\n Ensure your cursor is on the line with the command and do Control+Enter to send the command to the console to be executed.\n Examine the ‚Äòstructure‚Äô of the coat object using str()\n\nstr(coat)\n\n chr [1:6] \"black\" \"white\" \"tabby\" \"ginger\" \"tortoiseshell\" \"calico\"\n\n\nIt‚Äôs vector of 6 character values, chr\n Create a vector called freq containing the numbers of cats with each coat colour and examine it with str().\n Check sum(freq) gives the answer you expect:\n\n# the total Number of cats\nsum(freq)\n\n[1] 62",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#packages",
    "href": "pgt52m/week-2/workshop.html#packages",
    "title": "Workshop",
    "section": "Packages",
    "text": "Packages\nCommands like c(), sum(), and str() are in packages which are part the ‚Äòbase‚Äô R system. A package is a collection of related commands. Base packages are installed automatically when you install R.\nOther packages, such as ggplot2 (Wickham 2016) need to be installed once and then loaded each session. ggplot2 is one of the tidyverse (Wickham et al. 2019) packages.\n\n\n\n\n\n\nImportant\n\n\n\nIf you are working on a University computer (or the VDS) you do not need to install tidyverse.\nIf you are working on your own computer or using RStudio cloud you do need to install tidyverse.\n\n\nTo install a package:\n Go the Packages tab on the lower right pane. Click Install and type tidyverse into the box that appears.\nWait until you get the prompt back. It will take a few moments, be patient!\nTo use a package which is installed you have to load it with the library() function. You will need to do this whether you are working on your own computer or on a University computer\n Load the tidyverse:\n\nlibrary(tidyverse)\n\nYou will likely be warned of some function name conflicts but these will not be a problem for you.",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#plotting-the-data-with-ggplot",
    "href": "pgt52m/week-2/workshop.html#plotting-the-data-with-ggplot",
    "title": "Workshop",
    "section": "Plotting the data with ggplot()\n",
    "text": "Plotting the data with ggplot()\n\nggplot() takes a dataframe for an argument\nWe can make a dataframe of the two vectors, coat and freq using the data.frame() function.\n Make a dataframe called coat_data\n\ncoat_data &lt;- data.frame(coat, freq)\n\n Check the structure of coat_data\nClick on coat_data in the Environment to open a spreadsheet-like view of it.",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#a-barplot",
    "href": "pgt52m/week-2/workshop.html#a-barplot",
    "title": "Workshop",
    "section": "A barplot",
    "text": "A barplot\n Create a simple barplot using ggplot like this:\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col()\n\n\n\n\n\n\n\nggplot() alone creates a blank plot.\nggplot(data = coat_data) looks the same.\naes() gives the ‚ÄòAesthetic mappings‚Äô. How variables (columns) are mapped to visual properties (aesthetics) e.g., axes, colour, shapes.\nThus‚Ä¶\nggplot(data = coat_data, aes(x = coat, y = freq)) produces a plot with axes\ngeom_col A ‚ÄòGeom‚Äô (Geometric object) gives the visual representations of the data: points, lines, bars, boxplots etc.\nNote that ggplot2 is the name of the package and ggplot() is its most important command.",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#using-the-help-manual",
    "href": "pgt52m/week-2/workshop.html#using-the-help-manual",
    "title": "Workshop",
    "section": "Using the help manual",
    "text": "Using the help manual\n‚ÄòArguments‚Äô can be added to the geom_col() command inside the brackets.\nCommands do something and their arguments (in brackets) and can specify:\n\nwhat object to do it to\n\nhow exactly to do it\n\nMany arguments have defaults so you don‚Äôt always need to supply them.\n Open the manual page for geom_col() using:\n\n?geom_col\n\nThe manual page has several sections.\n\n\nDescription an overview of what the command does\n\n\nUsage lists arguments\n\nform: argument name = default value\n\nsome arguments MUST be supplied others have defaults\n\n... means etc and includes arguments that can be passed to many ‚Äògeoms‚Äô\n\n\n\nArguments gives the detail about the arguments\n\nDetails describes how the command works in more detail\n\n\nValue gives the output of the command\nDon‚Äôt be too perturbed by not fully understanding the information",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#customising-the-plot",
    "href": "pgt52m/week-2/workshop.html#customising-the-plot",
    "title": "Workshop",
    "section": "Customising the plot",
    "text": "Customising the plot\nBar colour\n Change the fill of the bars using fill:\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col(fill = \"lightblue\")\n\n\n\n\n\n\n\nColours can be given by their name, ‚Äúlightblue‚Äù or code, ‚Äú#ADD8E6‚Äù.\nLook up by name or code\n Change the bars to a colour you like.\nfill is one of the arguments covered by .... fill is an ‚Äòaesthetic‚Äô. If you look for ... in the list of arguments you will see it says:\n\nOther arguments passed on to layer(). These are often aesthetics, used to set an aesthetic to a fixed value, like colour = ‚Äúred‚Äù or size = 3. They may also be parameters to the paired geom/stat.\n\nWe just set the `fill` aesthetic to a fixed value.\nFurther down the manual, there is a section on Aesthetics which lists those understood by geom_col()\nWe can set (map) the fill aesthetic to a fixed colour inside geom_col() or map it to a variable from the dataframe inside the aes() instead. This means the colour will be different for different values in that variable.\n Map the fill aesthetic to the coat variable:\n\nggplot(data = coat_data, aes(x = coat, y = freq, fill = coat)) +\n  geom_col()\n\n\n\n\n\n\n\nNote that we have taken fill = \"lightblue\" out of the geom_col() and instead put fill = coat in the aes().\n Use the manual to put the bars next to each other. Look for the argument that will mean there is no space between the bars.\n\n\n\n\n\n\n\n\n Use the manual to change the colour of the lines around each bar to black.\n\n\n\n\n\n\n\n\nChanging the axes\nWe can make changes to the axes using:\n\nChanges to a discrete x axis: scale_x_discrete()\n\nChanges to a continuous y axis: scale_y_continuous()\n\n\nggplot automatically extends the axes slightly. You can turn this behaviour off with the expand argument in scale_x_discrete() and scale_y_continuous().1\n Remove the gap between the axes and the data:\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col(fill = \"lightblue\", \n           width = 1, \n           colour = \"black\") +\n  scale_x_discrete(expand = c(0, 0)) + \n  scale_y_continuous(expand = c(0, 0)) \n\n\n\n\n\n\n\nEach ‚Äòlayer‚Äô is added to the ggplot() command with a +\n\n\n\n\n\n\nTop Tip\n\n\n\nMake your code easier to read by using white space and new lines\n\nput spaces around = , -&gt; and after ,\n\nuse a newline after every comma in a command with lots of arguments\n\n\n\n Look up scale_x_discrete in the manual and work out how to change the axis title from ‚Äúcoat‚Äù to ‚ÄúCoat colour‚Äù. Also change the y-axis title.\n\n\n\n\n\n\n\n\n I would prefer to see the y-axis extend a little beyond the data and we can change the axis ‚Äúlimits‚Äù in the scale_y_continuous()\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col(fill = \"lightblue\", \n           width = 1, \n           colour = \"black\") +\n  scale_x_discrete(expand = c(0, 0),\n                   name = \"Coat colour\") + \n  scale_y_continuous(expand = c(0, 0),\n                     name = \"Number of cats\",\n                     limits = c(0, 25)) \n\n\n\n\n\n\n\nGetting rid of the grey background\nThe grey grid background is useful for examining plots on a screen but for a report of publication you will want a more scientific style. Every aspect of the ‚Äútheme‚Äù of a plot - the non-data elements such as fonts, background colours, axis line colours etc - can be controlled individually2 but there are some handy built in themes that apply several changes at once. One of these is theme_classic()\n Add theme_classic() to the plot:\n\nggplot(data = coat_data, aes(x = coat, y = freq)) +\n  geom_col(width = 1, \n           colour = \"black\",\n           fill = \"lightblue\") +\n  scale_x_discrete(expand = c(0, 0),\n                   name = \"Coat colour\") + \n  scale_y_continuous(expand = c(0, 0),\n                     name = \"Number of cats\",\n                     limits = c(0, 25)) +\n  theme_classic()\n\n\n\n\n\n\n\nChanging the order of bars\nThe default ordering of a categorical variable like coat is alphabetical. Often we want to change the order. For example, you might want a ‚ÄúControl‚Äù on the left or the categories might have an inherent order (e.g., small, medium and large). We can alter (mutate) the coat variable using fct_relevel().\n Make ‚Äúwhite‚Äù the first category:\n\ncoat_data &lt;- coat_data |&gt; \n  mutate(coat = fct_relevel(coat, \"white\"))\n\n\n\n\n\n\n\nThe pipe |&gt;\n\n\n\n|&gt; is called the ‚Äúpipe‚Äù. A keyboard shortcut is Control+Shift+M\nThe pipe puts the output of one command (one the left) as input to another command (on the right). It can be read as ‚Äúand then‚Äù. You will more about it next week.\n\n\n Now plot again.\n\n\n\n\n\n\n\n\nIf you wanted white and then ginger you would do fct_relevel(coat, c(\"white\", \"ginger\")\nWe can also order the categories by the values in another variable by using reorder() in the plot code.\n Reorder the categories in coat by the the value in freq:\n\nggplot(data = coat_data, \n       aes(x = reorder(coat, freq, decreasing = TRUE), \n           y = freq)) +\n  geom_col(width = 1, \n           colour = \"black\",\n           fill = \"lightblue\") +\n  scale_x_discrete(expand = c(0, 0),\n                   name = \"Coat colour\") + \n  scale_y_continuous(expand = c(0, 0),\n                     name = \"Number of cats\",\n                     limits = c(0, 25)) +\n  theme_classic()\n\n\n\n\n\n\n\nYou‚Äôre finished!",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/workshop.html#footnotes",
    "href": "pgt52m/week-2/workshop.html#footnotes",
    "title": "Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\nThere are also scale_x_continous() and scale_y_discrete() functions when you have those types of variable‚Ü©Ô∏é\nModify components of a theme‚Ü©Ô∏é",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#outline",
    "href": "pgt52m/week-2/rstudio-projects.html#outline",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Outline",
    "text": "Outline\n\nWho\nA One-line what\nThe high-level why\n\n\nMight be enough!\n\n\n\nMore detailed why\nMore detailed what"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#audience",
    "href": "pgt52m/week-2/rstudio-projects.html#audience",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Audience",
    "text": "Audience\n\nYou teach using R directly\n\nBecoming a Bioscientist 1 - 4\nIM group project\nPGT\n\nYou teach or supervise students using R\n\nfield courses, practical work\nprojects\n\nYou use R"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#an-rstudio-project",
    "href": "pgt52m/week-2/rstudio-projects.html#an-rstudio-project",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "üìÅ An RStudio Project",
    "text": "üìÅ An RStudio Project\n\nis a folder!\n\n\n\nhave been part of the stage 1 and IM stage 3 for &gt; 5 years\n\n\n\nStage 1\n\nUse an RStudio project containing the script you used to analyse and plot the data for your report, your figures and and the data itself. The Project should be structured and the script should be well-commented, well-organised and follow good practice in the use of spacing, indentation, and variable naming. It should include all the code required to reproduce data import and formatting as well as the summary information, analyses, and figures in your report."
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#y12345678",
    "href": "pgt52m/week-2/rstudio-projects.html#y12345678",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Y12345678",
    "text": "Y12345678\ndemo"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#babs-1-4-lo-progression",
    "href": "pgt52m/week-2/rstudio-projects.html#babs-1-4-lo-progression",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "BABS 1-4 LO progression",
    "text": "BABS 1-4 LO progression\nBABS 1-5 LO progression"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#why-use-rstudio-projects",
    "href": "pgt52m/week-2/rstudio-projects.html#why-use-rstudio-projects",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Why use RStudio Projects",
    "text": "Why use RStudio Projects\n\nthe same reason we keep lab books: reproducibility and validation\n\n\nIt‚Äôs science!\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#why-use-rstudio-projects-1",
    "href": "pgt52m/week-2/rstudio-projects.html#why-use-rstudio-projects-1",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Why use RStudio Projects",
    "text": "Why use RStudio Projects\n\nTransferable: explicit training in organising work"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#why-use-rstudio-projects-2",
    "href": "pgt52m/week-2/rstudio-projects.html#why-use-rstudio-projects-2",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Why use RStudio Projects",
    "text": "Why use RStudio Projects\n\n\n\nhelp you to work with your most important collaborator\n\n\n\n\n\nfutureself, CC-BY-NC, by Julen Colomb"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#section",
    "href": "pgt52m/week-2/rstudio-projects.html#section",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "",
    "text": "via GIPHY"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#working-directories-and-paths",
    "href": "pgt52m/week-2/rstudio-projects.html#working-directories-and-paths",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Working directories and Paths",
    "text": "Working directories and Paths\n\ndirectory means folder\nimportant concepts when you interact with computers without clicking\n\n\nAllison Horst cartoon ‚Äúcode gets the blame‚Äù"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#working-directories",
    "href": "pgt52m/week-2/rstudio-projects.html#working-directories",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Working directories",
    "text": "Working directories\n\nDefault folder a program will read and write to.\nYou will have some understanding\n\nWord demo"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#paths",
    "href": "pgt52m/week-2/rstudio-projects.html#paths",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Paths",
    "text": "Paths\n\nlocation of a file/folder\nappear in the address bar of explorer/finder and browsers\n\ndemo\n\n\nwhen you can‚Äôt click, you need the path\n\n\nchaffinch &lt;- read_table(\"chaff.txt\")"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#absolute-path",
    "href": "pgt52m/week-2/rstudio-projects.html#absolute-path",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Absolute path",
    "text": "Absolute path\n\nchaffinch &lt;- read_table(\"C:/Users/er13/OneDrive - University of York/Desktop/Desktop/undergrad-teaching-york/BIO00017C/BIO00017C-Data-Analysis-in-R-2020/data/chaff.txt\")\n\n\nOnly exists on my computer!"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#relative-paths",
    "href": "pgt52m/week-2/rstudio-projects.html#relative-paths",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "Relative paths",
    "text": "Relative paths\n\nlocation of a file/folder relative to the working directory\nIf my working directory is BIO00017C-Data-Analysis-in-R-2020:\n\n\nchaffinch &lt;- read_table(\"data/chaff.txt\")"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#rstudio-projects",
    "href": "pgt52m/week-2/rstudio-projects.html#rstudio-projects",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nSets the working directory to be the project folder\nCode is portable: you send someone the folder and everything just works!"
  },
  {
    "objectID": "pgt52m/week-2/rstudio-projects.html#demo",
    "href": "pgt52m/week-2/rstudio-projects.html#demo",
    "title": "RStudio ProjectsWho, what, why?",
    "section": "demo",
    "text": "demo"
  },
  {
    "objectID": "pgt52m/week-2/overview.html",
    "href": "pgt52m/week-2/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week you will start writing R code in RStudio and will create your first graph! You will learn about data types such as ‚Äúnumerics‚Äù and ‚Äúcharacters‚Äù and some of the different types of objects in R such as ‚Äúvectors‚Äù and ‚Äúdataframes‚Äù. These are the building blocks for the rest of your R journey. You will also learn a workflow and about the layout of RStudio and using RStudio Projects.\n\n\n\nArtwork by Horst (2023): ‚Äúbless this workflow‚Äù\n\n\n\nLearning objectives\nThe successful student will be able to:\n\nuse the R command line as a calculator and to assign variables\ncreate and use the basic data types in R\nfind their way around the RStudio windows\nuse an RStudio Project to organise work\nuse a script to run R commands\ncreate and customise a barplot\nsearch and understand manual pages\n\n\n\nInstructions\n\nPrepare\n\nFirst Steps in RStudio: Either üìñ Read the book OR üìπ Watch two videos\n\nWorkshop\ni.üíª üêà Coat colour of cats. Type in some data, perform calculations on, and plot it.\nConsolidate\n\nüíª Create a plot\nüìñ Read Workflow in RStudio\n\n\n\n\n\n\n\nReferences\n\nHorst, Allison. 2023. ‚ÄúData Science Illustrations.‚Äù https://allisonhorst.com/allison-horst.",
    "crumbs": [
      "PGT 52M",
      "Week 2: Introduction to R and project organisation",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-4/study_before_workshop.html",
    "href": "pgt52m/week-4/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read From importing to reporting. The first part of this chapter is about data import which we covered in the last workshop. You may be able to skip that part or you may find it useful to revise. The section on Summarising data will be mainly new.",
    "crumbs": [
      "PGT 52M",
      "Week 4: Summarising data with several variables",
      "Prepare!"
    ]
  },
  {
    "objectID": "pgt52m/week-4/overview.html",
    "href": "pgt52m/week-4/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Last week you summarised and plotted single variables. This week you will start plotting data sets with more than one variable. This means you need to be able determine which variable is the response and which is the explanatory. You will find out what is meant by ‚Äútidy‚Äù data and how to perform a simple data tidying task. Finally you will discover how to save your figures and place them in documents.\n\nLearning objectives\n\nsummarise and plot appropriately datasets with more than one variable\nrecognise that variables can be categorised by their role in analysis\nexplain what is meant by ‚Äòtidy‚Äô data and be able to perform some data tidying tasks.\nsave figures to file\ncreate neat reports which include text and figures\n\n\n\nInstructions\n\nPrepare\n\nüìñ From importing to reporting\n\nWorkshop\n\nüíª Summarise and plot datasets with more than one variable.\nüíª Practice with working directories, importing data, formatting figures and the pipe\nüíª Lay out text, figures and figure legends in documents\n\nConsolidate\n\nüíª Summarise and plot a dataframe from the workshop\nüíª Practice the complete RStudio Project worklfow for a new dataset",
    "crumbs": [
      "PGT 52M",
      "Week 4: Summarising data with several variables",
      "About"
    ]
  },
  {
    "objectID": "pgt52m/week-5/workshop.html",
    "href": "pgt52m/week-5/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚Äúlove this class‚Äù\n\n\nIn this session you will remind yourself how to import files, and calculate confidence intervals on large and small samples.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 5: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-5/workshop.html#session-overview",
    "href": "pgt52m/week-5/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this session you will remind yourself how to import files, and calculate confidence intervals on large and small samples.",
    "crumbs": [
      "PGT 52M",
      "Week 5: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-5/workshop.html#philosophy",
    "href": "pgt52m/week-5/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 5: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-5/workshop.html#remind-yourself-how-to-import-files",
    "href": "pgt52m/week-5/workshop.html#remind-yourself-how-to-import-files",
    "title": "Workshop",
    "section": "Remind yourself how to import files!",
    "text": "Remind yourself how to import files!\nImporting data from files was covered in a previous workshop (Rand 2023) if you need to remind yourself.",
    "crumbs": [
      "PGT 52M",
      "Week 5: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-5/workshop.html#confidence-intervals-large-samples",
    "href": "pgt52m/week-5/workshop.html#confidence-intervals-large-samples",
    "title": "Workshop",
    "section": "Confidence intervals (large samples)",
    "text": "Confidence intervals (large samples)\nThe data in beewing.txt are left wing widths of 100 honey bees (mm). The confidence interval for large samples is given by:\n\\(\\bar{x} \\pm 1.96 \\times s.e.\\)\nWhere 1.96 is the quantile for 95% confidence.\n Save beewing.txt to your data-raw folder.\n Read in the data and check the structure of the resulting dataframe.\n Calculate and assign to variables: the mean, standard deviation and standard error:\n\n# mean\nm &lt;- mean(bee$wing)\n\n# standard deviation\nsd &lt;- sd(bee$wing)\n\n# sample size (needed for the se)\nn &lt;- length(bee$wing)\n\n# standard error\nse &lt;- sd / sqrt(n)\n\n To calculate the 95% confidence interval we need to look up the quantile (multiplier) using qnorm()\n\nq &lt;- qnorm(0.975)\n\nThis should be about 1.96.\n Now we can use it in our confidence interval calculation\n\nlcl &lt;- m - q * se\nucl &lt;- m + q * se\n\n Print the values\n\nlcl\n\n[1] 4.473176\n\nucl\n\n[1] 4.626824\n\n\nThis means we are 95% confident the population mean lies between 4.47 mm and 4.63 mm. The usual way of expressing this is that the mean is 4.55 +/- 0.07 mm\n Between what values would you be 99% confident of the population mean being?",
    "crumbs": [
      "PGT 52M",
      "Week 5: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-5/workshop.html#confidence-intervals-small-samples",
    "href": "pgt52m/week-5/workshop.html#confidence-intervals-small-samples",
    "title": "Workshop",
    "section": "Confidence intervals (small samples)",
    "text": "Confidence intervals (small samples)\nThe confidence interval for small samples is given by:\n\\(\\bar{x} \\pm \\sf t_{[d.f]} \\times s.e.\\)\nThe only difference between the calculation for small and large sample is the multiple. For large samples we use the ‚Äúthe standard normal distribution‚Äù accessed with qnorm(); for small samples we use the ‚Äút distribution‚Äù assessed with qt().The value returned by q(t) is larger than that returned by qnorm() which reflects the greater uncertainty we have on estimations of population means based on small samples.\nThe fatty acid Docosahexaenoic acid (DHA) is a major component of membrane phospholipids in nerve cells and deficiency leads to many behavioural and functional deficits. The cross sectional area of neurons in the CA 1 region of the hippocampus of normal rats is 155 \\(\\mu m^2\\). A DHA deficient diet was fed to 8 animals and the cross sectional area (csa) of neurons is given in neuron.txt\n Save neuron.txt to your data-raw folder\n Read in the data and check the structure of the resulting dataframe\n Assign the mean to m.\n Calculate and assign the standard error to se.\nTo work out the confidence interval for our sample mean we need to use the t distribution because it is a small sample. This means we need to determine the degrees of freedom (the number in the sample minus one).\n We can assign this to a variable, df, using:\n\ndf &lt;- length(neur$csa) - 1\n\n The t value is found by:\n\nt &lt;- qt(0.975, df = df)\n\nNote that we are using qt() rather than qnorm() but that the probability, 0.975, used is the same. Finally, we need to put our mean, standard error and t value in the equation. \\(\\bar{x} \\pm \\sf t_{[d.f]} \\times s.e.\\).\n The upper confidence limit is:\n\n(m + t * se) |&gt; round(2)\n\n[1] 151.95\n\n\nThe first part of the command, (m + t * se) calculates the upper limit. This is ‚Äòpiped‚Äô in to the round() function to round the result to two decimal places.\n Calculate the lower confidence limit:\n Given the upper and lower confidence values for the estimate of the population mean, what do you think about the effect of the DHA deficient diet?\n\n\n\n\nYou‚Äôre finished!",
    "crumbs": [
      "PGT 52M",
      "Week 5: The logic of hypothesis testing and CI",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-5/study_after_workshop.html",
    "href": "pgt52m/week-5/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª Adiponectin is exclusively secreted from adipose tissue and modulates a number of metabolic processes. Nicotinic acid can affect adiponectin secretion. 3T3-L1 adipocytes were treated with nicotinic acid or with a control treatment and adiponectin concentration (pg/mL) measured. The data are in adipocytes.txt. Each row represents an independent sample of adipocytes and the first column gives the concentration adiponectin and the second column indicates whether they were treated with nicotinic acid or not. Estimate the mean Adiponectin concentration in each group - this means calculate the sample mean and construct a confidence interval around it for each group. This exercise forces you to bring together ideas from this workshop and from previous workshops\n\n\nHow to calculate a confidence intervals (this workshop)\n\nHow to summarise variables in more than one group (previous workshop)\n\n\nAnswer - don‚Äôt look until you have tried!# data import\nadip &lt;- read_table(\"data-raw/adipocytes.txt\")\n\n# examine the structure\nstr(adip)\n\n# summarise\nadip_summary &lt;- adip %&gt;% \n  group_by(treatment) %&gt;% \n  summarise(mean = mean(adiponectin),\n            sd = sd(adiponectin),\n            n = length(adiponectin),\n            se = sd/sqrt(n),\n            dif = qt(0.975, df = n - 1) * se,\n            lower_ci = mean - dif,\n            uppp_ci = mean + dif)\n\n\n# we conclude we're 95% certain the mean for the control group is \n# between 4.73 and 6.36 and the mean for the nicotinic group is \n# between 6.52 and 8.50. More usually we might put is like this:\n# the mean for the control group is 5.55 +/- 0.82 and that for the nicotinic group is 7.51 +/- 0.99",
    "crumbs": [
      "PGT 52M",
      "Week 5: The logic of hypothesis testing and CI",
      "Consolidate!"
    ]
  },
  {
    "objectID": "pgt52m/week-7/workshop.html",
    "href": "pgt52m/week-7/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚ÄúHow much I think I know about R‚Äù\n\n\nIn this workshop you will get practice in choosing between, performing, and presenting the results of, two-sample tests and their non-parametric equivalents in R.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-7/workshop.html#session-overview",
    "href": "pgt52m/week-7/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will get practice in choosing between, performing, and presenting the results of, two-sample tests and their non-parametric equivalents in R.",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-7/workshop.html#philosophy",
    "href": "pgt52m/week-7/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-7/workshop.html#adiponectin-secretion",
    "href": "pgt52m/week-7/workshop.html#adiponectin-secretion",
    "title": "Workshop",
    "section": "Adiponectin secretion",
    "text": "Adiponectin secretion\nAdiponectin is exclusively secreted from adipose tissue and modulates a number of metabolic processes. Nicotinic acid can affect adiponectin secretion. 3T3-L1 adipocytes were treated with nicotinic acid or with a control treatment and adiponectin concentration (pg/mL) measured. The data are in adipocytes.txt. Each row represents an independent sample of adipocytes and the first column gives the concentration adiponectin and the second column indicates whether they were treated with nicotinic acid or not.\n Save a copy of adipocytes.txt to data-raw\n Read in the data and check the structure. I used the name adip for the dataframe/tibble.\nWe have a tibble containing two variables: adiponectin is the response and is continuous and treatment is explanatory. treatment is categorical with two levels (groups). The first task is visualise the data to get an overview. For continuous response variables with categorical explanatory variables you could use geom_point(), geom_boxplot() or a variety of other geoms. I often use geom_violin() which allows us to see the distribution - the violin is fatter where there are more data points.\n Do a quick plot of the data:\n\nggplot(data = adip, aes(x = treatment, y = adiponectin)) +\n  geom_violin()\n\n\n\n\n\n\n\nSummarising the data\nSummarising the data for each treatment group is the next sensible step. The most useful summary statistics are the means, standard deviations, sample sizes and standard errors.\n Create a data frame called adip_summary that contains the means, standard deviations, sample sizes and standard errors for the control and nicotinic acid treated samples. You may need to the Summarise from the Week 4 workshop\nYou should get the following numbers:\n\n\n\n\ntreatment\nmean\nstd\nn\nse\n\n\n\ncontrol\n5.546000\n1.475247\n15\n0.3809072\n\n\nnicotinic\n7.508667\n1.793898\n15\n0.4631824\n\n\n\n\n\nSelecting a test\n Do you think this is a paired-sample test or two-sample test?\n\n\n\n\nApplying, interpreting and reporting\n Create a two-sample model like this:\n\nmod &lt;- lm(data = adip,\n          adiponectin ~ treatment)\n\n Examine the model with:\n\nsummary(mod)\n\n\nCall:\nlm(formula = adiponectin ~ treatment, data = adip)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3787 -1.0967  0.1927  1.0245  3.1113 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          5.5460     0.4240  13.079  1.9e-13 ***\ntreatmentnicotinic   1.9627     0.5997   3.273  0.00283 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.642 on 28 degrees of freedom\nMultiple R-squared:  0.2767,    Adjusted R-squared:  0.2509 \nF-statistic: 10.71 on 1 and 28 DF,  p-value: 0.00283\n\n\n What do you conclude from the test? Write your conclusion in a form suitable for a report.\n\n\n\n\nCheck assumptions\nThe assumptions of the general linear model are that the residuals ‚Äì the difference between predicted value (i.e., the group mean) and observed values - are normally distributed and have homogeneous variance. To check these we can examine the mod$residuals variable. You may want to refer to Checking assumptions in the ‚ÄúSingle regression‚Äù workshop.\n Plot the model residuals against the fitted values.\n What to you conclude?\n\n\n\nTo examine normality of the model residuals we can plot them as a histogram and do a normality test on them.\n Plot a histogram of the residuals.\n Use the shapiro.test() to test the normality of the model residuals\n What to you conclude?\n\n\n\n\nIllustrating\n Create a figure like the one below. You may need to refer to Visualise from the ‚ÄúSummarising data with several variables‚Äù workshop (Rand 2023)\n\n\n\n\n\n\n\n\nWe now need to annotate the figure with the results from the statistical test. This most commonly done with a line linking the means being compared and the p-value. The annotate() function can be used to draw the line and then to add the value. The line is a segment and the p-value is a text.\n Add annotation to the figure by adding:\n...... +\n  annotate(\"segment\", x = 1, xend = 2, \n           y = 11.3, yend = 11.3,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.5,  y = 11.7, \n           label = expression(italic(p)~\"= 0.003\")) +\n  theme_classic()\n\n\n\n\n\n\n\n\nFor the segment, annotate() needs the x and y coordinates for the start and the finish of the line.\nThe use of expression() allows you to specify formatting or special characters. expression() takes strings or LaTeX formatting. Each string or piece of LaTeX is separated by a * or a ~. The * concatenates the strings without a space, ~ does so with a space. It will generate a warning message ‚ÄúIn is.na(x) : is.na() applied to non-(list or vector) of type ‚Äòexpression‚Äô‚Äù which can be ignored.\n Save your figure to your figures folder.",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-7/workshop.html#grouse-parasites",
    "href": "pgt52m/week-7/workshop.html#grouse-parasites",
    "title": "Workshop",
    "section": "Grouse Parasites",
    "text": "Grouse Parasites\nGrouse livers were dissected and the number of individuals of a parasitic nematode were counted for two estates ‚ÄòGordon‚Äô and ‚ÄòMoss‚Äô. We want to know if the two estates have different infection rates. The data are in grouse.csv\n Save a copy of grouse.csv to data-raw\n Read in the data and check the structure. I used the name grouse for the dataframe/tibble.\nSelecting\n Using your common sense, do these data look normally distributed?\n\n\n\n What test do you suggest?\n\n\nApplying, interpreting and reporting\n Summarise the data by finding the median of each group:\n Carry out a two-sample Wilcoxon test (also known as a Mann-Whitney):\n\nwilcox.test(data = grouse, nematodes ~ estate)\n\n\n    Wilcoxon rank sum exact test\n\ndata:  nematodes by estate\nW = 78, p-value = 0.03546\nalternative hypothesis: true location shift is not equal to 0\n\n\n What do you conclude from the test? Write your conclusion in a form suitable for a report.\n\n\n\nIllustrating\nA box plot is a usually good choice for illustrating a two-sample Wilcoxon test because it shows the median and interquartile range.\n We can create a simple boxplot with:\n\nggplot(data = grouse, aes(x = estate, y = nematodes) ) +\n  geom_boxplot() \n\n\n\n\n\n\n\n Annotate and format the figure so it is more suitable for a report and save it to your figures folder.",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-7/workshop.html#gene-expression",
    "href": "pgt52m/week-7/workshop.html#gene-expression",
    "title": "Workshop",
    "section": "Gene Expression",
    "text": "Gene Expression\nBambara groundnut (Vigna subterranea) is an African legume with good nutritional value which can be influenced by low temperature stress. Researchers are interested in the expression levels of a particular set of 35 genes (probe_id) in response to temperature stress. They measure the expression of the genes at 23 and 18 degrees C (high and low temperature). These samples are not independent because we have two measure from one gene. The data are in expr.xlxs.\nSelecting\n What is the null hypothesis?\n\n\n\n Save a copy of expr.xlxs and import the data. I named the dataframe bambara\n What is the appropriate parametric test?\n\n\nApplying, interpreting and reporting\nA paired test requires us to test whether the difference in expression between high and low temperatures is zero on average. One handy way to achieve this is to organise our groups into two columns. The pivot_wider() function will do this for us. We need to tell it what column gives the identifiers (i.e., matches the the pairs) - the probe_ids in this case. We also need to say which variable contains what will become the column names and which contains the values.\n Pivot the data so there is a column for each temperature:\n\nbambara &lt;- bambara |&gt; \n  pivot_wider(names_from = temperature, \n              values_from = expression, \n              id_cols = probe_id)\n\n Click on the bambara dataframe in the environment to open a view of it so that you understand what pivot_wider() has done.\n Create a paired-sample model like this:\n\nmod &lt;- lm(data = bambara, \n          highert - lowert ~ 1)\n\nSince we have done highert - lowert, the ‚Äú(Intercept) Estimate‚Äù will be the average of the higher temperature expression minus the lower temperature expression for each gene.\n Examine the model with:\n\nsummary(mod)\n\n\nCall:\nlm(formula = highert - lowert ~ 1, data = bambara)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.05478 -0.46058  0.09682  0.33342  1.06892 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  0.30728    0.09591   3.204  0.00294 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5674 on 34 degrees of freedom\n\n\n State your conclusion from the test in a form suitable for including in a report. Make sure you give the direction of any significant effect.",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-7/workshop.html#look-after-future-you",
    "href": "pgt52m/week-7/workshop.html#look-after-future-you",
    "title": "Workshop",
    "section": "Look after future you!",
    "text": "Look after future you!\nThe code required to summarise, test, and plot data for any two-sample test AND for any for any one-way ANOVA is exactly the same except for the names of the dataframe, variables and the axis labels and limits. Take some time to comment it your code so that you can make use of it next week.\n\nYou‚Äôre finished!",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-7/study_after_workshop.html",
    "href": "pgt52m/week-7/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª Plant Biotech. Some plant biotechnologists are trying to increase the quantity of omega 3 fatty acids in Cannabis sativa. They have developed a genetically modified line using genes from Linum usitatissimum (linseed). They grow 50 wild type and fifty modified plants to maturity, collect the seeds and determine the amount of omega 3 fatty acids. The data are in csativa.txt. Do you think their modification has been successful?\n\n\nAnswer - don‚Äôt look until you have tried!csativa  &lt;-  read_table(\"data-raw/csativa.txt\")\nstr(csativa)\n\n# First realise that this is a two sample test. You have two independent samples\n#  - there are a total of 100 different plants and the values in one \n#  group have no relationship to the values in the other.\n\n\n\nAnswer - don‚Äôt look until you have tried!# create a rough plot of the data  \nggplot(data = csativa, aes(x = plant, y = omega)) +\n  geom_violin()\nAnswer - don‚Äôt look until you have tried!# note the modified plants seem to have lower omega!\n\n\n\nAnswer - don‚Äôt look until you have tried!# create a summary of the data\ncsativa_summary &lt;- csativa %&gt;%\n  group_by(plant) %&gt;%\n  summarise(mean = mean(omega),\n            std = sd(omega),\n            n = length(omega),\n            se = std/sqrt(n))\n\n\n\nAnswer - don‚Äôt look until you have tried!# The data seem to be continuous so it is likely that a parametric test will be fine\n# we will check the other assumptions after we have run the lm\n\n# build the statistical model\nmod &lt;- lm(data = csativa, omega ~ plant)\n\n\n# examine it\nsummary(mod)\n# So there is a significant difference but you need to make sure you know the direction!\n# Wild plants have a significantly higher omega 3 content (mean +/- s.e =  56.41 +/- 1.11) \n# than modified plants (49.46 +/- 0.82)(t = 5.03; d.f. = 98; p &lt; 0.0001).\n\n\n\nAnswer - don‚Äôt look until you have tried!# let's check the assumptions\nplot(mod, which = 1) \nAnswer - don‚Äôt look until you have tried!# we're looking for the variance in the residuals to be the same in both groups.\n# This looks OK. Maybe a bit higher in the wild plants (with the higher mean)\n \nhist(mod$residuals)\nAnswer - don‚Äôt look until you have tried!shapiro.test(mod$residuals)\n# On balance the use of lm() is probably justifiable  The variance isn't quite equal \n# and the histogram looks a bit off normal but the normality test is NS and the \n# effect (in the figure) is clear.\n\n\n\nAnswer - don‚Äôt look until you have tried!# A figure \nfig1 &lt;- ggplot() +\n  geom_point(data = csativa, aes(x = plant, y = omega),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"gray50\") +\n  geom_errorbar(data = csativa_summary, \n                aes(x = plant, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = csativa_summary, \n                aes(x = plant, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_x_discrete(name = \"Plant type\", labels = c(\"GMO\", \"WT\")) +\n  scale_y_continuous(name = \"Amount of Omega 3 (units)\",\n                     expand = c(0, 0),\n                     limits = c(0, 90)) +\n    annotate(\"segment\", x = 1, xend = 2, \n           y = 80, yend = 80,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.5,  y = 85, \n           label = expression(italic(p)~\"&lt; 0.001\")) +\n  theme_classic()\n\n# save figure to figures/csativa.png\nggsave(\"figures/csativa.png\",\n       plot = fig1,\n       width = 3.5,\n       height = 3.5,\n       units = \"in\",\n       dpi = 300)\n\n\n\nüíª another example",
    "crumbs": [
      "PGT 52M",
      "Week 7: Two-sample tests",
      "Consolidate!"
    ]
  },
  {
    "objectID": "pgt52m/week-6/workshop.html",
    "href": "pgt52m/week-6/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will get practice in applying, interpreting and reporting single linear regression.\n\n\nArtwork by Horst (2023): ‚Äúlinear regression dragons‚Äù\n\n\nIn this session you will carry out, interpret and report on a single linear regression.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 6: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-6/workshop.html#session-overview",
    "href": "pgt52m/week-6/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this session you will carry out, interpret and report on a single linear regression.",
    "crumbs": [
      "PGT 52M",
      "Week 6: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-6/workshop.html#philosophy",
    "href": "pgt52m/week-6/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 6: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-6/workshop.html#linear-regression",
    "href": "pgt52m/week-6/workshop.html#linear-regression",
    "title": "Workshop",
    "section": "Linear Regression",
    "text": "Linear Regression\nThe data in plant.xlsx is a set of observations of plant growth over two months. The researchers planted the seeds and harvested, dried and weighed a plant each day from day 10 so all the data points are independent of each other.\n Save a copy of plant.xlsx to your data-raw folder and import it.\n What type of variables do you have? Which is the response and which is the explanatory? What is the null hypothesis?\n\n\n\n\n\n\nExploring\n Do a quick plot of the data:\n\nggplot(plant, aes(x = day, y = mass)) +\n  geom_point()\n\n\n\n\n\n\n\n What are the assumptions of linear regression? Do these seem to be met?\n\n\n\n\n\n\n\n\n\n\nApplying, interpreting and reporting\n We now carry out a regression assigning the result of the lm() procedure to a variable and examining it with summary().\n\nmod &lt;- lm(data = plant, mass ~ day)\nsummary(mod)\n\n\nCall:\nlm(formula = mass ~ day, data = plant)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.810 -11.253  -0.408   9.075  48.869 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -8.6834     6.4729  -1.342    0.186    \nday           1.6026     0.1705   9.401  1.5e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.92 on 49 degrees of freedom\nMultiple R-squared:  0.6433,    Adjusted R-squared:  0.636 \nF-statistic: 88.37 on 1 and 49 DF,  p-value: 1.503e-12\n\n\nThe Estimates in the Coefficients table give the intercept (first line) and the slope (second line) of the best fitting straight line. The p-values on the same line are tests of whether that coefficient is different from zero.\nThe F value and p-value in the last line are a test of whether the model as a whole explains a significant amount of variation in the dependent variable. For a single linear regression this is exactly equivalent to the test of the slope against zero.\n What is the equation of the line? What do you conclude from the analysis?\n\n\n\n\n\n Does the line go through (0,0)?\n\n\n\n What percentage of variation is explained by the line?\n\n\nIt might be useful to assign the slope and the intercept to variables in case we need them later. The can be accessed in the mod$coefficients variable:\n\nmod$coefficients\n\n(Intercept)         day \n  -8.683379    1.602606 \n\n\n Assign mod$coefficients[1] to b0 and mod$coefficients[1] to b1:\n\nb0 &lt;- mod$coefficients[1] |&gt; round(2)\nb1 &lt;- mod$coefficients[2] |&gt; round(2)\n\nI also rounded the values to two decimal places.\nChecking assumptions\nWe need to examine the residuals. Very conveniently, the object which is created by lm() contains a variable called $residuals. Also conveniently, the R‚Äôs plot() function can used on the output objects of lm(). The assumptions demand that each y is drawn from a normal distribution for each x and these normal distributions have the same variance. Therefore we plot the residuals against the fitted values to see if the variance is the same for all the values of x. The fitted - predicted - values are the values on the line of best fit. Each residual is the difference between the fitted values and the observed value.\n Plot the model residuals against the fitted values like this:\n\nplot(mod, which = 1)\n\n\n\n\n\n\n\n What to you conclude?\n\n\n\nTo examine normality of the model residuals we can plot them as a histogram and do a normality test on them.\n Plot a histogram of the residuals:\n\nggplot(mapping = aes(x = mod$residuals)) + \n  geom_histogram(bins = 10)\n\n\n\n\n\n\n\n Use the shapiro.test() to test the normality of the model residuals\n\nshapiro.test(mod$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mod$residuals\nW = 0.96377, p-value = 0.1208\n\n\nUsually, when we are doing statistical tests we would like the the test to be significant because it means we have evidence of a biological effect. However, when doing normality tests we hope it will not be significant. A non-significant result means that there is no significant difference between the distribution of the residuals and a normal distribution and that indicates the assumptions are met.\n What to you conclude?\n\n\n\n\nIllustrating\nWe want a figure with the points and the statistical model, i.e., the best fitting straight line.\n Create a scatter plot using geom_point()\n\nggplot(plant, aes(x = day, y = mass)) +\n  geom_point() + \n  theme_classic()\n\n\n\n\n\n\n\n The geom_smooth() function will had a variety of fitted lines to a plot. We want a line so we need to specify method = \"lm\":\n\nggplot(plant, aes(x = day, y = mass)) +\n  geom_point() +   \n  geom_smooth(method = lm, \n              se = FALSE, \n              colour = \"black\") +\n  theme_classic()\n\n\n\n\n\n\n\n What do the se and colour arguments do? Try changing them.\n Let‚Äôs add the equation of the line to the figure using annotate():\n\nggplot(plant, aes(x = day, y = mass)) +\n  geom_point() +\n  geom_smooth(method = lm, \n              se = FALSE, \n              colour = \"black\") +\n  annotate(\"text\", x = 20, y = 110, \n           label = \"mass = 1.61 * day - 8.68\") +\n  theme_classic()\n\n\n\n\n\n\n\nWe have to tell annotate() what type of geom we want - text in this case, - where to put it, and the text we want to appear.\n Improve the axes. You may need to refer back Changing the axes from the Week 2 workshop\n Save your figure to your figures folder.",
    "crumbs": [
      "PGT 52M",
      "Week 6: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-6/workshop.html#look-after-future-you",
    "href": "pgt52m/week-6/workshop.html#look-after-future-you",
    "title": "Workshop",
    "section": "Look after future you!",
    "text": "Look after future you!\nYou‚Äôre finished!",
    "crumbs": [
      "PGT 52M",
      "Week 6: Introduction to statistical models: Single regression",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-6/study_after_workshop.html",
    "href": "pgt52m/week-6/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª Effect of anxiety status and sporting performance. The data in sprint.txt are from an investigation of the effect of anxiety status and sporting performance. A group of 40 100m sprinters undertook a psychometric test to measure their anxiety shortly before competing. The data are their anxiety scores and the 100m times achieved. What you do conclude from these data?\n\n\nAnswer - don‚Äôt look until you have tried!# this example is designed to emphasise the importance of plotting your data first\nsprint &lt;- read_table(\"data-raw/sprint.txt\")\n# Anxiety is discrete but ranges from 16 to 402 meaning the gap between possible measures is small and \n# the variable could be treated as continuous if needed. Time is a continuous measure that has decimal places and which we would expect to follow a normal distribution \n\n# explore with a plot\nggplot(sprint, aes(x = anxiety, y = time) ) +\n  geom_point()\nAnswer - don‚Äôt look until you have tried!# A scatterplot of the data clearly reveals that these data are not linear. There is a good relationship between the two variables but since it is not linear, single linear regression is not appropriate.\n\n\n\nüíª Juvenile hormone in stag beetles. The concentration of juvenile hormone in stag beetles is known to influence mandible growth. Groups of stag beetles were injected with different concentrations of juvenile hormone (arbitrary units) and their average mandible size (mm) determined. The experimenters planned to analyse their data with regression. The data are in stag.txt\n\n\n\nAnswer - don‚Äôt look until you have tried!# read the data in and check the structure\nstag &lt;- read_table(\"data-raw/stag.txt\")\nstr(stag)\n\n# jh is discrete but ordered and has been chosen by the experimenter - it is the explanatory variable.  \n# the response is mandible size which has decimal places and is something we would expect to be \n# normally distributed. So far, common sense suggests the assumptions of regression are met.\n\n\n\nAnswer - don‚Äôt look until you have tried!# exploratory plot\nggplot(stag, aes(x = jh, y = mand)) +\n  geom_point()\nAnswer - don‚Äôt look until you have tried!# looks linear-ish on the scatter\n# regression still seems appropriate\n# we will check the other assumptions after we have run the lm\n\n\n\nAnswer - don‚Äôt look until you have tried!# build the statistical model\nmod &lt;- lm(data = stag, mand ~ jh)\n\n# examine it\nsummary(mod)\n# mand = 0.032*jh + 0.419\n# the slope of the line is significantly different from zero / the jh explains a significant amount of the variation in mand (ANOVA: F = 16.63; d.f. = 1,14; p = 0.00113).\n# the intercept is 0.419 and differs significantly from zero \n\n\n\nAnswer - don‚Äôt look until you have tried!# checking the assumption\nplot(mod, which = 1) \nAnswer - don‚Äôt look until you have tried!# we're looking for the variance in the residuals to be equal along the x axis.\n# with a small data set there is some apparent heterogeneity but it doesn't look too.\n# \nhist(mod$residuals)\nAnswer - don‚Äôt look until you have tried!# We have some skew which again might be partly a result of a small sample size.\nshapiro.test(mod$residuals) # the also test not sig diff from normal\n\n# On balance the use of regression is probably justifiable but it is borderline\n# but ideally the experiment would be better if multiple individuals were measure at\n# each of the chosen juvenile hormone levels.\n\n\n\nAnswer - don‚Äôt look until you have tried!# a better plot\nggplot(stag, aes(x = jh, y = mand) ) +\n  geom_point() +\n  geom_smooth(method = lm, se = FALSE, colour = \"black\") +\n  scale_x_continuous(name = \"Juvenile hormone (arbitrary units)\",\n                     expand = c(0, 0),\n                     limits = c(0, 32)) +\n  scale_y_continuous(name = \"Mandible size (mm)\",\n                     expand = c(0, 0),\n                     limits = c(0, 2)) +\n  theme_classic()",
    "crumbs": [
      "PGT 52M",
      "Week 6: Introduction to statistical models: Single regression",
      "Consolidate!"
    ]
  },
  {
    "objectID": "pgt52m/week-3/workshop.html",
    "href": "pgt52m/week-3/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): Continuous and Discrete\n\n\nIn this workshop you will learn how to import data from files and create summaries and plots for it. You will also get more practice with working directories, formatting figures and the pipe.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/workshop.html#session-overview",
    "href": "pgt52m/week-3/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will learn how to import data from files and create summaries and plots for it. You will also get more practice with working directories, formatting figures and the pipe.",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/workshop.html#philosophy",
    "href": "pgt52m/week-3/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier workshops\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/workshop.html#importing-data-from-files",
    "href": "pgt52m/week-3/workshop.html#importing-data-from-files",
    "title": "Workshop",
    "section": "Importing data from files",
    "text": "Importing data from files\nLast week we created data by typing the values in to R. This is not practical when you have added a lot of data to a spreadsheet, or you are using data file that has been supplied to you by a person or a machine. Far more commonly, we import data from a file into R. This requires you know two pieces of information.\n\n\nWhat format the data are in\nThe format of the data determines what function you will use to import it and the file extension often indicates format.\n\n\n.txt a plain text file1, where the columns are often separated by a space but might also be separated by a tab, a backslash or forward slash, or some other character\n\n.csv a plain text file where the columns are separated by commas\n\n.xlsx an Excel file\n\n\n\nWhere the file is relative to your working directory\nR can only read in a file if you say where it is, i.e., you give its relative path. If you follow the advice in this course, your data will be in a folder, data-raw which is inside your Project folder (and working directory).\n\n\nWe will save the four files for this workshop to our Project folder (week-8) and read them in. We will then create a new folder inside our Project folder called data-raw and move the data files to there before modifying the file paths as required. This is demonstrate how the relative path to the file will change after we move it.\n Save these four files in to your week-8 folder\n\nThe coat colour and mass of 62 cats: cat-coats.csv\n\nThe relative size of over 5000 cells measure by forward scatter (FSC) in flow cytometry: cell-size.txt\n\nThe number of sternopleural bristles on 96 female Drosophila: bristles.txt\n\nThe number of sternopleural bristles on 96 female Drosophila (with technical replicates): bristles-mean.xlsx\n\n\nThe first three files can be read in with core tidyverse Wickham et al. (2019) functions and the last can be read in with the readxl Wickham and Bryan (2023) package.\n Load the two packages\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nWe will first read in cat-coats.csv. A .csv. extension suggests this is plain text file with comma separated columns. However, before we attempt to read it it, when should take a look at it. We can do this from RStudio\n Go to the Files pane (bottom right), click on the cat-coats.csv file and choose View File2\n\n\nRStudio Files Pane\n\nAny plain text file will open in the top left pane (Excel files will launch Excel).\n Is the file csv?\n\n\n What kind of variables does the file contain?\n\n\n Read in the csv file with:\n\ncats &lt;- read_csv(\"cat-coats.csv\")\n\nThe data from the file a read into a dataframe called cats and you will be able to see it in the Environment.\n Click on each of the remaining files and choose View File.\n In each case, say what the format is and what types of variables it contains.\n\n\n\n\n\n\n\n\nWe use the read_table()3 command to read in plain text files of single columns or where the columns are separated by spaces‚Ä¶\n ‚Ä¶so in cell-size.txt can be read into a dataframe called cells like this:\n\ncells &lt;- read_table(\"cell-size.txt\")\n\n Now you try reading bristles.txt in to a dataframe called fly_bristles\nThe readxl package we loaded earlier has two useful functions for working with Excel files: excel_sheets(\"filename.xlsx\") will list the sheets in an Excel workbook; read_excel(\"filename.xlsx\") will read in to top sheet or a specified sheet with a small modification read_excel(\"filename.xlsx\", sheet = \"Sheet1\").\n List the the names of the sheets and read in the sheet with the data like this:\n\nexcel_sheets(\"bristles-mean.xlsx\")\nfly_bristles_means &lt;- read_excel(\"bristles-mean.xlsx\", sheet = \"means\")\n\nWell done! You can now read read in from files in your working directory.\nTo help you understand relative file paths, we will now move the data files.\n First remove the dataframes you just created to make it easier to see whether you can successfully read in the files from a different place:\n\nrm(cat_coats, fly_bristles, cells, flies_bristles_means)\n\n Now make a new folder called data-raw. You can do this on the Files Pane by clicking New Folder and typing into the box that appears.\n Check the boxes next to the file names and choose More | Move‚Ä¶ and select the data-raw folder.\n The files will move. To import data from files in the data-raw folder, you need to give the relative path to the file from the working directory. The working directory is the Project folder, week-8 so the relative path is data-raw/cat-coats.csv\n Import the cat-coats.csv data like this:\n\ncats &lt;- read_csv(\"data-raw/cat-coats.csv\")\n\n Now you do the other files.\nFrom this point forward in the course, we will always create a data-raw folder each time we make a new Project.\nThese are the most common forms of data file you will encounter at first. However, data can certainly come to you in other formats particularly when they have come from particular software. Usually, there is an R package specially for that format.\nIn the rest of the workshop we will take each dataset in turn and create summaries and plots appropriate for the data types. Data is summarised using the group_by() and summarise() functions",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/workshop.html#summarising-discrete-data-cat-coat",
    "href": "pgt52m/week-3/workshop.html#summarising-discrete-data-cat-coat",
    "title": "Workshop",
    "section": "Summarising discrete data: Cat coat",
    "text": "Summarising discrete data: Cat coat\nThe most appropriate way to summarise nominal data like the colour of cat coats is to tabulate the number of cats with each colour.\n Summarise the cats dataframe by counting the number of cats in each category\n\ncats |&gt; \n  group_by(coat) |&gt; \n  count()\n\n# A tibble: 6 √ó 2\n# Groups:   coat [6]\n  coat              n\n  &lt;chr&gt;         &lt;int&gt;\n1 black            23\n2 calico            1\n3 ginger           10\n4 tabby             8\n5 tortoiseshell     5\n6 white            15\n\n\n|&gt; is the pipe and can be produced with Ctrl+Shift+M\nThis sort of data might be represented with a barchart. You have two options for producing that barchart:\n\nplot the summary table using geom_col()\nplot the raw data using geom_bar()\n\nWe did the first of these last week. The geom_col() function uses the numbers in a second column to determine how high the bars are. However, the geom_bar() function will do the tabulating for you.\n Plot the coat data using geom_bar:\n\nggplot(cats, aes(x = coat)) +\n  geom_bar()\n\n\n\n\n\n\n\nThe gaps that R put automatically between the bars reflects that the coat colours are discrete categories.",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/workshop.html#summarising-counts-bristles",
    "href": "pgt52m/week-3/workshop.html#summarising-counts-bristles",
    "title": "Workshop",
    "section": "Summarising Counts: Bristles",
    "text": "Summarising Counts: Bristles\nCounts are discrete and can be thought of a categories with an order (ordinal).\n Summarise the fly_bristles dataframe by counting the number of flies in each category of bristle number\nSince counts are numbers, we might also want to calculate some summary statistics such as the median and interquartile range.\n Summarise the fly_bristles dataframe by calculate the median and interquartile range\n\nfly_bristles |&gt; \n  summarise(median(number),\n            IQR(number))\n\n# A tibble: 1 √ó 2\n  `median(number)` `IQR(number)`\n             &lt;dbl&gt;         &lt;dbl&gt;\n1                6             4\n\n\nAs the interquartile is 4 and the median is 6 then 25% flies have 4 bristles or fewer and 25% have 8 or more.\nThe distribution of counts4 is not symmetrical for lower counts so the mean is not usually a good way to summarise count data.\n If you want to save the table you created and give the columns better names you can make two adjustments:\n\nfly_bristles_summary &lt;- fly_bristles |&gt; \n  summarise(med = median(number),\n            interquartile = IQR(number))\n\n Plot the bristles data using geom_bar:\nIf counts have a a high mean and big range, like number of hairs on a person‚Äôs head, then you can often treat them as continuous. This means you can use statistics like the mean and standard deviation to summarise them, histograms to plot them and use some standard statistical tests on them.",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/workshop.html#summarising-continuous-data",
    "href": "pgt52m/week-3/workshop.html#summarising-continuous-data",
    "title": "Workshop",
    "section": "Summarising continuous data",
    "text": "Summarising continuous data\nCat mass\nThe variable mass in the cats dataframe is continuous. Very many continuous variables have a normal distribution. e normal distribution is also known as the bell-shaped curve. If we had the mass of all the cats in the world, we would find many cats were near the mean and fewer would be away from the mean, either much lighter or much heavier. In fact 68% would be within one standard deviation of the mean and about 96% would be within two standard deviations.\n\n\n\n\n\n\n\n\n We can find the mean mass with:\n\ncats |&gt; \n  summarise(mean = mean(mass))\n\n# A tibble: 1 √ó 1\n   mean\n  &lt;dbl&gt;\n1  4.51\n\n\nWe can add any sort of summary by placing it inside the the summarise parentheses. Each one is separated by a comma. We did this to find the median and the interquatrile range for fly bristles.\n For example, another way to calculate the number of values is to use the length() function:\n\ncats |&gt; \n  summarise(mean = mean(mass),\n            n = length(mass))\n\n# A tibble: 1 √ó 2\n   mean     n\n  &lt;dbl&gt; &lt;int&gt;\n1  4.51    62\n\n\n Adapt the code to calculate the mean, the sample size and the standard deviation (sd())\nA single continuous variable can be plotted using a histogram to show the shape of the distribution.\n Plots a histogram of cats mass:\n\nggplot(cats, aes(x = mass)) +\n  geom_histogram(bins = 15, colour = \"black\") \n\n\n\n\n\n\n\nNotice that there are no gaps between the bars which reflects that mass is continuous. bins determines how many groups the variable is divided up into (i.e., the number of bars) and colour sets the colour for the outline of the bars. A sample of 62 is a relatively small number of values for plotting a distribution and the number of bins used determines how smooth or normally distributed the values look.\n Experiment with the number of bins. Does the number of bins affect how you view the distribution.\nNext week we will practice summarise and plotting data files with several variables but just to give you a taste, we will find summary statistics about mass for each of the coat types.  The group_by() function is used before the summarise() to do calculations for each of the coats:\n\ncats |&gt; \n  group_by(coat) |&gt; \n  summarise(mean = mean(mass),\n                  standard_dev = sd(mass))\n\n# A tibble: 6 √ó 3\n  coat           mean standard_dev\n  &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1 black          4.63        1.33 \n2 calico         2.19       NA    \n3 ginger         4.46        1.12 \n4 tabby          4.86        0.444\n5 tortoiseshell  4.50        0.929\n6 white          4.34        1.34 \n\n\nYou can read this as:\n\ntake cats and then group by coat and then summarise by finding the mean of mass and the standard deviation of mass\n\n Why do we get an NA for the standard deviation of the calico cats?\n\n\n\nCells\n Summarise the cells dataframe by calculating the mean, median, sample size and standard deviation of FSC.\n Add a column for the standard error which is given by \\(\\frac{s.d.}{\\sqrt{n}}\\)\nMeans of counts\nMany things are quite difficult to measure or count and in these cases we often do technical replicates. A technical replicate allows us the measure the exact same thing to check how variable the measurement process is. For example, Drosophila are small and counting their sternopleural bristles is tricky. In addition, where a bristle is short (young) or broken scientists might vary in whether they count it. Or people or machines might vary in measuring the concentration of the same solution.\nWhen we do technical replicates we calculate their mean and use that as the measure. This is what is in our fly_bristles_means dataframe - the bristles of each of the 96 flies was counted by 5 people and the data are those means. These has an impact on how we plot and summarise the dataset because the distribution of mean counts is continuous! We can use means, standard deviations and histograms. This will be an exercise in Consolidate.",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/workshop.html#look-after-future-you",
    "href": "pgt52m/week-3/workshop.html#look-after-future-you",
    "title": "Workshop",
    "section": "Look after future you!",
    "text": "Look after future you!\nFuture you is going to summarise and plot data from the ‚ÄúRiver practicals‚Äù. You can make this much easier by documenting what you have done now. At the moment all of your code from this workshop is in a single file, probably called analysis.R. I recommend making a new script for each of nominal, continuous and count data and copying the code which imports, summarises and plots it. This will make it easier for future you to find the code you need. Here is an example: nominal_data.R. You may wish to comment your version much more.\nYou‚Äôre finished!",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/workshop.html#footnotes",
    "href": "pgt52m/week-3/workshop.html#footnotes",
    "title": "Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\nPlain text files can be opened in notepad or other similar editor and still be readable.‚Ü©Ô∏é\nDo not be tempted to import data this way. Unless you are careful, your data import will not be scripted or will not be scripted correctly.‚Ü©Ô∏é\nnote read_csv() and read_table() are the same functions with some different settings.‚Ü©Ô∏é\nCount data are usually ‚ÄúPoisson‚Äù distributed.‚Ü©Ô∏é",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Workshop"
    ]
  },
  {
    "objectID": "pgt52m/week-3/study_after_workshop.html",
    "href": "pgt52m/week-3/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the packages and import the data.\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n\nfly_bristles_means &lt;- read_excel(\"data-raw/bristles-mean.xlsx\")\ncats &lt;- read_csv(\"data-raw/cat-coats.csv\")\n\nExercises\n\nüíª Summarise the fly_bristles_means dataframe by calculating the mean, median, sample size, standard deviation and standard error of the mean_count variable.\n\n\nAnswer - don‚Äôt look until you have tried!fly_bristles_means_summary &lt;- fly_bristles_means |&gt; \n  summarise(mean = mean(mean_count),\n            median = median(mean_count),\n            n = length(mean_count),\n            standard_dev = sd(mean_count),\n            standard_error = standard_dev / sqrt(n))\n\n\n\nüíª Create an appropriate plot to show the distribution of mean_count in fly_bristles_means\n\n\n\nAnswer - don‚Äôt look until you have tried!ggplot(fly_bristles_means, aes(x = mean_count)) +\n  geom_histogram(bins = 10)\n\n\n\nüíª Can you format the plot 2. by removing the grey background, giving the bars a black outline and the fill colour of your choice and improving the axis format and labelling? You may want to refer to last week‚Äôs workshop.\n\n\nAnswer - don‚Äôt look until you have tried!ggplot(fly_bristles_means, aes(x = mean_count)) +\n  geom_histogram(bins = 10, \n                 colour = \"black\",\n                 fill = \"skyblue\") +\n  scale_x_continuous(name = \"Number of bristles\",\n                     expand = c(0, 0)) +\n  scale_y_continuous(name = \"Frequency\",\n                     expand = c(0, 0),\n                     limits = c(0, 35)) +\n  theme_classic()\n\n\n\nüíª Amend this code to change the order of the bars by the average mass of each coat colour? Changing the order of bars was covered last week. You may also want to practice formatting the graph nicely.\n\n\nggplot(cats, aes(x = coat, y = mass)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nAnswer - don‚Äôt look until you have tried!ggplot(cats, \n       aes(x = reorder(coat, mass), y = mass)) +\n  geom_boxplot(fill = \"darkcyan\") +\n  scale_x_discrete(name = \"Coat colour\") +\n  scale_y_continuous(name = \"Mass (kg)\", \n                     expand = c(0, 0),\n                     limits = c(0, 8)) +\n  theme_classic()\n\n\n\nüìñ Read Understanding the pipe |&gt;",
    "crumbs": [
      "PGT 52M",
      "Week 3: Types of variable, summarising and plotting data",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs2/week-1/study_before_workshop.html",
    "href": "r4babs2/week-1/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read The logic of hyothesis testing\nüìñ Read Confidence Intervals\nIf you have not yet done so, I recommend setting up the Virtual Desktop Service. Instructions are in BABS1",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs2/week-1/overview.html",
    "href": "r4babs2/week-1/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week we will cover the logic of consider the logic of hypothesis testing and type 1 and type 2 errors. We will also find out what the sampling distribution of the mean and the standard error are, and how to calculate confidence intervals.\n\n\n\nArtwork by Horst (2023): ‚Äútype 1 error‚Äù\n\n\n\n\n\nArtwork by Horst (2023): ‚Äútype 2 error‚Äù\n\n\n\nLearning objectives\nThe successful student will be able to:\n\ndemonstrate the process of hypothesis testing with an example\nexplain type 1 and type 2 errors\ndefine the sampling distribution of the mean and the standard error\nexplain what a confidence interval is\ncalculate confidence intervals for large and small samples\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read The logic of hyothesis testing\nüìñ Read Confidence Intervals\n\nWorkshop\n\nüíª Remind yourself how to import files\nüíª Calculate confidence intervals on large\nüíª Calculate confidence intervals on small samples.\n\nConsolidate\n\nüíª Calculate confidence intervals for each group in a data set\n\n\n\n\n\n\n\nReferences\n\nHorst, Allison. 2023. ‚ÄúData Science Illustrations.‚Äù https://allisonhorst.com/allison-horst.",
    "crumbs": [
      "BABS 2",
      "Week 1: The logic of hypothesis testing and CI",
      "About"
    ]
  },
  {
    "objectID": "r4babs2/week-2/study_before_workshop.html",
    "href": "r4babs2/week-2/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read What is a statistical model\nüìñ Read Single linear regression",
    "crumbs": [
      "BABS 2",
      "Week 2: Introduction to statistical models: Single regression",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs2/week-2/overview.html",
    "href": "r4babs2/week-2/overview.html",
    "title": "Overview",
    "section": "",
    "text": "This week, you‚Äôll learn about statistical models, which are mathematical representations of data relationships. Specifically, you‚Äôll explore the general linear model (GLM), a broad framework for analyzing data patterns.\nYour first GLM will be simple linear regression, which fits a straight line to data to predict a response variable (outcome) based on an explanatory variable (predictor). We‚Äôll examine the two key parameters estimated in this model: the slope (which shows how the predictor influences the outcome) and the intercept (the value when the predictor is zero). We‚Äôll also assess whether these values are significantly different from zero.\n\nLearning objectives\nThe successful student will be able to:\n\nexplain what is meant by a statistical model and fitting a model\nknow what the general linear model is and how it relates to regression\nexplain the principle of regression and know when it can be applied\napply and interpret a simple linear regression in R\nevaluate whether the assumptions of regression are met\nscientifically report a regression result including appropriate figures\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read What is a statistical model\nüìñ Read Single linear regression\n\nWorkshop\ni.üíª Carry out a single linear regression\nConsolidate\n\nüíª Appropriately analyse the relationship between juvenile hormone and mandible size in stage beetles\nüíª Appropriately analyse the relationship between anxiety and performance",
    "crumbs": [
      "BABS 2",
      "Week 2: Introduction to statistical models: Single regression",
      "About"
    ]
  },
  {
    "objectID": "r4babs2/week-4/study_before_workshop.html",
    "href": "r4babs2/week-4/study_before_workshop.html",
    "title": "Independent Study to prepare for workshop",
    "section": "",
    "text": "üìñ Read One-way ANOVA and Kruskal-Wallis",
    "crumbs": [
      "BABS 2",
      "Week 4: One-way ANOVA and Kruskal-Wallis",
      "Prepare!"
    ]
  },
  {
    "objectID": "r4babs2/week-4/overview.html",
    "href": "r4babs2/week-4/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Last week you learnt how to use and interpret the general linear model when the x variable was categorical with two groups. You will now extend that to situations when there are more than two groups. This is often known as the one-way ANOVA (analysis of variance). You will also learn about the Kruskal-Wallis test which can be used when the assumptions of the general linear model are not met.\n\nLearning objectives\nThe successful student will be able to:\n\nexplain the rationale for ANOVA\nselect, appropriately, one-way ANOVA and Kruskal-Wallis\nknow what functions are used in R to run these tests and how to interpret them\nevaluate whether the assumptions of lm() are met\nscientifically report the results of these tests including appropriate figures\n\n\n\nInstructions\n\nPrepare\n\nüìñ Read One-way ANOVA and Kruskal-Wallis\n\nWorkshop\n\nüíª One-way ANOVA\nüíª Kruskal-Wallis\n\nConsolidate\n\nüíª Appropriately test if fitness and acclimation effect the sodium content of sweat\nüíª Appropriately test if insecticides vary in their effectiveness",
    "crumbs": [
      "BABS 2",
      "Week 4: One-way ANOVA and Kruskal-Wallis",
      "About"
    ]
  },
  {
    "objectID": "r4babs2/week-5/workshop.html",
    "href": "r4babs2/week-5/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023):\n\n\nIn this workshop you will get practice in applying, interpreting and reporting two-way ANOVA including the interaction term and post-hoc testing.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 5: Two-way ANOVA",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-5/workshop.html#session-overview",
    "href": "r4babs2/week-5/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will get practice in applying, interpreting and reporting two-way ANOVA including the interaction term and post-hoc testing.",
    "crumbs": [
      "BABS 2",
      "Week 5: Two-way ANOVA",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-5/workshop.html#philosophy",
    "href": "r4babs2/week-5/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 5: Two-way ANOVA",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-5/workshop.html#effect-of-brain-region-and-choline-deficiency-on-neuron-size",
    "href": "r4babs2/week-5/workshop.html#effect-of-brain-region-and-choline-deficiency-on-neuron-size",
    "title": "Workshop",
    "section": "Effect of brain region and choline deficiency on neuron size",
    "text": "Effect of brain region and choline deficiency on neuron size\nCognitive performance is influenced by the choline intake in utero. To better understand this phenomenon, pregnant mice were fed a control or choline-deficient diet and their offspring examined. The cross sectional area (CSA) of cholinergic neurons was determined in two brain regions, the MSN and the DB. The data are given in neuron-csa.xlsx\n Save a copy of the data file neuron-csa.xlsx to data-raw\nYou have previously read data from an excel file.\n List the the names of the work sheets in the excel workbook.\nThese data are organised into two worksheets, one for each brain region\n Read in each sheet. I used the names db and msn for the two dataframes/tibble.\n We have the top half and the bottom half of a data set and can combine these togther with bind_rows()\n\nneuron &lt;- bind_rows(db, msn)\n\nYou might want to click on neuron in the environment to open the spreadsheet-like view to check it looks how you expect.\n What kind of variables do you have?\n\n\n\n\n\nExploring\nWhen we have a single explanatory variable, it always goes on the x-axis. Here we have two explanatory variables: brain region and diet. We can map one of the explanatory variables to the x-axis and the other to a aesthetic like colour, shape or fill.\n Do a quick plot of the data:\n\nggplot(data = neuron, aes(x = BrainRegion, y = CSA, fill = Diet)) +\n  geom_violin()\n\n\n\n\n\n\n\nWhether we map BrainRegion to the x-axis or the fill does not really matter. It looks as though the cross sectional area of neurons is higher for the control diet than the deficient diet (the average of the read bars is grater than the average of the blue bars). It also looks like there might be a significant interaction between the effects of diet and brain region because the effect of diet seems to be greater in the DB region.\nSummarising the data\nJust as we needed to incorporate the second explanatory variable in the rough plot, we need to incorporate it into our summary. We do this by adding it to the group_by().\n Create a data frame called neuron_summary that contains the means, standard deviations, sample sizes and standard errors for each group:\n\nneuron_summary &lt;- neuron %&gt;%\n  group_by(BrainRegion, Diet) %&gt;%\n  summarise(mean = mean(CSA),\n            std = sd(CSA),\n            n = length(CSA),\n            se = std/sqrt(n))\n\nYou will get a message that you don‚Äôt need to worry about summarise()has grouped output by 'BrainRegion'. You can override using the.groupsargument.&gt;\nYou should get the following numbers:\n\n\n\n\nBrainRegion\nDiet\nmean\nstd\nn\nse\n\n\n\nDB\nControl\n26.6645\n3.633975\n10\n1.1491638\n\n\nDB\nDeficient\n21.2245\n4.213968\n10\n1.3325736\n\n\nMSN\nControl\n20.9695\n2.779860\n10\n0.8790688\n\n\nMSN\nDeficient\n19.9325\n2.560446\n10\n0.8096842\n\n\n\n\n\nApplying, interpreting and reporting\nWe can now carry out a two-way ANOVA using the same lm() function we used for two-sample tests and one-way ANOVA.\n Carry out an ANOVA and examine the results with:\n\nmod &lt;- lm(data = neuron, CSA ~ BrainRegion * Diet)\nsummary(mod)\n\n\nCall:\nlm(formula = CSA ~ BrainRegion * Diet, data = neuron)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6045 -2.6308  0.0765  2.4820  5.5505 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    26.664      1.064  25.071  &lt; 2e-16 ***\nBrainRegionMSN                 -5.695      1.504  -3.786 0.000560 ***\nDietDeficient                  -5.440      1.504  -3.617 0.000907 ***\nBrainRegionMSN:DietDeficient    4.403      2.127   2.070 0.045692 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.363 on 36 degrees of freedom\nMultiple R-squared:  0.4034,    Adjusted R-squared:  0.3537 \nF-statistic: 8.115 on 3 and 36 DF,  p-value: 0.0002949\n\n\nRemember: the tilde (~) means test the values in CSA when grouped by the values in BrainRegion and Diet Or explain CSA with BrainRegion and Diet\n Can you relate the values under Estimate to the means?\n\n\n\n\n\n\n\n\n\nThe model of brain region and diet overall explains a significant amount of the variation in the cross sectional area of neurons (p-value: 0.0002949). To see which of the three effects are significant we can use the anova() function on our model.\n Determine which effects are significant:\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: CSA\n                 Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nBrainRegion       1 122.05 122.045 10.7893 0.002280 **\nDiet              1 104.88 104.879  9.2717 0.004334 **\nBrainRegion:Diet  1  48.47  48.466  4.2846 0.045692 * \nResiduals        36 407.22  11.312                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere is a significant effect of brain region (F = 10.8; d.f. = 1, 36; p = 0.002) and diet (F = 9.3; d.f. = 1, 36; p = 0.004) on CSA and these effects interact (F = 4.3; d.f. = 1, 36; p = 0.046)\nWe need a post-hoc test to see which comparisons are significant and can again use then emmeans (Lenth 2024) package.\n Load the package\n\nlibrary(emmeans)\n\n Carry out the post-hoc test\n\nemmeans(mod, ~ BrainRegion * Diet) |&gt; pairs()\n\n contrast                     estimate  SE df t.ratio p.value\n DB Control - MSN Control        5.695 1.5 36   3.786  0.0030\n DB Control - DB Deficient       5.440 1.5 36   3.617  0.0048\n DB Control - MSN Deficient      6.732 1.5 36   4.476  0.0004\n MSN Control - DB Deficient     -0.255 1.5 36  -0.170  0.9982\n MSN Control - MSN Deficient     1.037 1.5 36   0.689  0.9005\n DB Deficient - MSN Deficient    1.292 1.5 36   0.859  0.8257\n\nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nEach row is a comparison between the two means in the ‚Äòcontrast‚Äô column. The ‚Äòestimate‚Äô column is the difference between those means and the ‚Äòp.value‚Äô indicates whether that difference is significant.\nA plot can be used to visualise the result of the post hoc which can be especially useful when there are very many comparisons.\n Plot the results of the post-hoc test:\n\nemmeans(mod, ~ BrainRegion * Diet) |&gt; plot()\n\n\n\n\n\n\n\n What do you conclude from the test?\n\n\n\n\n\n\nWe might report this result as:\nA choline-deficient diet in pregnant mice significantly decreases the cross sectional area of cholinergic neurons in the DB region of their offspring (t = 3.62; d.f. = 36; p = 0.0048). The cross sectional area of cholinergic neurons in the MSN region are also significantly smaller than those in the DB region (t = 3.79; d.f. = 36; p = 0.0030) but are not reduces by maternal choline-deficiency.\nCheck assumptions\nThe assumptions of the general linear model are that the residuals ‚Äì the difference between predicted value (i.e., the group mean) and observed values - are normally distributed and have homogeneous variance. To check these we can examine the mod$residuals variable. You may want to refer to Checking assumptions in the ‚ÄúSingle regression‚Äù workshop.\n Plot the model residuals against the fitted values.\n What to you conclude?\n\n\n\nTo examine normality of the model residuals we can plot them as a histogram and do a normality test on them.\n Plot a histogram of the residuals.\n Use the shapiro.test() to test the normality of the model residuals\n What to you conclude?\n\n\n\n\nIllustrating\nWe are going to create a figure like this:\n\n\n\n\n\n\n\n\nWe will again use both our neuron and neuron_summary dataframes.\n Try emulating what you did for one-way ANOVA based on Visualise from the ‚ÄúSummarising data with several variables‚Äù workshop (Rand 2023).\n\nggplot() +\n  geom_point(data = neuron, \n             aes(x = BrainRegion, y = CSA),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"gray50\",\n             size = 3) +\n  geom_errorbar(data = neuron_summary, \n                aes(x = BrainRegion, \n                    ymin = mean - se, \n                    ymax = mean + se),\n                width = 0.4) +\n  geom_errorbar(data = neuron_summary, \n                aes(x = BrainRegion, \n                    ymin = mean,\n                    ymax = mean),\n                width = 0.3, \n                linewidth = 1) +\n  scale_y_continuous(name = \"CSA\",\n                     expand = c(0, 0),\n                     limits = c(0, 45)) +\n  scale_x_discrete(name = \"BrainRegion\") +\n  theme_classic() \n\n\n\n\n\n\n\nHow can we show the two diets separately?\n We can map the Diet variable to the shape aesthetic!\n\nggplot() +\n  geom_point(data = neuron, \n             aes(x = BrainRegion, y = CSA, shape = Diet),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"gray50\",\n             size = 3) +\n  geom_errorbar(data = neuron_summary, \n                aes(x = BrainRegion, \n                    ymin = mean - se, \n                    ymax = mean + se),\n                width = 0.4) +\n  geom_errorbar(data = neuron_summary, \n                aes(x = BrainRegion, \n                    ymin = mean,\n                    ymax = mean),\n                width = 0.3, \n                linewidth = 1) +\n  scale_y_continuous(name = \"CSA\",\n                     expand = c(0, 0),\n                     limits = c(0, 45)) +\n  scale_x_discrete(name = \"BrainRegion\") +\n  theme_classic() \n\n\n\n\n\n\n\nOh, that isn‚Äôt quite what we want! We want the two diets side-by-side, not on top of each other.\n We can achieve that by using setting the position argument to position_jitterdodge() in the geom_point() and to position_dodge() in the two geom_errorbar(). We also have to specify that the error bars are grouped by Diet since they are not otherwise mapped to a shape, colour or fill.\n\nggplot() +\n  geom_point(data = neuron, \n             aes(x = BrainRegion, y = CSA, shape = Diet),\n             position = position_jitterdodge(dodge.width = 1,\n                                             jitter.width = 0.3,\n                                             jitter.height = 0),\n             colour = \"gray50\",\n             size = 3) +\n  geom_errorbar(data = neuron_summary, \n                aes(x = BrainRegion, \n                    ymin = mean - se, \n                    ymax = mean + se,\n                    group = Diet),\n                width = 0.4,\n                position = position_dodge(width = 1)) +\n  geom_errorbar(data = neuron_summary, \n                aes(x = BrainRegion, \n                    ymin = mean,\n                    ymax = mean,\n                    group = Diet),\n                width = 0.3, \n                linewidth = 1,\n                position = position_dodge(width = 1)) +\n  scale_y_continuous(name = \"CSA\",\n                     expand = c(0, 0),\n                     limits = c(0, 45)) +\n  scale_x_discrete(name = \"BrainRegion\") +\n  theme_classic() \n\n\n\n\n\n\n\n Add the annotation of the statistical results\n Finally, we can move the legend to a space on the plot area which helps you minimise the width needed like this:\n\n...... +\n  theme(legend.position = c(0.15, 0.15),\n        legend.background = element_rect(colour = \"black\"))\n\n Save your figure to your figures folder.\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 2",
      "Week 5: Two-way ANOVA",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-5/study_after_workshop.html",
    "href": "r4babs2/week-5/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse and emmeans packages.\n\nlibrary(tidyverse)\nlibrary(emmeans)\n\nExercises\n\nüíª Researchers suspect there may be regional differences between two species of butterfly, F.concocti and F.flappa. They catch 8 randomly chosen individuals of each species in two regions (North and South) and measure their wing lengths in mm. The data are in butterf.txt. What do you conclude about the size of these species in the North and South?\n\n\nAnswer - don‚Äôt look until you have tried!butter  &lt;-  read_table(\"data-raw/butterf.txt\")\nstr(butter)\n\n\n\nAnswer - don‚Äôt look until you have tried!# create a rough plot of the data  \nggplot(data = butter,\n       aes(x = region, y = winglen, fill = spp)) +\n  geom_violin()\nAnswer - don‚Äôt look until you have tried!# There seems to be little difference between the two species in the\n# south but F.concocti\n# is larger than F.flappa in the North.\n\n\n\nAnswer - don‚Äôt look until you have tried!# create a summary of the data\nbutter_summary &lt;- butter %&gt;%\n  group_by(region, spp) %&gt;%\n  summarise(mean = mean(winglen),\n            median = median(winglen),\n            sd = sd(winglen),\n            n = length(winglen),\n            se = sd/sqrt(n))\n\n\n\nAnswer - don‚Äôt look until you have tried!# The data seem to be continuous so it is likely that a parametric\n# test will be fine\n# we will check the other assumptions after we have run the lm\n\n# build the statistical model\nmod &lt;- lm(data = butter, winglen ~ spp * region)\n\n\n# examine it\nsummary(mod)\n\n\n# the line starting (Intercept) is  Œ≤0  \n# the line starting sppF.flappa is Œ≤1\n# the line starting regionsouth is Œ≤2\n# the line starting sppF.flappa:regionsouth is Œ≤3\n\n# F.concocti-north mean is Œ≤0 i.e., 32.275\n# F.Flappa-north mean is Œ≤0 + Œ≤1 i.e., 32.275 - 7.875 = 24.4\n# F.concocti-south is Œ≤0 + Œ≤2  i.e., 32.275 - 8.638 = 23.637\n# F.Flappa--south is Œ≤0 + Œ≤1 + Œ≤2 + Œ≤3 \n#           i.e., 32.275 - 7.875 - 8.638 + 7.713 = 23.475\n\n# The model of spp and region overall explains a significant \n# amount (49%) of the variation in wing lengths\n# (F = 8.1; d.f. = 3, 28; p = 0.0002). To see which of the three \n# effects are significant we can use the `anova()` function on our\n# model.\n\n\n\nAnswer - don‚Äôt look until you have tried!anova(mod)\n\n# There was a significant effect of species (F = 8.1; \n# d.f. = 1, 28; p = 0.008) and region (F = 8.1; \n# d.f. = 1, 28; p = 0.008) on wing length and these effects interact \n# (F = 7.5; d.f. = 1, 28; p = 0.01)\n\n# It is important to consider how the interaction effect is\n# influencing our interpretation of the main effects.\n# Judging by the means and the rough plot, the significant\n# effect of both species and region is due to the fact that\n# F.concocti is larger than F.flappa in the North.\n# In other words, we only have a significant effect of species\n# in the North. \n\n\n# the emmeans package will let us see exactly what comparisons\n# are significant\n\n\n\nAnswer - don‚Äôt look until you have tried!emmeans(mod, ~ spp * region) |&gt; pairs()\n\n# As we suspected all the difference are between  F.concocti north\n# and the other three groups. \n # F.concocti north - F.flappa north    p = 0.0026\n # F.concocti north - F.concocti south  p = 0.0010\n # F.concocti north - F.flappa south    p = 0.0008\n\n# There was a signifcant interaction between the effects of species \n# and region (F = 7.5; d.f. = 1, 28; p = 0.01) with Northern\n# F.concocti being significantly larger than F.concocti in the \n# south (Tukey HSD: p = 0.0010) and F.flappa in the \n# north (p = 0.0026) and south (p = 0.0008). This creates a \n# significant difference between species averaged over region \n# (F = 8.1; d.f. = 1, 28; p = 0.008) and region averaged over species\n\n\n\nAnswer - don‚Äôt look until you have tried!# There is a significant effect of species (F = 8.1; \n# d.f. = 1, 28; p = 0.008) and region (F = 11.5; d.f. = 1, 28; \n# p = 0.002) on wing length. These effect are \n\n\n\nAnswer - don‚Äôt look until you have tried!# let's check the assumptions\nplot(mod, which = 1) \nAnswer - don‚Äôt look until you have tried!# we're looking for the variance in the residuals to be the same in both groups.\n# This looks OK. Maybe a bit higher in the wild plants (with the higher mean)\n \nhist(mod$residuals)\nAnswer - don‚Äôt look until you have tried!shapiro.test(mod$residuals)\n# On balance the use of lm() is probably justifiable  The variance isn't quite equal \n# and the histogram looks a bit off normal but the normality test is NS and the \n# effect (in the figure) is clear.\n\n\n\nAnswer - don‚Äôt look until you have tried!# A figure \nbutter_fig &lt;- ggplot() +\n  geom_point(data = butter, \n             aes(x = region,\n                 y = winglen,\n                 shape = spp),\n             position = position_jitterdodge(dodge.width = 1,\n                                             jitter.width = 0.2,\n                                             jitter.height = 0),\n             size = 2,\n             colour = \"gray50\") +\n  geom_errorbar(data = butter_summary, \n                aes(x = region, \n                    ymin = mean - se, \n                    ymax = mean + se, \n                    group = spp),\n                width = 0.4, \n                position = position_dodge(width = 1)) +\n  geom_errorbar(data = butter_summary, \n                aes(x = region, \n                    ymin = mean, \n                    ymax = mean, \n                    group = spp),\n                width = 0.3, \n                position = position_dodge(width = 1) ) +\n  scale_x_discrete(name = \"region\") +\n  scale_y_continuous(name = \"Wing length (mm)\",\n                     expand = c(0, 0),\n                     limits = c(0, 55)) +\n  scale_shape_manual(values = c(19, 1),\n                     name = NULL,\n                     labels = c(bquote(italic(\"F.concocti\")),\n                                bquote(italic(\"F.flappa\")))) +\n  # F.concocti north - F.flappa north    p = 0.0026\n  annotate(\"segment\",\n           x = 0.75, xend = 1.25,\n           y = 40, yend = 40,\n           colour = \"black\") +\n  annotate(\"text\",\n           x = 1,  y = 42,\n           label = \"p = 0.0026\") +\n  # F.concocti north - F.concocti south  p = 0.0010\n  annotate(\"segment\",\n           x = 0.75, xend = 1.75,\n           y = 44, yend = 44,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.25,  y = 46,\n           label = \"p = 0.0010\") +\n  # F.concocti north - F.flappa south    p = 0.0008\n  annotate(\"segment\",\n           x = 0.75, xend = 2.25,\n           y = 48, yend = 48,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.5,  y = 50,\n           label = \"p = 0.0008\") +\n  theme_classic() +\n  theme(legend.title = element_blank(),\n        legend.position = c(0.2, 0.12)) \n\n# save figure to figures/butter.png\nggsave(\"figures/butter.png\",\n       plot = butter_fig,\n       width = 3.5,\n       height = 3.5,\n       units = \"in\",\n       dpi = 300)",
    "crumbs": [
      "BABS 2",
      "Week 5: Two-way ANOVA",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs2/week-6/workshop.html#session-overview",
    "href": "r4babs2/week-6/workshop.html#session-overview",
    "title": "Workshop",
    "section": "Session overview",
    "text": "Session overview\nIn this session you will",
    "crumbs": [
      "BABS 2",
      "Week 6: Association",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-6/workshop.html#philosophy",
    "href": "r4babs2/week-6/workshop.html#philosophy",
    "title": "Workshop",
    "section": "Philosophy",
    "text": "Philosophy\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 6: Association",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-6/workshop.html#pearsons-correlation",
    "href": "r4babs2/week-6/workshop.html#pearsons-correlation",
    "title": "Workshop",
    "section": "Pearson‚Äôs Correlation",
    "text": "Pearson‚Äôs Correlation\nThe data given in height.txt are the heights of eleven sibling pairs.\n Save a copy of height.txt to your data-raw folder and import it.\n\n\n\n\n\n\nTop Tip\n\n\n\nDid you know you can also read a file directly from the internet instead of saving it first?\nheight &lt;- read_table(\"https://3mmarand.github.io/R4BABS/r4babs2/week-6/data-raw/data-raw/height.txt\")\n\n\nExploring\n What type of variables are older and sister? What are the implications for the test?\n\n\n\n\n\n\n Do a quick plot of the data. We don‚Äôt have a causal relationship here so either variable can go on the x-axis.\n\nggplot(height, aes(x = younger, y = older) ) +\n  geom_point()\n\n\n\n\n\n\n\n Remembering that one of the assumptions for parametric correlation is that any correlation should be linear, what do you conclude from the plot?\n\n\n\n\n\nApplying, interpreting and reporting\nWe will do a parametric correlation in any case.\n We can carry out a Pearson‚Äôs product moment correlation with:\n\ncor.test(data = height, ~ older + younger, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  older and younger\nt = 2.0157, df = 9, p-value = 0.07464\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.06336505  0.86739285\nsample estimates:\n      cor \n0.5577091 \n\n\nNotice that were are not using the response ~ explanatory form here because this is not a causal relationship.\nPearson is the default correlation smethod, therefore we could omit method = \"pearson\".\n What do you conclude from the test?\n\n\n\nIllustrating\n Create a better figure for our data using:\n\nfig1 &lt;- ggplot(height, aes(x = younger, y = older)) +\n  geom_point() +\n  scale_x_continuous(name = \"Younger sibling height (cm)\",\n                     limits = c(120, 190),\n                     expand = c(0, 0)) +\n  scale_y_continuous(name = \"Older sibling height (cm)\",\n                     limits = c(120, 190),\n                     expand = c(0, 0)) +\n   theme_classic()\n\nfig1\n\n\n\n\n\n\n\n Use ggsave() to save your figure to file in your figures folder.",
    "crumbs": [
      "BABS 2",
      "Week 6: Association",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-6/workshop.html#effect-of-sample-size-on-correlation",
    "href": "r4babs2/week-6/workshop.html#effect-of-sample-size-on-correlation",
    "title": "Workshop",
    "section": "Effect of sample size on correlation",
    "text": "Effect of sample size on correlation\nNow we will explore the effect of sample size on the value of the correlation coefficient and its significance.\n Create a dataset with twice the number of observations:\n\nheight2 &lt;- rbind(height, height)\n\nMake sure you view the resulting dataframe. Each pair of values will appear twice.\n Now repeat the correlation with height2\n What do you conclude? What does this tell you about the sensitivity of correlation to sample size?",
    "crumbs": [
      "BABS 2",
      "Week 6: Association",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-6/workshop.html#spearmans-rank-correlation",
    "href": "r4babs2/week-6/workshop.html#spearmans-rank-correlation",
    "title": "Workshop",
    "section": "Spearman‚Äôs rank Correlation",
    "text": "Spearman‚Äôs rank Correlation\nSince our sibling dataset is so small we might very reasonably have chosen to do a non-parametric correlation. The same function is used but we specify a different value for the method argument.\n Carry out a Spearman‚Äôs rank correlation:\n\ncor.test(data = height, ~ older + younger, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  older and younger\nS = 109.74, p-value = 0.1163\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.5011722 \n\n\n What do you conclude?",
    "crumbs": [
      "BABS 2",
      "Week 6: Association",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-6/workshop.html#contingency-chi-squared-test",
    "href": "r4babs2/week-6/workshop.html#contingency-chi-squared-test",
    "title": "Workshop",
    "section": "Contingency chi-squared test",
    "text": "Contingency chi-squared test\nA human geneticist found that in a sample of 477 blood group O people 65 had peptic ulcers whereas in a sample of 387 blood group A people 31 had peptic ulcers.\n Draw a 2 x 2 table of these data (on a piece of paper).\n\n\n\n\n\n\n What is your null hypothesis and what type of test is required?\n\n\n\n\n\n\n Make a vector obs that holds the 4 observed numbers. For the moment, don‚Äôt worry about what order they are in.\nFor a contingency chi squared test, the inbuilt chi-squared test can be used in a straightforward way. However, we need to structure our data as a 2 x 2 table rather than as a 1 x 4 vector. A 2 x 2 table can be created with the matrix() function. We can also name the rows and columns which helps us interpret the results.\n To create a list containing two elements which are vectors for the two groups in each variable we do:\n\n# list of two elements\n# the two variables are whether someone has an ulcer or not and whether \n# they are blood group O or A\nvars &lt;- list(ulcer = c(\"yes\",\"no\"), blood = c(\"O\", \"A\"))\nvars\n\n$ulcer\n[1] \"yes\" \"no\" \n\n$blood\n[1] \"O\" \"A\"\n\n\n Now we can create the matrix from our vector of numbers obs and use our list vars to give the column and row names:\n\nulcers &lt;- matrix(obs, nrow = 2, dimnames = vars)\nulcers\n\n     blood\nulcer   O   A\n  yes  65  31\n  no  412 356\n\n\n Check the content of ulcers and recreate if the numbers are not in the correct place (i.e., do not match your table)\n Run a contingency chi-squared with:\n\nchisq.test(ulcers, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  ulcers\nX-squared = 6.824, df = 1, p-value = 0.008994\n\n# you should look up the command in the manual to see what correct = FALSE does\n\nTo help us discover what is the direction of any deviation from the null hypothesis it is helpful to see what the expected values were. These are accessible in the $expected variable in the output value of the chisq.test() method (See the manual!).\n View the expected values with:\n\nchisq.test(ulcers, correct = FALSE)$expected\n\n     blood\nulcer   O   A\n  yes  53  43\n  no  424 344\n\n\n What do you conclude about the association between ABO blood group and peptic ulcers?\n\n\n\n\n\n\nBlood group and ulcers- alternative data format.\nThe data we were given was already tabulated. There are raw data in blood_ulcers.txt. Examine this file to understand the format\n Save a copy of blood_ulcers.txt to your data-raw folder\n Read the data in to R and check the structure.\n We can tabulate the data and assign it using the table() command:\n\nulctab &lt;- table(blood_ulcers$blood, blood_ulcers$ulcer)\n# examine the result\nulctab\n\n   \n     no yes\n  A 356  31\n  O 412  65\n\n\nWe need to give both variables to cross tabulate.\n Now carry out the contingency chi-squared like this:\n\nchisq.test(ulctab, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  ulctab\nX-squared = 6.824, df = 1, p-value = 0.008994\n\n\nCongratulations on making it to the end of the stage 1 Data Analysis in R teaching!\n\n\nArtwork by Horst (2023):",
    "crumbs": [
      "BABS 2",
      "Week 6: Association",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-6/study_after_workshop.html",
    "href": "r4babs2/week-6/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª The slug Arion ater has three major colour forms, black, chocolate brown and red. Sampling in population X revealed 27 black, 17 brown and 9 red individuals, whereas in population Y the corresponding numbers were 39, 10 and 21. Create an appropriate data structure and test whether the proportion of black, brown and red slugs differs between the two populations.\n\n\nAnswer - don‚Äôt look until you have tried!#  names for the rows and columns\nvars &lt;- list(pop = c(\"x\",\"y\"), \n             colour = c(\"black\", \"brown\", \"red\"))\n\n# matrix of the data with named columns and rows\nslugs &lt;- matrix(c(27, 39, 17, 10, 9, 21), \n                nrow = 2, dimnames = vars)\nslugs\n# gives me\n#    colour\n# pop black brown red\n#   x    27    17   9\n#   y    39    10  21\n\n# you may need to try a couple of times to get the numbers in \n# the right places\n\n\n\nAnswer - don‚Äôt look until you have tried!chisq.test(slugs)\n# X-squared = 6.5726, df = 2, p-value = 0.03739\n\n# p &lt; 0.05 so we reject the null hypothesis i.e., the proportions of the colour \n# forms are significantly different in the two populations \n# (mostly as a result of differences in the brown and red classes - \n# look at the differences between observed and expected values for \n# the three colour forms in the table above).\nchisq.test(slugs)$expected\n#       colour\n# pop    black    brown      red\n#   x 28.43902 11.63415 12.92683\n#   y 37.56098 15.36585 17.07317\n\n\n\nüíª The raw, untabulated data are in slugs.txt. Perform the test on these data.\n\n\nAnswer - don‚Äôt look until you have tried!# import the data\nslugs &lt;- read_table(\"data-raw/slugs.txt\")\n\n# put it into a table\nslugtab &lt;- table(slugs$colour, slugs$pop)\n\n# carry out the test\nchisq.test(slugtab)",
    "crumbs": [
      "BABS 2",
      "Week 6: Association",
      "Consolidate!"
    ]
  },
  {
    "objectID": "r4babs2/week-3/workshop.html",
    "href": "r4babs2/week-3/workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Artwork by Horst (2023): ‚ÄúHow much I think I know about R‚Äù\n\n\nIn this workshop you will get practice in choosing between, performing, and presenting the results of, two-sample tests and their non-parametric equivalents in R.\n\nWorkshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-3/workshop.html#session-overview",
    "href": "r4babs2/week-3/workshop.html#session-overview",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop you will get practice in choosing between, performing, and presenting the results of, two-sample tests and their non-parametric equivalents in R.",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-3/workshop.html#philosophy",
    "href": "r4babs2/week-3/workshop.html#philosophy",
    "title": "Workshop",
    "section": "",
    "text": "Workshops are not a test. It is expected that you often don‚Äôt know how to start, make a lot of mistakes and need help. It is expected that you are familiar with independent study content before the workshop. However, you need not remember or understand every detail as the workshop should build and consolidate your understanding. Tips\n\ndon‚Äôt worry about making mistakes\ndon‚Äôt let what you can not do interfere with what you can do\ndiscussing code with your neighbours will help\nlook things up in the independent study material\nlook things up in your own code from earlier\nthere are no stupid questions\n\n\n\n\n\n\n\nKey\n\n\n\nThese four symbols are used at the beginning of each instruction so you know where to carry out the instruction.\n Something you need to do on your computer. It may be opening programs or documents or locating a file.\n Something you should do in RStudio. It will often be typing a command or using the menus but might also be creating folders, locating or moving files.\n Something you should do in your browser on the internet. It may be searching for information, going to the VLE or downloading a file.\n A question for you to think about and answer. Record your answers in your script for future reference.",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-3/workshop.html#adiponectin-secretion",
    "href": "r4babs2/week-3/workshop.html#adiponectin-secretion",
    "title": "Workshop",
    "section": "Adiponectin secretion",
    "text": "Adiponectin secretion\nAdiponectin is exclusively secreted from adipose tissue and modulates a number of metabolic processes. Nicotinic acid can affect adiponectin secretion. 3T3-L1 adipocytes were treated with nicotinic acid or with a control treatment and adiponectin concentration (pg/mL) measured in the medium. The data are in adipocytes.txt. Each row represents an independent sample of adipocytes and the first column gives the concentration of adiponectin and the second column indicates whether they were treated with nicotinic acid or not (the control).\n Save a copy of adipocytes.txt to data-raw\n Read in the data and check the structure. I used the name adip for the dataframe/tibble.\nWe have a tibble containing two variables: adiponectin is the response variable and is continuous; treatment is explanatory. treatment is categorical with two levels (groups). The first task is visualise the data to get an overview. For continuous response variables with categorical explanatory variables you could use geom_point(), geom_boxplot() or a variety of other geoms. I often use geom_violin() which allows us to see the distribution - the violin is fatter where there are more data points.\n Do a quick plot of the data:\n\nggplot(data = adip, aes(x = treatment, y = adiponectin)) +\n  geom_violin()\n\n\n\n\n\n\n\nSummarising the data\nSummarising the data for each treatment group is the next sensible step. The most useful summary statistics are the means, standard deviations, sample sizes and standard errors.\n Create a data frame called adip_summary that contains the means, standard deviations, sample sizes and standard errors for the control and nicotinic acid treated samples. You may need to read the Summarise section from the Week 9 workshop of BABS1 (Rand 2023)\nYou should get the following numbers:\n\n\n\n\ntreatment\nmean\nstd\nn\nse\n\n\n\ncontrol\n5.546000\n1.475247\n15\n0.3809072\n\n\nnicotinic\n7.508667\n1.793898\n15\n0.4631824\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nRemember that you can see the contents of a dataframe with any of these:\n\ntype the name of the dataframe in the console: prints the dataframe to console\nclick on the dataframe name in the Environment window: opens a spreadsheet like view of the dataframe in the Code window\ntyping View(dataframe) in the console: opens a spreadsheet like view of the dataframe in the Code window\n\n\n\nSelecting a test\n Do you think this is a paired-sample test or two-sample test?\n\n\n\n\nApplying, interpreting and reporting\n Create a two-sample model like this:\n\nmod &lt;- lm(data = adip,\n          adiponectin ~ treatment)\n\n Examine the model with:\n\nsummary(mod)\n\n\nCall:\nlm(formula = adiponectin ~ treatment, data = adip)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3787 -1.0967  0.1927  1.0245  3.1113 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          5.5460     0.4240  13.079  1.9e-13 ***\ntreatmentnicotinic   1.9627     0.5997   3.273  0.00283 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.642 on 28 degrees of freedom\nMultiple R-squared:  0.2767,    Adjusted R-squared:  0.2509 \nF-statistic: 10.71 on 1 and 28 DF,  p-value: 0.00283\n\n\n What do you conclude from the test? Write your conclusion in a form suitable for a report.\n\n\n\n\nCheck assumptions\nThe assumptions of the general linear model are that the residuals ‚Äì the difference between predicted value (i.e., the group mean) and observed values - are normally distributed, and have homogeneous variance. To check these we can examine the mod$residuals variable. You may want to refer to Checking assumptions in the ‚ÄúSingle regression‚Äù workshop.\n Plot the model residuals against the fitted values.\n What to you conclude?\n\n\n\nTo examine normality of the model residuals we can plot them as a histogram and do a normality test on them.\n Plot a histogram of the residuals.\n Use the shapiro.test() to test the normality of the model residuals\n What to you conclude?\n\n\n\n\nIllustrating\n Create a figure like the one below. You may need to refer to Visualise from the ‚ÄúSummarising data with several variables‚Äù workshop (Rand 2023)\n\n\n\n\n\n\n\n\nWe now need to annotate the figure with the results from the statistical test. This most commonly done with a line linking the means being compared and the p-value. The annotate() function can be used to draw the line and then to add the value. The line is a segment and the p-value is a text.\n Add annotation to the figure by adding:\n...... +\n  annotate(\"segment\", x = 1, xend = 2, \n           y = 11.3, yend = 11.3,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.5,  y = 11.7, \n           label = expression(italic(p)~\"= 0.003\")) +\n  theme_classic()\n\n\n\n\n\n\n\n\nFor the segment, annotate() needs the x and y coordinates for the start and the finish of the line.\nThe use of expression() allows you to specify formatting or special characters. expression() takes strings1 or LaTeX2 formatting. Each string or piece of LaTeX is separated by a * or a ~. The * concatenates the strings without a space, ~ does so with a space. It will generate a warning message ‚ÄúIn is.na(x) : is.na() applied to non-(list or vector) of type ‚Äòexpression‚Äô‚Äù which can be ignored.\n Save your figure to your figures folder. Make sure you script figure saving with ggsave().",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-3/workshop.html#grouse-parasites",
    "href": "r4babs2/week-3/workshop.html#grouse-parasites",
    "title": "Workshop",
    "section": "Grouse Parasites",
    "text": "Grouse Parasites\nGrouse livers were dissected and the number of individuals of a parasitic nematode were counted for two estates ‚ÄòGordon‚Äô and ‚ÄòMoss‚Äô. We want to know if the two estates have different infection rates. The data are in grouse.csv\n Save a copy of grouse.csv to data-raw\n Read in the data and check the structure. I used the name grouse for the dataframe/tibble.\nSelecting\n Using your common sense, do these data look normally distributed?\n\n\n\n What test do you suggest?\n\n\nApplying, interpreting and reporting\n Summarise the data by finding the median of each group:\n Carry out a two-sample Wilcoxon test (also known as a Mann-Whitney):\n\nwilcox.test(data = grouse, nematodes ~ estate)\n\n\n    Wilcoxon rank sum exact test\n\ndata:  nematodes by estate\nW = 78, p-value = 0.03546\nalternative hypothesis: true location shift is not equal to 0\n\n\n What do you conclude from the test? Write your conclusion in a form suitable for a report.\n\n\n\nIllustrating\nA box plot is a usually good choice for illustrating a two-sample Wilcoxon test because it shows the median and interquartile range.\n We can create a simple boxplot with:\n\nggplot(data = grouse, aes(x = estate, y = nematodes) ) +\n  geom_boxplot() \n\n\n\n\n\n\n\n Annotate and format the figure so it is more suitable for a report and save it to your figures folder.",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-3/workshop.html#gene-expression",
    "href": "r4babs2/week-3/workshop.html#gene-expression",
    "title": "Workshop",
    "section": "Gene Expression",
    "text": "Gene Expression\nBambara groundnut (Vigna subterranea) is an African legume with good nutritional value which can be influenced by low temperature stress. Researchers are interested in the expression levels of a particular set of 35 genes (probe_id) in response to temperature stress. They measure the expression of the genes at 23 and 18 degrees C (high and low temperature). These samples are not independent because we have two measure from one gene. The data are in expr.xlsx.\nSelecting\n What is the null hypothesis?\n\n\n\n Save a copy of expr.xlsx and import the data. I named the dataframe bambara\n What is the appropriate parametric test?\n\n\nApplying, interpreting and reporting\nA paired test requires account for the variation between genes.\n Create a paired-sample model like this:\n\nmod &lt;- lm(data = bambara, \n          expression ~ temperature + probe_id)\n\n Examine the model with:\n\nsummary(mod)\n\n\nCall:\nlm(formula = expression ~ temperature + probe_id, data = bambara)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5345 -0.2094  0.0000  0.2094  0.5345 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      2.00019    0.28773   6.952 5.15e-08 ***\ntemperaturelowert               -0.30728    0.09591  -3.204  0.00294 ** \nprobe_idGma.12117.1.S1_at        0.11320    0.40122   0.282  0.77955    \nprobe_idGma.12565.1.A1_at        1.31450    0.40122   3.276  0.00243 ** \nprobe_idGma.12641.1.A1_at        0.41440    0.40122   1.033  0.30896    \nprobe_idGma.12911.1.A1_s_at      0.21940    0.40122   0.547  0.58806    \nprobe_idGma.13045.1.S1_at        0.02165    0.40122   0.054  0.95728    \nprobe_idGma.1679.1.A1_at         0.15610    0.40122   0.389  0.69965    \nprobe_idGma.17385.1.S1_at        0.35280    0.40122   0.879  0.38540    \nprobe_idGma.2266.1.S1_s_at      -0.27105    0.40122  -0.676  0.50388    \nprobe_idGma.2555.1.S1_s_at      -0.74210    0.40122  -1.850  0.07308 .  \nprobe_idGma.4452.1.A1_s_at      -0.39600    0.40122  -0.987  0.33062    \nprobe_idGma.5163.2.S1_at         0.69635    0.40122   1.736  0.09169 .  \nprobe_idGma.6423.1.S1_at         0.09230    0.40122   0.230  0.81943    \nprobe_idGma.8525.1.S1_s_at       0.87865    0.40122   2.190  0.03549 *  \nprobe_idGmaAffx.19961.1.S1_at    0.38790    0.40122   0.967  0.34047    \nprobe_idGmaAffx.24949.1.S1_at    0.17475    0.40122   0.436  0.66592    \nprobe_idGmaAffx.30443.1.S1_at    0.36625    0.40122   0.913  0.36775    \nprobe_idGmaAffx.33657.1.S1_at   -0.37655    0.40122  -0.939  0.35460    \nprobe_idGmaAffx.36315.1.S1_at    1.80255    0.40122   4.493 7.73e-05 ***\nprobe_idGmaAffx.37672.1.A1_at    0.60275    0.40122   1.502  0.14225    \nprobe_idGmaAffx.39830.1.S1_at    0.11055    0.40122   0.276  0.78457    \nprobe_idGmaAffx.44319.1.S1_at    0.45780    0.40122   1.141  0.26183    \nprobe_idGmaAffx.52122.1.S1_at    1.17505    0.40122   2.929  0.00604 ** \nprobe_idGmaAffx.55864.1.S1_at   -0.40805    0.40122  -1.017  0.31632    \nprobe_idGmaAffx.5705.1.S1_at     0.81750    0.40122   2.038  0.04944 *  \nprobe_idGmaAffx.59856.1.S1_at   -0.22190    0.40122  -0.553  0.58384    \nprobe_idGmaAffx.67021.2.S1_at    0.22690    0.40122   0.566  0.57543    \nprobe_idGmaAffx.68483.1.S1_at    0.81930    0.40122   2.042  0.04897 *  \nprobe_idGmaAffx.7166.1.S1_at    -1.01450    0.40122  -2.529  0.01626 *  \nprobe_idGmaAffx.77709.1.S1_at    0.72625    0.40122   1.810  0.07913 .  \nprobe_idGmaAffx.77888.1.S1_at    0.17170    0.40122   0.428  0.67139    \nprobe_idGmaAffx.81915.1.S1_at    0.64390    0.40122   1.605  0.11777    \nprobe_idGmaAffx.8717.1.S1_at     0.93150    0.40122   2.322  0.02638 *  \nprobe_idGmaAffx.93493.1.S1_s_at  0.37840    0.40122   0.943  0.35227    \nprobe_idGmaAffx.9536.1.S1_at    -0.61725    0.40122  -1.538  0.13320    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4012 on 34 degrees of freedom\nMultiple R-squared:  0.8238,    Adjusted R-squared:  0.6424 \nF-statistic: 4.542 on 35 and 34 DF,  p-value: 1.273e-05\n\n\nThe ‚Äú(Intercept) Estimate‚Äù will be the average of the higher temperature expression because h come before l in the alphabet. The ‚Äútemperaturelowert‚Äù is how much the expression changes on average going from higher to lower temperatures. You can ignore the rest of the output.\n If you prefer, you can use the anova() function on the model object:\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: expression\n            Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ntemperature  1  1.6524 1.65240 10.2649  0.002943 ** \nprobe_id    34 23.9354 0.70398  4.3732 2.079e-05 ***\nResiduals   34  5.4732 0.16098                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis presents you with less information. The p-value for the effect of temperate on gene expression will always be the same as in the larger table.\n State your conclusion from the test in a form suitable for including in a report. Make sure you give the direction of any significant effect.",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-3/workshop.html#look-after-future-you",
    "href": "r4babs2/week-3/workshop.html#look-after-future-you",
    "title": "Workshop",
    "section": "Look after future you!",
    "text": "Look after future you!\nThe code required to summarise, test, and plot data for a two-independent-samples test AND for a one-way ANOVA is exactly the same except for the names of the dataframe, variables and the axis labels and limits. Take some time to comment it your code so that you can make use of it next week.\n\nYou‚Äôre finished!",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-3/workshop.html#footnotes",
    "href": "r4babs2/week-3/workshop.html#footnotes",
    "title": "Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\nA string in R is a sequence of characters enclosed in quotes, used to represent text data.‚Ü©Ô∏é\nLaTeX is a typesetting system used for scientific documents, enabling precise control over equations, symbols, and document structure.‚Ü©Ô∏é",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Workshop"
    ]
  },
  {
    "objectID": "r4babs2/week-3/study_after_workshop.html",
    "href": "r4babs2/week-3/study_after_workshop.html",
    "title": "Independent Study to consolidate this week",
    "section": "",
    "text": "Set up\nIf you have just opened RStudio you will want to load the tidyverse package\n\nlibrary(tidyverse)\n\nExercises\n\nüíª Plant Biotech. Some plant biotechnologists are trying to increase the quantity of omega 3 fatty acids in Cannabis sativa. They have developed a genetically modified line using genes from Linum usitatissimum (linseed). They grow 50 wild type and fifty modified plants to maturity, collect the seeds and determine the amount of omega 3 fatty acids. The data are in csativa.txt. Do you think their modification has been successful?\n\n\nAnswer - don‚Äôt look until you have tried!csativa  &lt;-  read_table(\"data-raw/csativa.txt\")\nstr(csativa)\n\n# First realise that this is a two sample test. You have two \n# independent samples - there are a total of 100 different plants \n# and the values in one group have no relationship to the values \n# in the other.\n\n\n\nAnswer - don‚Äôt look until you have tried!# create a rough plot of the data  \nggplot(data = csativa, aes(x = plant, y = omega)) +\n  geom_violin()\nAnswer - don‚Äôt look until you have tried!# note the modified plants seem to have lower omega!\n\n\n\nAnswer - don‚Äôt look until you have tried!# create a summary of the data\ncsativa_summary &lt;- csativa |&gt;\n  group_by(plant) |&gt;\n  summarise(mean = mean(omega),\n            std = sd(omega),\n            n = length(omega),\n            se = std/sqrt(n))\n\n\n\nAnswer - don‚Äôt look until you have tried!# The data seem to be continuous so it is likely that a parametric \n# test will be fine.\n# we will check the other assumptions after we have run the lm\n\n# build the statistical model\nmod &lt;- lm(data = csativa, omega ~ plant)\n\n\n# examine it\nsummary(mod)\n# So there is a significant difference but you need to make sure \n# you know the direction!\n# Wild plants have a significantly higher omega 3 content \n# (mean +/- s.e =  56.41 +/- 1.11) than modified plants \n# (49.46 +/- 0.82)(t = 5.03; d.f. = 98; p &lt; 0.0001).\n\n\n\nAnswer - don‚Äôt look until you have tried!# let's check the assumptions\nplot(mod, which = 1) \nAnswer - don‚Äôt look until you have tried!# we're looking for the variance in the residuals to be the \n# same in both groups.\n# This looks OK. Maybe a bit higher in the wild plants\n# (with the higher mean)\n \nhist(mod$residuals)\nAnswer - don‚Äôt look until you have tried!shapiro.test(mod$residuals)\n# On balance the use of lm() is probably justifiable  The variance \n# isn't quite equal and the histogram looks a bit off normal but \n# the normality test is NS and the effect (in the figure) is clear.\n\n\n\nAnswer - don‚Äôt look until you have tried!# A figure \nfig1 &lt;- ggplot() +\n  geom_point(data = csativa, aes(x = plant, y = omega),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"gray50\") +\n  geom_errorbar(data = csativa_summary, \n                aes(x = plant, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = csativa_summary, \n                aes(x = plant, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_x_discrete(name = \"Plant type\", labels = c(\"GMO\", \"WT\")) +\n  scale_y_continuous(name = \"Amount of Omega 3 (units)\",\n                     expand = c(0, 0),\n                     limits = c(0, 90)) +\n    annotate(\"segment\", x = 1, xend = 2, \n           y = 80, yend = 80,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.5,  y = 85, \n           label = expression(italic(p)~\"&lt; 0.001\")) +\n  theme_classic()\n\n# save figure to figures/csativa.png\nggsave(\"figures/csativa.png\",\n       plot = fig1,\n       width = 3.5,\n       height = 3.5,\n       units = \"in\",\n       dpi = 300)",
    "crumbs": [
      "BABS 2",
      "Week 3: Two-sample tests",
      "Consolidate!"
    ]
  }
]